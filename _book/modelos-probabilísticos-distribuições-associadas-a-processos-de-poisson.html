<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 7 Modelos Probabilísticos: Distribuições Associadas a Processos de Poisson | GED-13: Probabilidade e Estatística</title>
  <meta name="description" content="Apostila do curso de GED-13: Probabilidade e Estatística." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 7 Modelos Probabilísticos: Distribuições Associadas a Processos de Poisson | GED-13: Probabilidade e Estatística" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Apostila do curso de GED-13: Probabilidade e Estatística." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 7 Modelos Probabilísticos: Distribuições Associadas a Processos de Poisson | GED-13: Probabilidade e Estatística" />
  
  <meta name="twitter:description" content="Apostila do curso de GED-13: Probabilidade e Estatística." />
  

<meta name="author" content="Prof. Denise Beatriz Ferrari" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"/>
<link rel="next" href="modelos-probabilísticos-distribuição-normal.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Probabilidade e Estatística</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Objetivos do Curso</a></li>
<li class="chapter" data-level="1" data-path="introdução.html"><a href="introdução.html"><i class="fa fa-check"></i><b>1</b> Introdução</a><ul>
<li class="chapter" data-level="1.1" data-path="introdução.html"><a href="introdução.html#estatística-e-o-raciocínio-científico"><i class="fa fa-check"></i><b>1.1</b> Estatística e o Raciocínio Científico</a></li>
<li class="chapter" data-level="1.2" data-path="introdução.html"><a href="introdução.html#o-que-é-estatística"><i class="fa fa-check"></i><b>1.2</b> O que é Estatística?</a></li>
<li class="chapter" data-level="1.3" data-path="introdução.html"><a href="introdução.html#o-papel-da-probabilidade-em-estatística"><i class="fa fa-check"></i><b>1.3</b> O Papel da Probabilidade em Estatística</a></li>
<li class="chapter" data-level="1.4" data-path="introdução.html"><a href="introdução.html#elementos-fundamentais-em-estatística"><i class="fa fa-check"></i><b>1.4</b> Elementos Fundamentais em Estatística</a><ul>
<li class="chapter" data-level="" data-path="introdução.html"><a href="introdução.html#população-e-amostra"><i class="fa fa-check"></i>População e Amostra</a></li>
<li class="chapter" data-level="" data-path="introdução.html"><a href="introdução.html#variáveis"><i class="fa fa-check"></i>Variáveis</a></li>
<li class="chapter" data-level="" data-path="introdução.html"><a href="introdução.html#dados-e-fontes-de-dados"><i class="fa fa-check"></i>Dados e Fontes de Dados</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introdução.html"><a href="introdução.html#tipos-de-problemas"><i class="fa fa-check"></i><b>1.5</b> Tipos de Problemas</a></li>
<li class="chapter" data-level="1.6" data-path="introdução.html"><a href="introdução.html#o-processo-de-análise-de-dados"><i class="fa fa-check"></i><b>1.6</b> O Processo de Análise de Dados</a></li>
<li class="chapter" data-level="1.7" data-path="introdução.html"><a href="introdução.html#métodos-para-exploração-resumo-e-descrição-de-dados"><i class="fa fa-check"></i><b>1.7</b> Métodos para Exploração, Resumo e Descrição de Dados</a><ul>
<li class="chapter" data-level="" data-path="introdução.html"><a href="introdução.html#análise-exploratória-de-dados-exploratory-data-analysis-eda"><i class="fa fa-check"></i>Análise Exploratória de Dados (“Exploratory Data Analysis”, EDA)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html"><i class="fa fa-check"></i><b>2</b> Introdução à Teoria de Probabilidades</a><ul>
<li class="chapter" data-level="2.1" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#breve-histórico"><i class="fa fa-check"></i><b>2.1</b> Breve Histórico</a><ul>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#chance-e-incerteza"><i class="fa fa-check"></i>Chance e Incerteza</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#jogos-de-azar"><i class="fa fa-check"></i>Jogos de Azar</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#origem-da-teoria-matemática-de-probabilidades"><i class="fa fa-check"></i>Origem da Teoria Matemática de Probabilidades</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#formalização-matemática"><i class="fa fa-check"></i>Formalização Matemática</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#definições-iniciais"><i class="fa fa-check"></i><b>2.2</b> Definições Iniciais</a><ul>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#experimento-aleatório"><i class="fa fa-check"></i>Experimento Aleatório</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#espaço-amostral-e-evento"><i class="fa fa-check"></i>Espaço Amostral e Evento</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#lei-de-probabilidade"><i class="fa fa-check"></i>Lei de Probabilidade</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#interpretações-de-probabilidade"><i class="fa fa-check"></i><b>2.3</b> Interpretações de Probabilidade</a><ul>
<li><a href="introdução-à-teoria-de-probabilidades.html#interpretação-clássica-a-priori-laplace-1812">Interpretação Clássica (<em>a priori</em>): Laplace, 1812</a></li>
<li><a href="introdução-à-teoria-de-probabilidades.html#interpretação-empírica-ou-de-frequência-relativa-a-posteriori-richard-v.-mises-1919">Interpretação Empírica ou de Frequência Relativa (<em>a posteriori</em>): Richard V. Mises, 1919</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#interpretação-subjetiva"><i class="fa fa-check"></i>Interpretação Subjetiva</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#resumo"><i class="fa fa-check"></i>Resumo</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#definição-axiomática"><i class="fa fa-check"></i><b>2.4</b> Definição Axiomática</a></li>
<li class="chapter" data-level="2.5" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#revisitando-o-paradoxo-de-de-méré-o-problema-dos-dados"><i class="fa fa-check"></i><b>2.5</b> Revisitando o Paradoxo de De Méré: O Problema dos Dados</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html"><i class="fa fa-check"></i><b>3</b> Probabilidade Condicional e Independência</a><ul>
<li class="chapter" data-level="3.1" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#probabilidade-condicional"><i class="fa fa-check"></i><b>3.1</b> Probabilidade Condicional</a><ul>
<li class="chapter" data-level="" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#propriedades"><i class="fa fa-check"></i>Propriedades</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#independência-de-eventos"><i class="fa fa-check"></i><b>3.2</b> Independência de Eventos</a><ul>
<li class="chapter" data-level="" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#propriedades-1"><i class="fa fa-check"></i>Propriedades</a></li>
<li class="chapter" data-level="" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#independência-condicional"><i class="fa fa-check"></i>Independência Condicional</a></li>
<li class="chapter" data-level="" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#eventos-independentes-x-eventos-mutuamente-exclusivos"><i class="fa fa-check"></i>Eventos Independentes x Eventos Mutuamente Exclusivos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="teoremas-fundamentais-da-probabilidade.html"><a href="teoremas-fundamentais-da-probabilidade.html"><i class="fa fa-check"></i><b>4</b> Teoremas Fundamentais da Probabilidade</a><ul>
<li class="chapter" data-level="4.1" data-path="teoremas-fundamentais-da-probabilidade.html"><a href="teoremas-fundamentais-da-probabilidade.html#teorema-da-probabilidade-total-dividir-para-conquistar"><i class="fa fa-check"></i><b>4.1</b> Teorema da Probabilidade Total: …dividir para conquistar!</a></li>
<li class="chapter" data-level="4.2" data-path="teoremas-fundamentais-da-probabilidade.html"><a href="teoremas-fundamentais-da-probabilidade.html#teorema-de-bayes-aprendendo-pela-experiência"><i class="fa fa-check"></i><b>4.2</b> Teorema de Bayes: …aprendendo pela experiência</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html"><i class="fa fa-check"></i><b>5</b> Variáveis Aleatórias e Distribuições</a><ul>
<li class="chapter" data-level="5.1" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#variáveis-aleatórias"><i class="fa fa-check"></i><b>5.1</b> Variáveis Aleatórias</a><ul>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#definição-caso-unidimensional"><i class="fa fa-check"></i>Definição (caso unidimensional)</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#tipos-de-variáveis-aleatórias"><i class="fa fa-check"></i>Tipos de Variáveis Aleatórias</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#distribuições-de-probabilidade"><i class="fa fa-check"></i><b>5.2</b> Distribuições de Probabilidade</a><ul>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#função-distribuição-de-probabilidade-fdp-caso-discreto"><i class="fa fa-check"></i>Função Distribuição de Probabilidade (fdp): caso discreto</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#função-distribuição-de-probabilidade-fdp-caso-contínuo"><i class="fa fa-check"></i>Função Distribuição de Probabilidade (fdp): caso contínuo</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#função-distribuição-acumulada-fda"><i class="fa fa-check"></i>Função Distribuição Acumulada (FDA)</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#valor-esperado-e-variância"><i class="fa fa-check"></i><b>5.3</b> Valor Esperado e Variância</a><ul>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#valor-esperado"><i class="fa fa-check"></i>Valor Esperado</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#o-problema-dos-pontos-e-a-aposta-de-pascal"><i class="fa fa-check"></i>O Problema dos Pontos e a Aposta de Pascal</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#variância"><i class="fa fa-check"></i>Variância</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#desvio-padrão"><i class="fa fa-check"></i>Desvio-padrão</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#momentos"><i class="fa fa-check"></i><b>5.4</b> Momentos</a><ul>
<li><a href="variáveis-aleatórias-e-distribuições.html#assimetria-skewness-e-excesso-kurtosis">Assimetria (<em>skewness</em>) e Excesso (<em>kurtosis</em>)</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#desigualdades-de-markov-e-chebyshev"><i class="fa fa-check"></i><b>5.5</b> Desigualdades de Markov e Chebyshev</a><ul>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#desigualdade-de-markov"><i class="fa fa-check"></i>Desigualdade de Markov</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#desigualdade-de-chebyshev"><i class="fa fa-check"></i>Desigualdade de Chebyshev</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><i class="fa fa-check"></i><b>6</b> Modelos Probabilísticos: Distribuições Associadas a Processos de Bernoulli</a><ul>
<li class="chapter" data-level="6.1" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#o-experimento-de-bernoulli"><i class="fa fa-check"></i><b>6.1</b> O Experimento de Bernoulli</a></li>
<li class="chapter" data-level="6.2" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-de-bernoulli"><i class="fa fa-check"></i><b>6.2</b> Distribuição de Bernoulli</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#resumo-2"><i class="fa fa-check"></i>Resumo</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-binomial"><i class="fa fa-check"></i><b>6.3</b> Distribuição Binomial</a></li>
<li class="chapter" data-level="6.4" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#um-problema-de-tomada-de-decisão"><i class="fa fa-check"></i><b>6.4</b> Um Problema de Tomada de Decisão</a></li>
<li class="chapter" data-level="6.5" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-geométrica"><i class="fa fa-check"></i><b>6.5</b> Distribuição Geométrica</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#propriedade-de-ausência-de-memória"><i class="fa fa-check"></i>Propriedade de Ausência de Memória</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#outras-distribuições"><i class="fa fa-check"></i><b>6.6</b> Outras Distribuições</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-binomial-negativa-ou-distribuição-de-pascal"><i class="fa fa-check"></i>Distribuição Binomial Negativa (ou Distribuição de Pascal)</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-multinomial"><i class="fa fa-check"></i>Distribuição Multinomial</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-multinomial-negativa"><i class="fa fa-check"></i>Distribuição Multinomial Negativa</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-hipergeométrica"><i class="fa fa-check"></i>Distribuição Hipergeométrica</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-hipergeométrica-negativa"><i class="fa fa-check"></i>Distribuição Hipergeométrica Negativa</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#resumo-4"><i class="fa fa-check"></i>Resumo</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><i class="fa fa-check"></i><b>7</b> Modelos Probabilísticos: Distribuições Associadas a Processos de Poisson</a><ul>
<li class="chapter" data-level="7.1" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#uma-aproximação-para-a-distribuição-binomial"><i class="fa fa-check"></i><b>7.1</b> Uma aproximação para a Distribuição Binomial</a></li>
<li class="chapter" data-level="7.2" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#distribuição-de-poisson"><i class="fa fa-check"></i><b>7.2</b> Distribuição de Poisson</a></li>
<li class="chapter" data-level="7.3" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#o-processo-de-poisson"><i class="fa fa-check"></i><b>7.3</b> O Processo de Poisson</a></li>
<li class="chapter" data-level="7.4" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#distribuição-exponencial"><i class="fa fa-check"></i><b>7.4</b> Distribuição Exponencial</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#propriedade-de-ausência-de-memória-1"><i class="fa fa-check"></i>Propriedade de Ausência de Memória</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#distribuição-de-weibull"><i class="fa fa-check"></i>Distribuição de Weibull:</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#distribuição-gama"><i class="fa fa-check"></i><b>7.5</b> Distribuição Gama</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html"><i class="fa fa-check"></i><b>8</b> Modelos Probabilísticos: Distribuição Normal</a><ul>
<li class="chapter" data-level="8.1" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#distribuição-normal"><i class="fa fa-check"></i><b>8.1</b> Distribuição Normal</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#mais-uma-aproximação-para-a-distribuição-binomial"><i class="fa fa-check"></i>…(Mais) Uma Aproximação para a Distribuição Binomial</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#cálculo-de-probabilidades"><i class="fa fa-check"></i>Cálculo de Probabilidades</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#padronização-1"><i class="fa fa-check"></i>Padronização</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#regra-empírica"><i class="fa fa-check"></i>Regra Empírica</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#coeficiente-de-variação"><i class="fa fa-check"></i>Coeficiente de Variação</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#aproximação-para-distribuições-discretas"><i class="fa fa-check"></i><b>8.2</b> Aproximação para Distribuições Discretas</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#aproximação-para-a-distribuição-binomial"><i class="fa fa-check"></i>Aproximação para a Distribuição Binomial</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#métodos-descritivos-para-avaliar-normalidade"><i class="fa fa-check"></i><b>8.3</b> Métodos Descritivos para Avaliar Normalidade</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html"><i class="fa fa-check"></i><b>9</b> Distribuições Amostrais</a><ul>
<li class="chapter" data-level="9.1" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#introdução-à-inferência-estatística"><i class="fa fa-check"></i><b>9.1</b> Introdução à Inferência Estatística</a><ul>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#inferência-estatística"><i class="fa fa-check"></i>Inferência Estatística</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#amostras-e-distribuições-amostrais"><i class="fa fa-check"></i><b>9.2</b> Amostras e Distribuições Amostrais</a><ul>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#amostra-aleatória"><i class="fa fa-check"></i>Amostra Aleatória</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#parâmetos-vs.-estatísticas"><i class="fa fa-check"></i>Parâmetos vs. Estatísticas</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-amostral"><i class="fa fa-check"></i>Distribuição Amostral</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-da-média-amostral"><i class="fa fa-check"></i><b>9.3</b> Distribuição da Média Amostral</a><ul>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#propriedades-da-média-amostral"><i class="fa fa-check"></i>Propriedades da Média Amostral</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#lei-dos-grandes-números"><i class="fa fa-check"></i>Lei dos Grandes Números</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#teorema-do-limite-central"><i class="fa fa-check"></i><b>9.4</b> Teorema do Limite Central</a></li>
<li class="chapter" data-level="9.5" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuições-amostrais-associadas-a-populações-normais"><i class="fa fa-check"></i><b>9.5</b> Distribuições Amostrais Associadas a Populações Normais</a><ul>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-qui-quadrado"><i class="fa fa-check"></i>Distribuição Qui-Quadrado</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-t-student"><i class="fa fa-check"></i>Distribuição t-Student</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#aproximando-distribuições-amostrais-via-simulação-de-monte-carlo"><i class="fa fa-check"></i><b>9.6</b> Aproximando Distribuições Amostrais via Simulação de Monte Carlo</a><ul>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-aproximada-da-mediana-amostral"><i class="fa fa-check"></i>Distribuição Aproximada da Mediana Amostral</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-aproximada-do-desvio-padrão-amostral"><i class="fa fa-check"></i>Distribuição Aproximada do Desvio-Padrão Amostral</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-aproximada-da-variância-amostral"><i class="fa fa-check"></i>Distribuição Aproximada da Variância Amostral</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-aproximada-do-mad-desvio-mediano-absoluto"><i class="fa fa-check"></i>Distribuição Aproximada do MAD (Desvio Mediano Absoluto)</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-aproximada-da-amplitude-inter-quartis-iqr"><i class="fa fa-check"></i>Distribuição Aproximada da Amplitude Inter-Quartis (IQR)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="estimação-pontual.html"><a href="estimação-pontual.html"><i class="fa fa-check"></i><b>10</b> Estimação Pontual</a><ul>
<li class="chapter" data-level="10.1" data-path="estimação-pontual.html"><a href="estimação-pontual.html#estimador-e-estimativa"><i class="fa fa-check"></i><b>10.1</b> Estimador e Estimativa</a></li>
<li class="chapter" data-level="10.2" data-path="estimação-pontual.html"><a href="estimação-pontual.html#propriedades-de-estimadores"><i class="fa fa-check"></i><b>10.2</b> Propriedades de Estimadores</a><ul>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#não-tendeciosidade-exatidão"><i class="fa fa-check"></i>Não-Tendeciosidade (exatidão)</a></li>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#eficiência-precisão"><i class="fa fa-check"></i>Eficiência (precisão)</a></li>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#consistência"><i class="fa fa-check"></i>Consistência</a></li>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#erro-médio-quadrático"><i class="fa fa-check"></i>Erro Médio Quadrático</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="estimação-pontual.html"><a href="estimação-pontual.html#métodos-clássicos-de-estimação-de-parâmetros"><i class="fa fa-check"></i><b>10.3</b> Métodos Clássicos de Estimação de Parâmetros</a><ul>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#método-dos-momentos"><i class="fa fa-check"></i>Método dos Momentos</a></li>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#método-da-máxima-verossimilhança"><i class="fa fa-check"></i>Método da Máxima Verossimilhança</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="intervalos-de-confiança.html"><a href="intervalos-de-confiança.html"><i class="fa fa-check"></i><b>11</b> Intervalos de Confiança</a><ul>
<li class="chapter" data-level="11.1" data-path="intervalos-de-confiança.html"><a href="intervalos-de-confiança.html#estimação-por-intervalos"><i class="fa fa-check"></i><b>11.1</b> Estimação por Intervalos</a></li>
<li class="chapter" data-level="11.2" data-path="intervalos-de-confiança.html"><a href="intervalos-de-confiança.html#procedimento-para-construção-de-ics"><i class="fa fa-check"></i><b>11.2</b> Procedimento para Construção de IC’s</a><ul>
<li><a href="intervalos-de-confiança.html#caso-1-ic-para-mu-com-sigma2-conhecida">CASO 1: IC para <span class="math inline">\(\mu\)</span> com <span class="math inline">\(\sigma^2\)</span> conhecida</a></li>
<li><a href="intervalos-de-confiança.html#caso-2.1-ic-para-mu-com-sigma2-desconhecida">CASO 2.1: IC para <span class="math inline">\(\mu\)</span> com <span class="math inline">\(\sigma^2\)</span> desconhecida</a></li>
<li><a href="intervalos-de-confiança.html#caso-2.2-ic-para-mu-com-sigma2-desconhecida-amostras-grandes">CASO 2.2: IC para <span class="math inline">\(\mu\)</span> com <span class="math inline">\(\sigma^2\)</span> desconhecida (amostras grandes)</a></li>
<li><a href="intervalos-de-confiança.html#caso-3-ic-para-p-proporção-populacional">CASO 3: IC para <span class="math inline">\(p\)</span> (proporção populacional)</a></li>
<li><a href="intervalos-de-confiança.html#caso-3-ic-para-sigma2">CASO 3: IC para <span class="math inline">\(\sigma^2\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html"><i class="fa fa-check"></i><b>12</b> Testes de Hipóteses</a><ul>
<li class="chapter" data-level="12.1" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#formulação-de-hipóteses-estatísticas"><i class="fa fa-check"></i><b>12.1</b> Formulação de Hipóteses Estatísticas</a></li>
<li class="chapter" data-level="12.2" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#estatística-do-teste"><i class="fa fa-check"></i><b>12.2</b> Estatística do Teste</a></li>
<li class="chapter" data-level="12.3" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#erros-de-decisão"><i class="fa fa-check"></i><b>12.3</b> Erros de Decisão</a></li>
<li class="chapter" data-level="12.4" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#região-crítica"><i class="fa fa-check"></i><b>12.4</b> Região Crítica</a></li>
<li class="chapter" data-level="12.5" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#valor-p"><i class="fa fa-check"></i><b>12.5</b> Valor-p</a></li>
<li class="chapter" data-level="" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#qual-a-probabilidade-de-cometer-erro-do-tipo-ii"><i class="fa fa-check"></i>Qual a probabilidade de cometer erro do tipo II?</a></li>
<li class="chapter" data-level="12.6" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#poder-do-teste"><i class="fa fa-check"></i><b>12.6</b> Poder do Teste</a></li>
<li class="chapter" data-level="12.7" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#resumo-gráfico"><i class="fa fa-check"></i><b>12.7</b> Resumo Gráfico</a></li>
<li class="chapter" data-level="12.8" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#testes-mono--e-bi-caudais"><i class="fa fa-check"></i><b>12.8</b> Testes Mono- e Bi-Caudais</a><ul>
<li class="chapter" data-level="" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#região-de-rejeição-para-um-teste-bi-caudal"><i class="fa fa-check"></i>Região de Rejeição para um Teste Bi-caudal</a></li>
</ul></li>
<li class="chapter" data-level="12.9" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#procedimento-para-testes-de-hipóteses-utilizando-o-nível-de-significância"><i class="fa fa-check"></i><b>12.9</b> Procedimento para Testes de Hipóteses (utilizando o nível de significância)</a></li>
<li class="chapter" data-level="12.10" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#procedimento-para-testes-de-hipóteses-utilizando-valor-p"><i class="fa fa-check"></i><b>12.10</b> Procedimento para Testes de Hipóteses (utilizando valor-p)</a></li>
<li class="chapter" data-level="12.11" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#ic-vs-th"><i class="fa fa-check"></i><b>12.11</b> IC vs TH</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">GED-13: Probabilidade e Estatística</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson" class="section level1">
<h1><span class="header-section-number">Capítulo 7</span> Modelos Probabilísticos: Distribuições Associadas a Processos de Poisson</h1>
<p>No capítulo anterior, estudamos algumas distribuições associadas aos chamados processos de Bernoulli, formados por sequências de experimentos aleatórios independentes, para os quais há apenas dois resultados possíveis, rotulados “sucesso” e “fracasso”, de forma que a probabilidade de “sucesso” é a mesma para todos os experimentos. Estes processos aleatórios foram estudados por muitos matemáticos como Jakob Bernoulli I, Abraham de Moivre, entre muitos outros.</p>
<p>Na primeira metade do século XIX, o matemático francês Siméon-Denis Poisson, (1781-1840) analisou uma longa sequência de experimentos de Bernoulli (ou seja, em que <span class="math inline">\(n\)</span> é grande), para os quais a probabilidade <span class="math inline">\(p\)</span> de sucesso em cada experimento era muito pequena. Assim, encontrou uma forma limite para a distribuição Binomial que recebeu seu nome, ficando conhecida como distribuição de Poisson.</p>
<div id="uma-aproximação-para-a-distribuição-binomial" class="section level2">
<h2><span class="header-section-number">7.1</span> Uma aproximação para a Distribuição Binomial</h2>
<p>Vamos considerar uma v.a. <span class="math inline">\(X\)</span> que tem distribuição Binomial com parâmetros <span class="math inline">\(n\)</span> e <span class="math inline">\(p\)</span>, tal que <span class="math inline">\(n\)</span> é muito grande ( <span class="math inline">\(n \rightarrow \infty\)</span> ) e <span class="math inline">\(p\)</span> muito pequeno ( <span class="math inline">\(p \rightarrow 0\)</span> ), de forma que o número esperado de sucessos <span class="math inline">\(\lambda = np\)</span>, seja constante.</p>
<p>Substituindo <span class="math inline">\(p\)</span> por <span class="math inline">\(\lambda/n\)</span>, é possível escrever a probabilidade de observar <span class="math inline">\(x\)</span> sucessos como segue:</p>
<p><span class="math display">\[\begin{align*}
  X \sim \mathit{Bin}(n, p): \quad P[X = x] &amp;= \frac{n!}{(n-x)!x!} p^x (1-p)^{n-x}\\
           &amp;= \frac{n!}{(n-x)!x!} \left(\frac{\lambda}{n}\right)^x \left(1-\frac{\lambda}{n}\right)^{n-x}\\
           &amp;= \frac{n(n-1)\ldots(n-x+1)}{n^x} \frac{\lambda^x}{x!} \frac{(1- \lambda/n)^n}{(1- \lambda/n)^x}\\
  \begin{array}{l} 
    n \rightarrow \infty, \; p \rightarrow 0\\ 
    np \stackrel{n \rightarrow \infty}{\longrightarrow}\lambda = cte.
  \end{array}&amp;\longrightarrow \frac{\lambda^x}{x!}e^{-\lambda}\\\\
\end{align*}\]</span></p>
<p>Vamos analisar os termos da expressão para <span class="math inline">\(P[X=x]\)</span>, ao se manter <span class="math inline">\(x\)</span> e <span class="math inline">\(\lambda\)</span> constantes e fazendo <span class="math inline">\(n\)</span> tender ao infinito <span class="math inline">\(n\rightarrow \infty\)</span>:
+ o termo <span class="math inline">\(n/n\)</span> é exatamente igual a 1;<br />
+ cada um dos termos <span class="math inline">\(n-1/n\)</span>, <span class="math inline">\(n-2/n\)</span>, até <span class="math inline">\((n-x+1)/n\)</span> tende a 1;<br />
+ o limite de <span class="math inline">\((1 - \lambda/n)^n\)</span> quando <span class="math inline">\(n \rightarrow \infty\)</span> é o limite exponencial fundamental e, portanto, este limite vai a <span class="math inline">\(e^{-\lambda}\)</span>; e, finalmente,
+ o denominador <span class="math inline">\((1 - \lambda/n)^x\)</span> tem limite igual a 1 quando <span class="math inline">\(n \rightarrow \infty\)</span>, já que <span class="math inline">\(\lambda\)</span> e <span class="math inline">\(x\)</span> são mantidos constantes.</p>
<p>Portanto, a probabilidade de observar exatamente <span class="math inline">\(x\)</span> sucessos em uma longa sequência de experimentos de Bernoulli tende a <span class="math inline">\((\lambda^x/x!) e^{-\lambda}\)</span>. Esta é a chamada distribuição de Poisson. Note que ela depende apenas do produto <span class="math inline">\(\lambda = np\)</span>, não de <span class="math inline">\(n\)</span> e <span class="math inline">\(p\)</span>, separadamente. Esta aproximação é válida quando <span class="math inline">\(np \approx 5\)</span>, ou seja, quando <span class="math inline">\(n\geq 50\)</span> e <span class="math inline">\(p \leq 0.1\)</span>, ou <span class="math inline">\(n \geq 100\)</span> e <span class="math inline">\(p \leq 0.05\)</span>. Se estivermos diante de uma situação em que a probabilidade de sucesso é muito elevada, próxima de um, basta inverter os rótulos “sucesso” e “fracasso” e a aproximação continua sendo válida, claro!</p>
</div>
<div id="distribuição-de-poisson" class="section level2">
<h2><span class="header-section-number">7.2</span> Distribuição de Poisson</h2>
<p>Uma v.a. <span class="math inline">\(X\)</span> com distribuição de Poisson com parâmetro <span class="math inline">\(\lambda &gt; 0\)</span> tem fdp dada por:</p>
<p>Seja a v.a. <span class="math inline">\(X \sim Pois(\lambda)\)</span></p>
<p><span class="math inline">\(X =\)</span> no. de ocorrências em uma longa sequência de experimentos de Bernoulli.</p>
<p><span class="math display">\[\begin{align*}
  &amp;{} f_{X}(x) = \left\{
  \begin{array}{rl}
    \frac{\lambda^x}{x!} e^{-\lambda}, &amp; x = 0, 1, \ldots\\
    0,           &amp; c.c.
  \end{array}\right.
  \quad \lambda &gt; 0
  \\ \\
  &amp;{} E[X] = \lambda \qquad Var[X] = \lambda
\end{align*}\]</span></p>
<p>A v.a. de Poisson modela o número de sucessos em uma longa sequência de experimentos de Bernoulli, em que a chance de sucesso em cada experimento é muito pequena. Sendo assim, sua distribuição pode ser entendida como descrição do número de ocorrências de um evento raro, quando se submete a uma grande exposição ao fenômeno que produz tais eventos.</p>
<p>Como modela a contagem de um número de ocorrências, a v.a. <span class="math inline">\(X\)</span> pode assumir qualquer valor inteiro não negativo. A média, ou o número esperado de ocorrências, é dado pela constante <span class="math inline">\(\lambda\)</span>, que é o mesmo valor da variância desta v.a.</p>
<p>A distribuição de Poisson pode ser utilizada também para modelar os chamados “never events”, que consistem em erros médicos que nunca deveriam ocorrer, como por exemplo, realizar uma cirurgia na parte errada do corpo do paciente, ou trocar mãe e bebê em uma maternidade.</p>
<p>Esta distribuição foi desenvolvida por Poisson em 1837 em um livro que escreveu, mostrando o uso de teoria de probabilidades em aplicações jurídicas, embora o próprio Poisson nunca mais tenha apresentado este resultado em qualquer de suas numerosas publicações matemáticas.</p>
<p>A distribuição de Poisson começou a ganhar notoriedade apenas depois da publicação, em 1898, de um trabalho desenvolvido pelo estatístico russo Ladislaus Bortkiewicz (1868-1931), que mostrou pela primeira vez como esta distribuição poderia ser utilizada para explicar a regularidade estatística observada na ocorrência de certos eventos raros, como nós veremos no exemplo a seguir.</p>

<div class="example">
<span id="exm:unnamed-chunk-1" class="example"><strong>Exemplo 1.1  </strong></span>
</div>

<p>No final do século XIX, unidades de cavalaria estavam presentes em grande parte dos exércitos e, vez por outra, alguém em uma dessas unidades acabava morrendo como consequência de um coice de cavalo recebido. Bortkiewicz registrou as ocorrências de tais mortes para 14 unidades de cavalaria do exército prussiano durante o período de 20 anos de 1875 a 1894, obtendo um total de 280 observações, e analisou os dados estatisticamente.</p>
<p>A chance de um soldado ser morto por um coice de cavalo em um determinado ano era extremamente baixa, mas como o número de soldados nas unidades era muito grande, o número de mortes deveria seguir a distribuição de Poisson. Os dados coletados por Bortkiewicz são apresentados na tabela apresentada a seguir. A primeira coluna corresponde ao número de mortes observadas; a segunda coluna registra a frequência observada para cada quantidade de mortes. O total de mortes registrado é de 196 (que corresponde a <span class="math inline">\(91 \times 1 + 32 \times 2 + 11 \times 3 + 2 \times 4\)</span> ), portanto o número de mortes por unidade por ano é 196/280 = 0.7. Bortkiewicz utilizou esse valor como uma estimativa para <span class="math inline">\(\lambda\)</span>.</p>
<div class="figure"><span id="fig:ch7-prussian-cavalry-horse-kick-table"></span>
<img src="img/prussian-cavalry-horse-kick-table.png" alt="Fonte: Bortkewitsch, L (1898). *Das Gesetz der kleinen Zahlen*. In: Bulmer, MG. (1979) *Principles of Statistics*, Dover Publications." width="70%" />
<p class="caption">
Figura 7.1: Fonte: Bortkewitsch, L (1898). <em>Das Gesetz der kleinen Zahlen</em>. In: Bulmer, MG. (1979) <em>Principles of Statistics</em>, Dover Publications.
</p>
</div>
<p>A coluna com as frequências esperadas foi obtida utilizando <span class="math inline">\(\lambda = 0,7\)</span> no cálculo das probabilidades que seriam obtidas a partir da distribuição de Poisson (multiplicando cada valor por 280). Então, o valor 139 corresponde à probabilidade de não observar nenhuma morte (que vale aproximadamente 49,7%) vezes 280. Os outros valores são obtidos de maneira análoga. Você pode tentar realizar o exercício de calcular os outros valores da coluna. Se calcularmos a variância para os dados observados temos um valor igual a 0,75 (o que é compatível com a distribuição de Poisson). Note a semelhança entre os valores observados e os valores estimados utilizando o modelo matemático.</p>
<p>De fato, é possível testar a hipótese de que os dados seguem a distribuição de Poisson e chegar à conclusão de que não há diferença estatisticamente significativa entre os valores estimados e os valores observados. E isto foi feito por um dos grandes nomes da Estatística do século XX, Sir Ronald Fisher, que foi o primeiro a demonstrar quantitativamente a adequação do modelo probabilístico de Poisson a este conjunto de dados, utilizando o teste de aderência Qui-quadrado.</p>
<p>A distribuição de Poisson é uma das mais importantes na prática, devido à sua ampla aplicação nas mais diversas áreas científicas que incluem genética, astronomia, geologia, finanças e muitas outras, além de grande importância na análise de sistemas de filas, presentes em sistemas de produção, logística, transporte, comunicação, entre tantos outros. Alguns exemplos de situações que podem ser satisfatoriamente modeladas pela v.a. de Poisson incluem: o número de mensagens de email que chegam a um servidor; o número de pessoas que chegam a um estabelecimento comercial; o número de asteróides que atingem o planeta terra (pode ser analisado com relação ao domínio do tempo ou localização); o número de imperfeições em um material; a quantidade de organismos em uma quantidade de fluido, e assim, por diante.</p>
<p>Basicamente, cada uma dessas situações e inúmeras outras podem ser modeladas aproximadamente por uma distribuição de Poisson pelo mesmo motivo: o fato de a distribuição de Poisson ser uma aproximação para a distribuição Binomial.</p>
</div>
<div id="o-processo-de-poisson" class="section level2">
<h2><span class="header-section-number">7.3</span> O Processo de Poisson</h2>
<p>A distribuição de Poisson também pode ser utilizada para modelar a contagem de “sucessos” ocorrendo em um outro tipo de processo aleatório, chamado Processo de Poisson. Diferentemente de um processo de Bernoulli, em que a contagem se dava em um domínio discreto, em um processo de Poisson as ocorrências se dão em um domínio contínuo (que pode ser tempo, comprimento, área, volume etc). Por conveniência (e sem perda de generalidade), vamos analisar o caso em que observamos certas ocorrências de um fenômeno de interesse no tempo.</p>
<p>Vamos ilustrar um processo de Poisson considerando a seguinte situação: Suponha que observamos a chegada de pessoas a um local onde se encontra um caminhão pipa que fornece água para famílias de uma certa localidade. Vamos registrar o número de famílias que chegam a esse posto num determinado período de tempo, que pode ser, por exemplo, um dia.</p>
<p>Historicamente, sabe-se que, <em>em média</em>, 10 famílias costumam buscar água neste local diariamente. O caminhão tem capacidade de abastecer no máximo 15 famílias. Então, se houver uma demanda superior a 15, as famílias excedentes terão que ser redirecionadas a outro local.</p>
<p><em>Qual a probabilidade de que, em um determinado dia, algumas famílias tenham que ser desviadas para outro posto?</em> Portanto, queremos determinar a probabilidade de que a demanda exceda a capacidade de atendimento do posto.</p>
<p>Então, estamos monitorando o processo de chegada de pessoas a este posto e podemos facilmente imaginar que esse processo não é completamente previsível. Podemos considerar que as famílias chegam ao local em instantes aleatórios, <span class="math inline">\(T_1, T_2, T_3 \ldots\)</span> , durante o intervalo de tempo <span class="math inline">\((0, t]\)</span> que, no nosso caso, corresponde ao período de operação diária do caminhão pipa. As ocorrências no tempo podem ser representadas da seguinte maneira:</p>
<p><img src="img/processo-poisson-tempo.png" width="100%" /></p>
<p>Vamos considerar uma <em>ocorrência</em> como sendo a chegada de uma família até o posto e vamos iniciar a contagem das ocorrências no instante <span class="math inline">\(t = 0\)</span>. O número de ocorrências <span class="math inline">\(N(t)\)</span> é um processo estocástico de contagem se satisfaz às condições apresentadas a seguir.</p>
<p>Se iniciamos a contagem de ocorrências no instante de tempo igual a 0, então o número <span class="math inline">\(N(t)\)</span> de ocorrências registradas no instante <span class="math inline">\(t\geq0\)</span> é o resultado de um processo aleatório <span class="math inline">\(\{N(t): t \geq 0\}\)</span>, tal que:</p>
<ul>
<li><span class="math inline">\(N(0) = 0\)</span><br />
</li>
<li><span class="math inline">\(N(t) \in \{0, 1, 2, \ldots\}\)</span><br />
</li>
<li><span class="math inline">\(u &lt; t \Rightarrow N(u) \leq N(t)\)</span></li>
</ul>
<p>Portanto, onúmero de ocorrências no instante inicial é igual a zero, o que, para o nosso exemplo, significa que não há famílias esperando no posto antes de iniciar o período de operação do caminhão pipa; o número de ocorrências em cada instante de tempo <span class="math inline">\(t\)</span> é um número inteiro não negativo; e para um determinado instante <span class="math inline">\(u\)</span> anterior ao instante <span class="math inline">\(t\)</span>, o número de ocorrências no instante <span class="math inline">\(u\)</span> será menor ou igual ao número de ocorrências no instante <span class="math inline">\(t\)</span>.</p>
<p>Sejam <span class="math inline">\(t, s &gt;0\)</span> instantes quaisquer após o instante inicial <span class="math inline">\(t_0 = 0\)</span>:</p>
<p><img src="img/processo-poisson-tempo-2.png" width="60%" /></p>
<ul>
<li>o intervalo <span class="math inline">\((0,t]\)</span> tem comprimento <span class="math inline">\(t\)</span>;<br />
</li>
<li>o intervalo <span class="math inline">\((t, t+s]\)</span> tem comprimento <span class="math inline">\(s\)</span>; de forma que<br />
</li>
<li>o número de ocorrências entre os instantes <span class="math inline">\(t\)</span> e <span class="math inline">\(t+s\)</span> vale <span class="math inline">\(N(t+s) - N(t)\)</span>.</li>
</ul>
<p>Um processo estocástico de contagem apresenta incrementos independentes quando o número de ocorrências em intervalos disjuntos são independentes e apresenta incrementos estacionários quando o número de ocorrências em um intervalo só depende do comprimento do intervalo. Um dos processos estocásticos de contagem mais importantes é o <strong>Processo de Poisson</strong>, que apresenta as seguintes características:</p>
<ul>
<li><p><strong>(Homogeneidade, estacionariedade fraca)</strong> A probabilidade de exatamente uma ocorrência em um pequeno intervalo de comprimento <span class="math inline">\(h\)</span> é aproximadamente proporcional ao comprimento do intervalo:
<span class="math display">\[P[N(h) = 1] = \lambda h + o(h); \qquad \lim_{h \rightarrow 0}  \frac{o(h)}{h} = 0\]</span></p></li>
<li><p>A probabilidade de <strong>mais de uma ocorrência</strong> em um pequeno intervalo de comprimento <span class="math inline">\(h\)</span> é desprezível:
<span class="math display">\[P[N(h) &gt; 1] = o(h)\]</span></p></li>
<li><p><strong>(Independência, ausência de memória)</strong> O número de ocorrências em qualquer intervalo de comprimento <span class="math inline">\(h\)</span> é
independente do histórico de ocorrências em outros instantes fora deste intervalo.</p></li>
</ul>
<p>Portanto, um processo de contagem aleatório é um Processo de Poisson se é possível assumir que:</p>
<ol style="list-style-type: lower-roman">
<li><p>a probabilidade de observar <em>exatamente uma ocorrência</em> em um pequeno intervalo de comprimento <span class="math inline">\(h\)</span> é aproximadamente proporcional ao comprimento desse intervalo, de forma que, para pequenos valores de <span class="math inline">\(h\)</span>, essa probabilidade vale <span class="math inline">\(\lambda h\)</span> mais algo que é muito menor se comparado a <span class="math inline">\(h\)</span> ( <span class="math inline">\(\lambda\)</span> é a constante de proporcionalidade, chamada de taxa do processo e
a função <span class="math inline">\(o(h)\)</span> é uma função nula, que vai mais rapidamente para zero que <span class="math inline">\(h\)</span> );</p></li>
<li><p>a probabilidade de observar duas ou mais ocorrências em um pequeno intervalo é desprezível, o que significa que a probabilidade de duas ou mais ocorrências simultâneas é nula; e, finalmente,</p></li>
<li><p>as ocorrências se dão de maneira independente, de forma que o que quer que aconteça em determinado intervalo, isto não tem efeito probabilístico em outros intervalos não sobrepostos a este.</p></li>
</ol>
<p>Sob essas condições, precisamos determinar, para qualquer valor de <span class="math inline">\(k\)</span>, a probabilidade de <strong>exatamente</strong> <span class="math inline">\(k\)</span> ocorrências em um intervalo de comprimento <span class="math inline">\(t+h\)</span>:</p>
<p><span class="math display">\[P_k(t+h) = P[N(t+h) = k]\]</span></p>
<p>Façamos, então, para <span class="math inline">\(k=0\)</span>, <span class="math inline">\(k=1\)</span> e, assim, sucessivamente.</p>
<ul>
<li>Para <span class="math inline">\(k = 0\)</span>:</li>
</ul>
<p><span class="math display">\[\begin{align*}
  P_0(t+h) &amp;= P[\text{nenhuma ocorrência no intervalo } (0, t+h]]\\
           &amp;= P[\text{nenhuma ocorrência em } (0, t] \cap 
                \text{nenhuma ocorrência em } (t, t+h] ]\\
  \stackrel{\text{(indep.)}}{} 
           &amp;= P[\text{nenhuma ocorrência em } (0, t]] \cdot  
              P[\text{nenhuma ocorrência em }(t, t+h]]\\  
           &amp;= P_0(t) \cdot P_0(h)
\end{align*}\]</span></p>
<p>Mas,</p>
<p><span class="math display">\[\begin{align*}
  P_0(h)  &amp;= P[\text{nenhuma ocorrência no intervalo } (t, t+h]]\\
          &amp;= 1 - P [\text{pelo menos uma ocorrência em }(t, t+h]]\\
          &amp;= 1 - P[\text{exatamente uma ocorrência em } (t, t+h]] \\
          &amp; \phantom{= 1\;}- P[\text{pelo menos duas ocorrências em }(t, t+h]]\\
          &amp;= 1 - \lambda h - o(h) - o(h)
\end{align*}\]</span></p>
<p>Portanto,</p>
<p><span class="math display">\[\begin{align*}
  P_0(t+h) &amp;= P_0(t) \cdot P_0(h)  \\
           &amp;= P_0(t) \cdot (1 - \lambda h - o(h) - o(h))\\
           &amp;= P_0(t) - \lambda h P_0(t) - P_0(t) (o(h) + o(h))\\
\end{align*}\]</span></p>
<p>Dividindo toda a expressão por <span class="math inline">\(h\)</span>:</p>
<p><span class="math display">\[\frac{P_0(t+h) - P_0(t)}{h} = - \lambda P_0(t) - P_0(t) \frac{o(h) + o(h)}{h}\]</span></p>
<p>Tomando o limite quando <span class="math inline">\(h \rightarrow 0:\)</span></p>
<p><span class="math display">\[\lim_{h \rightarrow 0} \frac{P_0(t+h) - P_0(t)}{h} = - \lambda P_0(t)\]</span>
Obtemos:</p>
<p><span class="math inline">\(P_0^\prime(t) = - \lambda P_0(t)\)</span></p>
<p>Sob a condição inicial <span class="math inline">\(P_0(0) = 1\)</span>, esta é uma equação diferencial cuja solução é:</p>
<p><span class="math display">\[P_0(t) = e^{-\lambda t}\]</span>
Analogamente,</p>
<ul>
<li>Para <span class="math inline">\(k = 1\)</span>:</li>
</ul>
<p><span class="math display">\[\begin{align*}
  P_1(t+h) &amp;= P_1(t)\cdot P_0(h) + P_0(t)\cdot P_1(h)\\ 
           &amp;= P_1(t)(1 - \lambda h - o(h)) + P_0(t)(\lambda h + o(h))\\   
\end{align*}\]</span></p>
<p>Que leva à equação diferencial:</p>
<p><span class="math inline">\(P_1^\prime(t) = - \lambda P_1(t) + \lambda P_0(t)\)</span></p>
<p>Cuja solução, sob a condição inicial <span class="math inline">\(P_1(0) = 0\)</span>, é:</p>
<p><span class="math display">\[P_1(t) = (\lambda t) e^{-\lambda t}\]</span></p>
<p>É possível mostrar que:</p>
<p><span class="math inline">\(P_k^\prime(t) = - \lambda P_k(t) + \lambda P_{k-1}(t), \quad\)</span> para <span class="math inline">\(k = 2, 3, \ldots\)</span></p>
<p>Este sistema de equações diferenciais tem solução:</p>
<p><span class="math display">\[P_k(t) = \frac{(\lambda t)^k}{k!} e^{-\lambda t}\]</span></p>
<p>Se
<span class="math inline">\(P[N(t)=k]:\)</span> probabilidade de exatamente <span class="math inline">\(k\)</span> ocorrências em um intervalo de tempo qualquer de comprimento <span class="math inline">\(t\geq 0\)</span></p>
<p>então:
<span class="math display">\[\sum_{k=0}^\infty P[N(t)=k] = 1,\]</span>
ou seja, em cada intervalo de comprimento <span class="math inline">\(t\)</span>, devemos ter exatamente ou 0, ou 1, ou 2 etc ocorrências.</p>
<p>Note que <span class="math inline">\(P[N(t)=k]\)</span> é fdp com relação a <span class="math inline">\(k\)</span>, mas não é fdp com relação a <span class="math inline">\(t\)</span>. Podemos garantir apenas que:
<span class="math display">\[0 \leq \int_{t=0}^\infty P[N(t)=k] dt &lt; \infty\]</span></p>
<p>A distribuição de probabilidade para o número de ocorrências em um intervalo de tempo de comprimento <span class="math inline">\(t\)</span> é dada por:</p>
<p><span class="math display">\[P[X = k] = \frac{(\lambda t)^k}{k!} e^{-\lambda t}\]</span>
Portanto, para o exemplo de motivação, definindo a v.a.</p>
<p><span class="math inline">\(X =\)</span> no. de famílias que chegam ao posto a uma taxa <span class="math inline">\(\lambda = 10\)</span>/dia; <span class="math inline">\(t=1\)</span> dia.</p>
<p>A probabilidade de que algumas famílias precisem ser desviadas para outro local é igual à probabilidade de que mais do que 15 famílias cheguem ao local em um dia. Utilizando o complementar, essa probabilidade é igual a 1 - a probabilidade de <span class="math inline">\(X \leq 15\)</span>, que vale aproximadamente 5%:</p>
<p><span class="math display">\[\begin{align*}
P[X &gt; 15] = 1 - P[X \leq 15] = 1 - \sum_{x=0}^{15}\frac{e^{-\lambda}}{x!}\lambda^x 
          = 1 - 0,9513 = 0,0487 \approx 5\% 
\end{align*}\]</span></p>
<p>Como acabamos de ver, um processo de Poisson consiste em um experimento em que ocorrências de um determinado fenômeno aleatório que possui certas características especiais se dão em um domínio contínuo. A v.a. de Poisson é utilizada para modelar o número dessas ocorrências.</p>
<p>Agora, suponha que uma dessas ocorrências tenha apenas sido observada. Por exemplo, uma família tenha acabado de chegar ao posto onde se encontra o caminhão pipa. O que podemos afirmar sobre o tempo de espera até a chegada da próxima família? Podemos perceber que se as chegadas acontecem de maneira aleatória, de forma que o instante dessas ocorrências é também uma variável aleatória. Portanto, resta determinar qual a distribuição do tempo de espera até observar a próxima ocorrência em um Processo de Poisson? Este aspecto do processo de Poisson é modelado pela distribuição Exponencial.</p>
</div>
<div id="distribuição-exponencial" class="section level2">
<h2><span class="header-section-number">7.4</span> Distribuição Exponencial</h2>
<p>Para um processo de Poisson, consideremos <span class="math inline">\(X\)</span> o instante de ocorrência do primeiro evento. Se o primeiro evento ocorrer após o instante <span class="math inline">\(t\)</span>, isso significa que nenhuma ocorrência no processo de Poisson foi observada no intervalo que vai de 0 a <span class="math inline">\(t\)</span>. Portanto, a probabilidade de observar a primeira ocorrência após o instante <span class="math inline">\(t\)</span> vale:</p>
<p><span class="math inline">\(P[X &gt; t] = P[\)</span> nenhuma ocorrência no intervalo <span class="math inline">\((0,t]] = P_{0}(t) = e^{-\lambda t}\)</span></p>
<p>A função distribuição acumulada para essa v.a. corresponde à probabilidade de que o tempo de espera seja no máximo igual a <span class="math inline">\(t\)</span>, que é o complementar da probabilidade calculada anteriormente. Assim, a FDA de <span class="math inline">\(X\)</span> vale:</p>
<p><span class="math inline">\(P[X \leq t] = F_{X}(t) = 1 - P[X &gt; t] = 1 - e^{-\lambda t}, \quad t &gt;0\)</span>.</p>
<p>A fdp de <span class="math inline">\(X\)</span> pode ser obtida derivando-se a FDA:</p>
<p><span class="math display">\[f_{X}(x) =\frac{dF_X(x)}{dx} = \lambda e^{-\lambda x}, \quad x &gt; 0\]</span></p>
<p>Sendo assim, uma v.a. <span class="math inline">\(X\)</span> que representa o tempo de espera entre ocorrências sucessivas em um processo de Poisson tem distribuição exponencial com parâmetro <span class="math inline">\(\lambda\)</span>, em que <span class="math inline">\(\lambda\)</span> é a taxa de ocorrência no processo de Poisson. Por se tratar de um tempo de espera, a v.a. pode assumir valores reais não negativos, de acordo com fdp <span class="math inline">\(f_X(x)\)</span>, dada abaixo.</p>
<p>Seja a v.a. <span class="math inline">\(X \sim Exp(\lambda)\)</span></p>
<p><span class="math inline">\(X =\)</span> tempo de espera entre ocorrências sucessivas em um processo de Poisson</p>
<p><span class="math display">\[\begin{align*}
  &amp;{} f_{X}(x) = \left\{
  \begin{array}{rl}
    \lambda e^{-\lambda x}, &amp; x \geq 0\\
    0,           &amp; c.c.
  \end{array}\right.
  \quad \lambda &gt; 0
  \\ \\
  &amp;{} E[X] = \frac{1}{\lambda} \qquad Var[X] = \frac{1}{\lambda^2}
\end{align*}\]</span></p>
<p>É possível mostrar que o valor esperado desta v.a. é <span class="math inline">\(1/\lambda\)</span>, ou seja, o tempo médio de espera é o inverso da taxa média de ocorrências, e que a variância vale <span class="math inline">\(1/\lambda^2\)</span>.</p>
<p>Vimos anteriormente que o processo de Poisson pode ser visto como um limite para um processo de Bernoulli, portanto há analogias entre esses dois tipos de processos aleatórios e também entre as distribuições associadas a eles.</p>
<p>A distribuição de Poisson é análoga à distribuição Binomial; ambas descrevem o número de ocorrências (ou sucessos). A distribuição exponencial pode ser vista como uma análoga contínua da distribuição geométrica; ambas descrevem o tempo de espera. Uma v.a. com distribuição geométrica estava associada a um processo de Bernoulli e descrevia o número de experimentos necessários até obter o primeiro sucesso (ou seja, num domínio discreto); já a distribuição exponencial descreve o tempo de espera até observar a primeira ocorrência em um processo de Poisson, cujo domínio é contínuo.</p>
<p>Como podemos suspeitar, existe também relação limite entre as distribuições geométrica e exponencial. Se <span class="math inline">\(Y\)</span> for uma v.a. com distribuição geométrica e probabilidade de sucesso igual a <span class="math inline">\(\lambda/n\)</span>, então a distribuição de <span class="math inline">\(Y/n\)</span> converge para a distribuição exponencial com parâmetro <span class="math inline">\(\lambda\)</span>.</p>
<div id="propriedade-de-ausência-de-memória-1" class="section level3 unnumbered">
<h3>Propriedade de Ausência de Memória</h3>
<p>Geralmente, em Engenharia, modelos matemáticos servem de representações simplificadas de fenômenos observados no mundo real. Tais simplificações frequentemente são resultantes de nossa incapacidade de perceber e representar o fenômeno em sua totalidade, ou podem ser necessárias para tornar o problema matematicamente tratável. No entanto, sempre há o risco de super-simplificar o problema, de forma que as conclusões obtidas a partir da solução matemática podem acabar vagamente relacionadas ao problema real. Então, no processo de modelagem matemática de um fenômeno real, é necessário dosar de maneira adequada o nível de simplificação do modelo a fim de que ele seja tratável, mas não tanto que se acabe por resolver perfeitamente um problema que não existe. Uma simplificação comumente adotada na modelagem de certos fenômenos aleatórios é de que a v.a. tem distribuição exponencial. Como vimos, esta variável aleatória descreve tempo de espera e, por este motivo, é frequentemente utilizada em confiabilidade para modelar o tempo de vida de sistemas.</p>
<p>Assim como sua correspondente discreta, a distribuição exponencial também possui a propriedade de ausência de memória, enunciada a seguir:</p>
<p><span class="math display">\[P[X \geq t + s | X \geq t]  = P [X \geq s], \quad \forall t, s \geq 0\]</span></p>
<p>Se modelarmos a vida de um componente por uma v.a. <span class="math inline">\(X\)</span> com distribuição exponencial, a propriedade de ausência de memória afirma o seguinte: a probabilidade de que o componente funcione um período de pelo menos <span class="math inline">\(t+s\)</span>, dado que funcionou pelo menos até o instante <span class="math inline">\(t\)</span> é igual à probabilidade inicial de que dure pelo menos até o instante <span class="math inline">\(s\)</span>. Em outras palavras, se o componente durou até o instante <span class="math inline">\(t\)</span>, então a distribuição do restante de vida é igual à distribuição da vida original. Ou seja, a vida residual do componente tem fdp independente da idade do componente, o componente “não lembra” que já funcionou até o instante <span class="math inline">\(t\)</span>, ele não sofre desgaste, é tão bom quanto um novo. Dizemos que a função taxa de falha para a distribuição exponencial é constante e vale <span class="math inline">\(\lambda\)</span>.</p>
<p>Esta é uma hipótese um tanto restritiva que implicitamente precisamos aceitar como válida ao utilizar a distribuição Exponencial para modelar a vida de componentes, instrumentos ou sistemas. Por este motivo, a distribuição exponencial deve ser utilizada com cautela, já que há inúmeras situações em que esta hipótese não é válida. Neste caso, o modelo exponencial não é adequado e outros modelos para tempo de vida são possíveis, tais como a distribuição de Weibull, que é uma generalização da distribuição exponencial. A distribuição de Weibull é bastante flexível e permite representar sistemas com função taxa de falha crescente (para valores do parâmetro <span class="math inline">\(\beta &gt; 1\)</span> ), constante ( <span class="math inline">\(\beta= 1\)</span> ) e decrescente ( <span class="math inline">\(\beta &lt; 1\)</span> ).</p>
<div id="distribuição-exponencial-1" class="section level4 unnumbered">
<h4>Distribuição Exponencial:</h4>
<p><span class="math inline">\(F_X(x) = P[X \leq x] = 1 - e^{-\lambda x}\)</span> : função taxa de falha constante = <span class="math inline">\(\lambda\)</span></p>
</div>
</div>
<div id="distribuição-de-weibull" class="section level3 unnumbered">
<h3>Distribuição de Weibull:</h3>
<p><span class="math inline">\(F_X(x) = P[X \leq x] = 1 - e^{-(x/\eta)^\beta}; \; x \geq 0, \beta &gt;0, \eta &gt;0\)</span> : função taxa de falha crescente <span class="math inline">\((\beta &gt; 1)\)</span>, constante <span class="math inline">\((\beta=1)\)</span>, decrescente <span class="math inline">\((\beta &lt; 1)\)</span></p>
<p>O caso de função taxa de falha crescente é bastante intuitivo e representa situações em que o sistema se degrada e sofre desgaste com o tempo. O caso de função taxa de falha decrescente representa situações em que o sistema “melhora” com o tempo. Um exemplo clássico é um sistema que apresenta um período de mortalidade infantil. Este tipo de falha normalmente está associado a erro de projeto, baixo controle de qualidade ou defeitos de material, de forma que quando o período inicial é superado, o sistema apresenta menor taxa de falha conforme o tempo passa.</p>
<p>Vejamos alguns exemplos.</p>

<div class="example">
<span id="exm:unnamed-chunk-2" class="example"><strong>Exemplo 2.1  </strong></span>
</div>

<p>Suponha que é razoável modelar o tempo de espera por atendimento em um banco por uma v.a. com distribuição exponencial, com média 10 min (isto é, <span class="math inline">\(\lambda = 1/10\)</span>).</p>
<ul>
<li><p>Qual a probabilidade de que um cliente espere por um tempo maior do que 15 min?</p></li>
<li><p>Qual a probabilidade de que um cliente espere por um tempo maior do que 15 min, dado que já está esperando há 10 min?</p></li>
</ul>

<div class="solution">
 <span class="solution"><em>Solução. </em></span> 
</div>

<p>Representamos o tempo que o cliente espera na fila do banco por uma v.a. <span class="math inline">\(X\)</span> com distribuição Exponencial. O tempo médio de espera é de 10 min, portanto o parâmetro <span class="math inline">\(\lambda\)</span> da distribuição vale 1/10.</p>
<p>Seja <span class="math inline">\(X\)</span> = tempo que o cliente espera na fila do banco<br />
<span class="math inline">\(X \sim Exp(\lambda = 1/10)\)</span>.</p>
<ul>
<li><p>Queremos <span class="math inline">\(P[X &gt; 15]\)</span>:<br />
<span class="math inline">\(P[X &gt; 15] = 1 - P[X \leq 15] = e^{-\lambda t} = e^{- 15/10} \approx 0.223\)</span><br />
Portanto, esta probabilidade é de aproximadamente 22,3%.</p></li>
<li><p>Queremos <span class="math inline">\(P[X &gt; 15 | X &gt; 10]\)</span>:<br />
<span class="math inline">\(P[X &gt; 15 | X &gt; 10] = P[X &gt; 10 + 5 | X &gt; 10] = P[X &gt; 5] = e^{-5\lambda}= e^{-5/10}\)</span> <span class="math inline">\(\approx 0.607\)</span></p></li>
</ul>
<p>Pela propriedade de ausência de memória, como a distribuição exponencial não se lembra de que o cliente já está esperando há 10 min, a probabilidade de que espere por pelo menos 5 min adicionais é igual à probabilidade de ele esperar pelo menos 5 min no momento em que entra no banco. Neste caso, a probabilidade desejada vale aproximadamente 60%.</p>
<p>Os comandos para obter esses valores de probabilidade utilizando o software R, são dados abaixo.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#cb44-1"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pexp</span>(<span class="dv">15</span>, <span class="dt">rate =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">10</span>)  </span>
<span id="cb44-2"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#cb44-2"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pexp</span>(<span class="dv">5</span>, <span class="dt">rate =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">10</span>)</span></code></pre></div>
<p>O próximo exemplo traz uma ilustração simples de aplicação de distribuição exponencial em confiabilidade.</p>

<div class="example">
<span id="exm:unnamed-chunk-5" class="example"><strong>Exemplo 3.3  </strong></span>
</div>

<p>Um sistema contém componentes cuja vida (em anos) é dada pela v.a. <span class="math inline">\(T\)</span>, que segue distribuição exponencial com média 5.</p>
<p>Se 5 desses componentes são instalados em diferentes sistemas, qual a probabilidade de que pelo menos 2 deles continuem funcionando ao final de 8 anos?</p>

<div class="solution">
 <span class="solution"><em>Solução. </em></span> 
</div>

<p>Sabemos que o tempo de falha de cada um dos componentes pode ser adequadamente modelado por uma va exponencial com média 5, de forma que a taxa de falha, <span class="math inline">\(\lambda\)</span> vale 1/5. Portanto, temos: <span class="math inline">\(T \sim Exp(\lambda = 1/5)\)</span>.</p>
<p>Em primeiro lugar, precisamos calcular a probabilidade de que a falha em um desses componentes ocorra após um período de 8 anos, isto é, precisamos calcular <span class="math inline">\(P[T \geq 8]\)</span>.</p>
<p>Para um componente:<br />
<span class="math inline">\(P[T \geq 8] = \frac{1}{5} \int_{8}^{\infty} e^{-t/5} dt = e^{8/5} \approx 0.2\)</span></p>
<p>Mas nós ainda não resolvemos o problema completamente… essa é apenas a probabilidade de que um componente dure pelo menos 8 anos!</p>
<p>Queremos a probabilidade de que pelo menos dois de um total de 5 desses componentes instalados em sistemas independentes durem pelo menos 8 anos. Ou seja, temos uma outra variável aleatória. Os sistemas são idênticos e funcionam de forma independente. Precisamos definir uma v.a. <span class="math inline">\(X\)</span> com distribuição binomial, com parâmetros <span class="math inline">\(n =5\)</span> (esse é o número de repetições do experimento de Bernoulli) e probabilidade de sucesso (que neste caso significa funcionar por pelo menos 8 anos) igual a 0,2. Portanto, a probabilidade desejada é <span class="math inline">\(P[X \geq 2]\)</span>.</p>
<p>Seja <span class="math inline">\(X=\)</span> número de componentes funcionando ao final de 8 anos<br />
<span class="math inline">\(X \sim Bin(n = 5, p = 0.2)\)</span></p>
<p><span class="math display">\[\begin{align*}
  P[X \geq 2] = \sum_{x=2}^{5}Bin(n=5, p=0.2)
              &amp;= 1- \sum_{x=0}^{1}Bin(n=5, p=0.2)\\
              &amp;= 1 - 0.7373 = 0.2627\\  
\end{align*}\]</span></p>
<p>A probabilidade de que pelo menos 2 dos 5 componentes instalados continuem funcionando ao final de 8 anos vale aproximadamente 26%.</p>
<p>Vejamos, agora, um outro exercício interessante que faz uso da propriedade de ausência de memória.</p>

<div class="example">
<span id="exm:unnamed-chunk-7" class="example"><strong>Exemplo 5.1  </strong></span>
</div>

<p>Em um pronto-atendimento oftalmológico há dois consultórios médicos e os pacientes podem ser atendidos por qualquer um dos dois plantonistas. Quando o paciente C chega até a clínica, descobre que os dois consultórios já estão ocupados, um pelo paciente A e o outro, pelo B. O paciente C é informado que será atendido assim que terminar a consulta de um dos pacientes A ou B.</p>
<p>Suponha que o tempo de duração de uma consulta seja uma v.a. com distribuição exponencial com média <span class="math inline">\(1/\lambda\)</span>.</p>
<p><em>Qual a probabilidade de que, dos três pacientes, C seja o último a deixar a clínica?</em></p>

<div class="solution">
 <span class="solution"><em>Solução. </em></span> 
</div>

<p>A resposta pode se obtida utilizando a propriedade de ausência de memória, seguindo este raciocínio: no momento em que um dos consultórios for liberado e o paciente C iniciar o atendimento, um dos outros dois pacientes A ou B, digamos B, terá deixado a clínica enquanto o paciente A ainda estará sendo atendido. No entanto, devido à propriedade de ausência de memória, o tempo remanescente de atendimento do paciente A tem distribuição exponencial com média <span class="math inline">\(1/\lambda\)</span>, independentemente do tempo que a consulta já durou. Ou seja, a situação aleatória se comporta como se o atendimento do paciente A tivesse acabado de iniciar, no mesmo instante em que o atendimento do paciente C foi iniciado. Sendo assim, a probabilidade de que o paciente A deixe a clínica antes do paciente C é de 50%.</p>
</div>
</div>
<div id="distribuição-gama" class="section level2">
<h2><span class="header-section-number">7.5</span> Distribuição Gama</h2>
<p>Assim como encontramos analogias entre a distribuição exponencial e a distribuição geométrica, em um processo de Poisson, a distribuição correspondente à binomial negativa no processo de Bernoulli é a distribuição Gama. Essa v.a. modela o tempo de espera até observar um certo número de ocorrências em um processo de Poisson.</p>
<p>Sendo assim, uma v.a. <span class="math inline">\(X\)</span> tem distribuição gama com parâmetros <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> em que <span class="math inline">\(\alpha\)</span> é o número de ocorrências desejadas (também chamado parâmetro de forma) e <span class="math inline">\(\beta\)</span> é o inverso da taxa de ocorrência do processo de Poisson (também chamado de parâmetro de escala). Por se tratar de um tempo de espera, a v.a. pode assumir valores reais não negativos, de acordo com fdp <span class="math inline">\(f_X(x)\)</span> abaixo.</p>
<p>Seja a v.a. <span class="math inline">\(X \sim Gama(\alpha, \beta)\)</span></p>
<p><span class="math inline">\(X =\)</span> tempo de espera até <span class="math inline">\(\alpha\)</span>-ésima ocorrência em um processo de Poisson</p>
<p><span class="math display">\[\begin{align*}
  &amp;{} f_{X}(x) = \left\{
  \begin{array}{rl}
    \frac{1}{\beta^\alpha\Gamma(\alpha)}x^{\alpha -1} e^{-x/\beta}, &amp; x \geq 0\\
    0,           &amp; c.c.
  \end{array}\right.
  \quad \alpha, \; \beta &gt; 0
  \\ \\
  &amp;{} E[X] = \alpha\beta \qquad Var[X] = \alpha\beta^2
\end{align*}\]</span></p>
<p><strong>OBS: Função Gama</strong>
<span class="math display">\[\Gamma(\alpha) = \int_{0}^{\infty} x^{\alpha -1} e^{-x} dx, \; \alpha &gt;0  \quad \textsf{ tq: } \quad \begin{array}{l}
    \alpha \in \mathcal{Z}^{+}: \Gamma(\alpha) = (\alpha-1)! \quad (\textsf{dist. Erlang})\\
    \Gamma(1/2) = \sqrt{\pi}
  \end{array}\]</span></p>
<p>A distribuição gama tem valor esperado <span class="math inline">\(\alpha \beta\)</span> (o mesmo que <span class="math inline">\(\alpha/\lambda\)</span> ) e variância <span class="math inline">\(\alpha \beta^2\)</span> (ou seja, <span class="math inline">\(\alpha/\lambda^2\)</span> ).
Obviamente, quando <span class="math inline">\(\alpha = 1\)</span>, temos a distribuição exponencial. Quando <span class="math inline">\(\alpha\)</span> é um número inteiro positivo, a distribuição resultante também é chamada de distribuição de Erlang, em referência ao engenheiro dinamarquês Agner Erlang (1878-1929), que deu contribuições pioneiras para o desenvolvimento da teoria de filas.</p>

<div class="example">
<span id="exm:unnamed-chunk-9" class="example"><strong>Exemplo 7.1  </strong></span>
</div>

<p>Suponha que chamadas chegando a uma central de atendimento sigam um processo de Poisson com taxa de 5 telefonemas por minuto.</p>
<p>Qual a probabilidade de que não mais que um minuto se passe até dois telefonemas sejam recebidos?</p>

<div class="solution">
 <span class="solution"><em>Solução. </em></span> 
</div>

<p>Seja <span class="math inline">\(X=\)</span> tempo até que 2 chamadas sejam recebidas.<br />
Temos uma va gama, com parâmetros <span class="math inline">\(\alpha = 2\)</span> e <span class="math inline">\(\beta = 1/\lambda = 1/5\)</span>.</p>
<p><span class="math inline">\(X \sim Gama(\alpha = 2, \beta = 1/\lambda = 1/5)\)</span></p>
<p><span class="math inline">\(P[X \leq 1] = \int_{0}^{1} \frac{1}{\beta^2}x e^{-x/\beta} dx = 25 \int_{0}^{1} x e^{-5x} dx = 1 - e^{-5}(1+5) = 0.96\)</span></p>
<p>Portanto, a probabilidade de que <span class="math inline">\(X\)</span> seja menor ou igual a 1 vale aproximadamente 96%. Este valor de probabilidade pode ser facilmente obtido com o auxílio do R, utilizando o código abaixo.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#cb45-1"></a><span class="kw">pgamma</span>(<span class="dv">1</span>, <span class="dt">shape =</span> <span class="dv">2</span>, <span class="dt">scale =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">5</span>)</span></code></pre></div>

<div class="example">
<span id="exm:unnamed-chunk-12" class="example"><strong>Exemplo 7.2  </strong></span>
</div>

<p>Vejamos agora uma aplicação da distribuição Gama a um problema de tomada de decisão:</p>
<p>Vamos supor que as reclamações de clientes a respeito de um certo produto sejam adequadamente modeladas de acordo com um processo de Poisson, de forma que o período entre duas reclamações sucessivas siga a distribuição gama com parâmetros <span class="math inline">\(\alpha = 1\)</span> e <span class="math inline">\(\beta = 4\)</span>. Isto nos daria uma expectativa de 4 meses até observar a primeira reclamação.</p>
<p>Não satisfeito com essa situação, o fabricante implementou modificações no controle de qualidade do processo de produção, de forma que, após essas modificações, a primeira reclamação ocorreu somente após 12 meses.</p>
<p>Antes que essa modificação seja implementada em outras plantas da empresa, é necessário determinar se este aparente aumento no tempo de espera até a primeira reclamação foi resultado das modificações no processo produtivo, ou seja, queremos saber se o novo controle de qualidade foi efetivo.</p>

<div class="solution">
 <span class="solution"><em>Solução. </em></span> 
</div>

<p>Antes de modelar o problema matematicamente, precisamos identificar que aspecto desse problema nos ajuda a tomar essa decisão.</p>
<p>Veja que estamos monitorando uma v.a. <span class="math inline">\(X\)</span>, que descreve o tempo de espera até a primeira reclamação.</p>
<p>Se o processo modificado for idêntico ao original, observaremos um tempo de espera de 12 meses com alta probabilidade; isso implica que o novo controle de qualidade não foi efetivo e que o processo é descrito pela distribuição Gama com parâmetros <span class="math inline">\(\alpha = 1\)</span> e <span class="math inline">\(\beta = 4\)</span>. Neste caso, podemos concluir que observar um tempo de espera de 12 meses é algo corriqueiro, que não estamos diante de uma situação incomum. Esta seria uma observação completamente compatível com o esperado para um processo como esse.</p>
<p>Por outro lado, se chegarmos à conclusão de que a probabilidade de observar a primeira reclamação após 12 meses é muito baixa, significa que estamos diante de uma de duas situações: (i) ou acabamos de presenciar a ocorrência de um evento raro; ou (ii) o processo não se comporta da maneira que imaginávamos, de forma que a distribuição que representava o comportamento aleatório não se aplica mais e, portanto, o novo controle de qualidade de fato, modificou o processo produtivo.</p>
<p>Portanto, precisamos calcular a probabilidade <span class="math inline">\(P[X \geq 12]\)</span> para que possamos chegar a uma conclusão.</p>
<p>Utilizando as informações apresentadas e, com o auxílio do software R (veja o código fornecido abaixo), obtemos um valor de probabilidade ligeiramente inferior a 5%.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#cb46-1"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pgamma</span>(<span class="dv">12</span>, <span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">scale =</span> <span class="dv">4</span>)</span></code></pre></div>
<p>Isso significa que, se o processo produtivo não tiver sido efetivamente modificado com a implantação do novo controle de qualidade, em cerca de 5% das vezes, observaremos um tempo de espera de 12 meses até a primeira reclamação.</p>
<p>Quão rara é essa situação? A resposta a essa pergunta depende do risco que estamos dispostos a correr ao tomar essa decisão. Se considerarmos que a probabilidade 5% é pequena o bastante para que essa situação não seja considerada corriqueira, então é razoável concluir que a mudança no controle de qualidade foi, de fato, efetiva.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="modelos-probabilísticos-distribuição-normal.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["apostila-GED13.pdf", "apostila-GED13.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
