<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 6 Modelos Probabilísticos: Distribuições Associadas a Processos de Bernoulli | GED-13: Probabilidade e Estatística</title>
  <meta name="description" content="Apostila do curso de GED-13: Probabilidade e Estatística." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 6 Modelos Probabilísticos: Distribuições Associadas a Processos de Bernoulli | GED-13: Probabilidade e Estatística" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Apostila do curso de GED-13: Probabilidade e Estatística." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 6 Modelos Probabilísticos: Distribuições Associadas a Processos de Bernoulli | GED-13: Probabilidade e Estatística" />
  
  <meta name="twitter:description" content="Apostila do curso de GED-13: Probabilidade e Estatística." />
  

<meta name="author" content="Prof. Denise Beatriz Ferrari" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="variáveis-aleatórias-e-distribuições.html"/>
<link rel="next" href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Probabilidade e Estatística</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Objetivos do Curso</a></li>
<li class="chapter" data-level="1" data-path="introdução.html"><a href="introdução.html"><i class="fa fa-check"></i><b>1</b> Introdução</a><ul>
<li class="chapter" data-level="1.1" data-path="introdução.html"><a href="introdução.html#estatística-e-o-raciocínio-científico"><i class="fa fa-check"></i><b>1.1</b> Estatística e o Raciocínio Científico</a></li>
<li class="chapter" data-level="1.2" data-path="introdução.html"><a href="introdução.html#o-que-é-estatística"><i class="fa fa-check"></i><b>1.2</b> O que é Estatística?</a></li>
<li class="chapter" data-level="1.3" data-path="introdução.html"><a href="introdução.html#o-papel-da-probabilidade-em-estatística"><i class="fa fa-check"></i><b>1.3</b> O Papel da Probabilidade em Estatística</a></li>
<li class="chapter" data-level="1.4" data-path="introdução.html"><a href="introdução.html#elementos-fundamentais-em-estatística"><i class="fa fa-check"></i><b>1.4</b> Elementos Fundamentais em Estatística</a><ul>
<li class="chapter" data-level="" data-path="introdução.html"><a href="introdução.html#população-e-amostra"><i class="fa fa-check"></i>População e Amostra</a></li>
<li class="chapter" data-level="" data-path="introdução.html"><a href="introdução.html#variáveis"><i class="fa fa-check"></i>Variáveis</a></li>
<li class="chapter" data-level="" data-path="introdução.html"><a href="introdução.html#dados-e-fontes-de-dados"><i class="fa fa-check"></i>Dados e Fontes de Dados</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introdução.html"><a href="introdução.html#tipos-de-problemas"><i class="fa fa-check"></i><b>1.5</b> Tipos de Problemas</a></li>
<li class="chapter" data-level="1.6" data-path="introdução.html"><a href="introdução.html#o-processo-de-análise-de-dados"><i class="fa fa-check"></i><b>1.6</b> O Processo de Análise de Dados</a></li>
<li class="chapter" data-level="1.7" data-path="introdução.html"><a href="introdução.html#métodos-para-exploração-resumo-e-descrição-de-dados"><i class="fa fa-check"></i><b>1.7</b> Métodos para Exploração, Resumo e Descrição de Dados</a><ul>
<li class="chapter" data-level="" data-path="introdução.html"><a href="introdução.html#análise-exploratória-de-dados-exploratory-data-analysis-eda"><i class="fa fa-check"></i>Análise Exploratória de Dados (“Exploratory Data Analysis”, EDA)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html"><i class="fa fa-check"></i><b>2</b> Introdução à Teoria de Probabilidades</a><ul>
<li class="chapter" data-level="2.1" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#breve-histórico"><i class="fa fa-check"></i><b>2.1</b> Breve Histórico</a><ul>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#chance-e-incerteza"><i class="fa fa-check"></i>Chance e Incerteza</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#jogos-de-azar"><i class="fa fa-check"></i>Jogos de Azar</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#origem-da-teoria-matemática-de-probabilidades"><i class="fa fa-check"></i>Origem da Teoria Matemática de Probabilidades</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#formalização-matemática"><i class="fa fa-check"></i>Formalização Matemática</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#definições-iniciais"><i class="fa fa-check"></i><b>2.2</b> Definições Iniciais</a><ul>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#experimento-aleatório"><i class="fa fa-check"></i>Experimento Aleatório</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#espaço-amostral-e-evento"><i class="fa fa-check"></i>Espaço Amostral e Evento</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#lei-de-probabilidade"><i class="fa fa-check"></i>Lei de Probabilidade</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#interpretações-de-probabilidade"><i class="fa fa-check"></i><b>2.3</b> Interpretações de Probabilidade</a><ul>
<li><a href="introdução-à-teoria-de-probabilidades.html#interpretação-clássica-a-priori-laplace-1812">Interpretação Clássica (<em>a priori</em>): Laplace, 1812</a></li>
<li><a href="introdução-à-teoria-de-probabilidades.html#interpretação-empírica-ou-de-frequência-relativa-a-posteriori-richard-v.-mises-1919">Interpretação Empírica ou de Frequência Relativa (<em>a posteriori</em>): Richard V. Mises, 1919</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#interpretação-subjetiva"><i class="fa fa-check"></i>Interpretação Subjetiva</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#resumo"><i class="fa fa-check"></i>Resumo</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#definição-axiomática"><i class="fa fa-check"></i><b>2.4</b> Definição Axiomática</a></li>
<li class="chapter" data-level="2.5" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#revisitando-o-paradoxo-de-de-méré-o-problema-dos-dados"><i class="fa fa-check"></i><b>2.5</b> Revisitando o Paradoxo de De Méré: O Problema dos Dados</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html"><i class="fa fa-check"></i><b>3</b> Probabilidade Condicional e Independência</a><ul>
<li class="chapter" data-level="3.1" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#probabilidade-condicional"><i class="fa fa-check"></i><b>3.1</b> Probabilidade Condicional</a><ul>
<li class="chapter" data-level="" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#propriedades"><i class="fa fa-check"></i>Propriedades</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#independência-de-eventos"><i class="fa fa-check"></i><b>3.2</b> Independência de Eventos</a><ul>
<li class="chapter" data-level="" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#propriedades-1"><i class="fa fa-check"></i>Propriedades</a></li>
<li class="chapter" data-level="" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#independência-condicional"><i class="fa fa-check"></i>Independência Condicional</a></li>
<li class="chapter" data-level="" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#eventos-independentes-x-eventos-mutuamente-exclusivos"><i class="fa fa-check"></i>Eventos Independentes x Eventos Mutuamente Exclusivos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="teoremas-fundamentais-da-probabilidade.html"><a href="teoremas-fundamentais-da-probabilidade.html"><i class="fa fa-check"></i><b>4</b> Teoremas Fundamentais da Probabilidade</a><ul>
<li class="chapter" data-level="4.1" data-path="teoremas-fundamentais-da-probabilidade.html"><a href="teoremas-fundamentais-da-probabilidade.html#teorema-da-probabilidade-total-dividir-para-conquistar"><i class="fa fa-check"></i><b>4.1</b> Teorema da Probabilidade Total: …dividir para conquistar!</a></li>
<li class="chapter" data-level="4.2" data-path="teoremas-fundamentais-da-probabilidade.html"><a href="teoremas-fundamentais-da-probabilidade.html#teorema-de-bayes-aprendendo-pela-experiência"><i class="fa fa-check"></i><b>4.2</b> Teorema de Bayes: …aprendendo pela experiência</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html"><i class="fa fa-check"></i><b>5</b> Variáveis Aleatórias e Distribuições</a><ul>
<li class="chapter" data-level="5.1" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#variáveis-aleatórias"><i class="fa fa-check"></i><b>5.1</b> Variáveis Aleatórias</a><ul>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#definição-caso-unidimensional"><i class="fa fa-check"></i>Definição (caso unidimensional)</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#tipos-de-variáveis-aleatórias"><i class="fa fa-check"></i>Tipos de Variáveis Aleatórias</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#distribuições-de-probabilidade"><i class="fa fa-check"></i><b>5.2</b> Distribuições de Probabilidade</a><ul>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#função-distribuição-de-probabilidade-fdp-caso-discreto"><i class="fa fa-check"></i>Função Distribuição de Probabilidade (fdp): caso discreto</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#função-distribuição-de-probabilidade-fdp-caso-contínuo"><i class="fa fa-check"></i>Função Distribuição de Probabilidade (fdp): caso contínuo</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#função-distribuição-acumulada-fda"><i class="fa fa-check"></i>Função Distribuição Acumulada (FDA)</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#valor-esperado-e-variância"><i class="fa fa-check"></i><b>5.3</b> Valor Esperado e Variância</a><ul>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#valor-esperado"><i class="fa fa-check"></i>Valor Esperado</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#o-problema-dos-pontos-e-a-aposta-de-pascal"><i class="fa fa-check"></i>O Problema dos Pontos e a Aposta de Pascal</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#variância"><i class="fa fa-check"></i>Variância</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#desvio-padrão"><i class="fa fa-check"></i>Desvio-padrão</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#momentos"><i class="fa fa-check"></i><b>5.4</b> Momentos</a><ul>
<li><a href="variáveis-aleatórias-e-distribuições.html#assimetria-skewness-e-excesso-kurtosis">Assimetria (<em>skewness</em>) e Excesso (<em>kurtosis</em>)</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#desigualdades-de-markov-e-chebyshev"><i class="fa fa-check"></i><b>5.5</b> Desigualdades de Markov e Chebyshev</a><ul>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#desigualdade-de-markov"><i class="fa fa-check"></i>Desigualdade de Markov</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#desigualdade-de-chebyshev"><i class="fa fa-check"></i>Desigualdade de Chebyshev</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><i class="fa fa-check"></i><b>6</b> Modelos Probabilísticos: Distribuições Associadas a Processos de Bernoulli</a><ul>
<li class="chapter" data-level="6.1" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#o-experimento-de-bernoulli"><i class="fa fa-check"></i><b>6.1</b> O Experimento de Bernoulli</a></li>
<li class="chapter" data-level="6.2" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-de-bernoulli"><i class="fa fa-check"></i><b>6.2</b> Distribuição de Bernoulli</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#resumo-2"><i class="fa fa-check"></i>Resumo</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-binomial"><i class="fa fa-check"></i><b>6.3</b> Distribuição Binomial</a></li>
<li class="chapter" data-level="6.4" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#um-problema-de-tomada-de-decisão"><i class="fa fa-check"></i><b>6.4</b> Um Problema de Tomada de Decisão</a></li>
<li class="chapter" data-level="6.5" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-geométrica"><i class="fa fa-check"></i><b>6.5</b> Distribuição Geométrica</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#propriedade-de-ausência-de-memória"><i class="fa fa-check"></i>Propriedade de Ausência de Memória</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#outras-distribuições"><i class="fa fa-check"></i><b>6.6</b> Outras Distribuições</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-binomial-negativa-ou-distribuição-de-pascal"><i class="fa fa-check"></i>Distribuição Binomial Negativa (ou Distribuição de Pascal)</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-multinomial"><i class="fa fa-check"></i>Distribuição Multinomial</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-multinomial-negativa"><i class="fa fa-check"></i>Distribuição Multinomial Negativa</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-hipergeométrica"><i class="fa fa-check"></i>Distribuição Hipergeométrica</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-hipergeométrica-negativa"><i class="fa fa-check"></i>Distribuição Hipergeométrica Negativa</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#resumo-4"><i class="fa fa-check"></i>Resumo</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><i class="fa fa-check"></i><b>7</b> Modelos Probabilísticos: Distribuições Associadas a Processos de Poisson</a><ul>
<li class="chapter" data-level="7.1" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#uma-aproximação-para-a-distribuição-binomial"><i class="fa fa-check"></i><b>7.1</b> Uma aproximação para a Distribuição Binomial</a></li>
<li class="chapter" data-level="7.2" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#distribuição-de-poisson"><i class="fa fa-check"></i><b>7.2</b> Distribuição de Poisson</a></li>
<li class="chapter" data-level="7.3" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#o-processo-de-poisson"><i class="fa fa-check"></i><b>7.3</b> O Processo de Poisson</a></li>
<li class="chapter" data-level="7.4" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#distribuição-exponencial"><i class="fa fa-check"></i><b>7.4</b> Distribuição Exponencial</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#propriedade-de-ausência-de-memória-1"><i class="fa fa-check"></i>Propriedade de Ausência de Memória</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#distribuição-de-weibull"><i class="fa fa-check"></i>Distribuição de Weibull:</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#distribuição-gama"><i class="fa fa-check"></i><b>7.5</b> Distribuição Gama</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html"><i class="fa fa-check"></i><b>8</b> Modelos Probabilísticos: Distribuição Normal</a><ul>
<li class="chapter" data-level="8.1" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#distribuição-normal"><i class="fa fa-check"></i><b>8.1</b> Distribuição Normal</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#mais-uma-aproximação-para-a-distribuição-binomial"><i class="fa fa-check"></i>…(Mais) Uma Aproximação para a Distribuição Binomial</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#cálculo-de-probabilidades"><i class="fa fa-check"></i>Cálculo de Probabilidades</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#padronização-1"><i class="fa fa-check"></i>Padronização</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#regra-empírica"><i class="fa fa-check"></i>Regra Empírica</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#coeficiente-de-variação"><i class="fa fa-check"></i>Coeficiente de Variação</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#aproximação-para-distribuições-discretas"><i class="fa fa-check"></i><b>8.2</b> Aproximação para Distribuições Discretas</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#aproximação-para-a-distribuição-binomial"><i class="fa fa-check"></i>Aproximação para a Distribuição Binomial</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#métodos-descritivos-para-avaliar-normalidade"><i class="fa fa-check"></i><b>8.3</b> Métodos Descritivos para Avaliar Normalidade</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html"><i class="fa fa-check"></i><b>9</b> Distribuições Amostrais</a><ul>
<li class="chapter" data-level="9.1" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#introdução-à-inferência-estatística"><i class="fa fa-check"></i><b>9.1</b> Introdução à Inferência Estatística</a><ul>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#inferência-estatística"><i class="fa fa-check"></i>Inferência Estatística</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#amostras-e-distribuições-amostrais"><i class="fa fa-check"></i><b>9.2</b> Amostras e Distribuições Amostrais</a><ul>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#amostra-aleatória"><i class="fa fa-check"></i>Amostra Aleatória</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#parâmetos-vs.-estatísticas"><i class="fa fa-check"></i>Parâmetos vs. Estatísticas</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-amostral"><i class="fa fa-check"></i>Distribuição Amostral</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-da-média-amostral"><i class="fa fa-check"></i><b>9.3</b> Distribuição da Média Amostral</a><ul>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#propriedades-da-média-amostral"><i class="fa fa-check"></i>Propriedades da Média Amostral</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#lei-dos-grandes-números"><i class="fa fa-check"></i>Lei dos Grandes Números</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#teorema-do-limite-central"><i class="fa fa-check"></i><b>9.4</b> Teorema do Limite Central</a></li>
<li class="chapter" data-level="9.5" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuições-amostrais-associadas-a-populações-normais"><i class="fa fa-check"></i><b>9.5</b> Distribuições Amostrais Associadas a Populações Normais</a><ul>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-qui-quadrado"><i class="fa fa-check"></i>Distribuição Qui-Quadrado</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-t-student"><i class="fa fa-check"></i>Distribuição t-Student</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#aproximando-distribuições-amostrais-via-simulação-de-monte-carlo"><i class="fa fa-check"></i><b>9.6</b> Aproximando Distribuições Amostrais via Simulação de Monte Carlo</a><ul>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-aproximada-da-mediana-amostral"><i class="fa fa-check"></i>Distribuição Aproximada da Mediana Amostral</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-aproximada-do-desvio-padrão-amostral"><i class="fa fa-check"></i>Distribuição Aproximada do Desvio-Padrão Amostral</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-aproximada-da-variância-amostral"><i class="fa fa-check"></i>Distribuição Aproximada da Variância Amostral</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-aproximada-do-mad-desvio-mediano-absoluto"><i class="fa fa-check"></i>Distribuição Aproximada do MAD (Desvio Mediano Absoluto)</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-aproximada-da-amplitude-inter-quartis-iqr"><i class="fa fa-check"></i>Distribuição Aproximada da Amplitude Inter-Quartis (IQR)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="estimação-pontual.html"><a href="estimação-pontual.html"><i class="fa fa-check"></i><b>10</b> Estimação Pontual</a><ul>
<li class="chapter" data-level="10.1" data-path="estimação-pontual.html"><a href="estimação-pontual.html#estimador-e-estimativa"><i class="fa fa-check"></i><b>10.1</b> Estimador e Estimativa</a></li>
<li class="chapter" data-level="10.2" data-path="estimação-pontual.html"><a href="estimação-pontual.html#propriedades-de-estimadores"><i class="fa fa-check"></i><b>10.2</b> Propriedades de Estimadores</a><ul>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#não-tendeciosidade-exatidão"><i class="fa fa-check"></i>Não-Tendeciosidade (exatidão)</a></li>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#eficiência-precisão"><i class="fa fa-check"></i>Eficiência (precisão)</a></li>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#consistência"><i class="fa fa-check"></i>Consistência</a></li>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#erro-médio-quadrático"><i class="fa fa-check"></i>Erro Médio Quadrático</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="estimação-pontual.html"><a href="estimação-pontual.html#métodos-clássicos-de-estimação-de-parâmetros"><i class="fa fa-check"></i><b>10.3</b> Métodos Clássicos de Estimação de Parâmetros</a><ul>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#método-dos-momentos"><i class="fa fa-check"></i>Método dos Momentos</a></li>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#método-da-máxima-verossimilhança"><i class="fa fa-check"></i>Método da Máxima Verossimilhança</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="intervalos-de-confiança.html"><a href="intervalos-de-confiança.html"><i class="fa fa-check"></i><b>11</b> Intervalos de Confiança</a><ul>
<li class="chapter" data-level="11.1" data-path="intervalos-de-confiança.html"><a href="intervalos-de-confiança.html#estimação-por-intervalos"><i class="fa fa-check"></i><b>11.1</b> Estimação por Intervalos</a></li>
<li class="chapter" data-level="11.2" data-path="intervalos-de-confiança.html"><a href="intervalos-de-confiança.html#procedimento-para-construção-de-ics"><i class="fa fa-check"></i><b>11.2</b> Procedimento para Construção de IC’s</a><ul>
<li><a href="intervalos-de-confiança.html#caso-1-ic-para-mu-com-sigma2-conhecida">CASO 1: IC para <span class="math inline">\(\mu\)</span> com <span class="math inline">\(\sigma^2\)</span> conhecida</a></li>
<li><a href="intervalos-de-confiança.html#caso-2.1-ic-para-mu-com-sigma2-desconhecida">CASO 2.1: IC para <span class="math inline">\(\mu\)</span> com <span class="math inline">\(\sigma^2\)</span> desconhecida</a></li>
<li><a href="intervalos-de-confiança.html#caso-2.2-ic-para-mu-com-sigma2-desconhecida-amostras-grandes">CASO 2.2: IC para <span class="math inline">\(\mu\)</span> com <span class="math inline">\(\sigma^2\)</span> desconhecida (amostras grandes)</a></li>
<li><a href="intervalos-de-confiança.html#caso-3-ic-para-p-proporção-populacional">CASO 3: IC para <span class="math inline">\(p\)</span> (proporção populacional)</a></li>
<li><a href="intervalos-de-confiança.html#caso-3-ic-para-sigma2">CASO 3: IC para <span class="math inline">\(\sigma^2\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html"><i class="fa fa-check"></i><b>12</b> Testes de Hipóteses</a><ul>
<li class="chapter" data-level="12.1" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#formulação-de-hipóteses-estatísticas"><i class="fa fa-check"></i><b>12.1</b> Formulação de Hipóteses Estatísticas</a></li>
<li class="chapter" data-level="12.2" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#estatística-do-teste"><i class="fa fa-check"></i><b>12.2</b> Estatística do Teste</a></li>
<li class="chapter" data-level="12.3" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#erros-de-decisão"><i class="fa fa-check"></i><b>12.3</b> Erros de Decisão</a></li>
<li class="chapter" data-level="12.4" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#região-crítica"><i class="fa fa-check"></i><b>12.4</b> Região Crítica</a></li>
<li class="chapter" data-level="12.5" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#valor-p"><i class="fa fa-check"></i><b>12.5</b> Valor-p</a></li>
<li class="chapter" data-level="" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#qual-a-probabilidade-de-cometer-erro-do-tipo-ii"><i class="fa fa-check"></i>Qual a probabilidade de cometer erro do tipo II?</a></li>
<li class="chapter" data-level="12.6" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#poder-do-teste"><i class="fa fa-check"></i><b>12.6</b> Poder do Teste</a></li>
<li class="chapter" data-level="12.7" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#resumo-gráfico"><i class="fa fa-check"></i><b>12.7</b> Resumo Gráfico</a></li>
<li class="chapter" data-level="12.8" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#testes-mono--e-bi-caudais"><i class="fa fa-check"></i><b>12.8</b> Testes Mono- e Bi-Caudais</a><ul>
<li class="chapter" data-level="" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#região-de-rejeição-para-um-teste-bi-caudal"><i class="fa fa-check"></i>Região de Rejeição para um Teste Bi-caudal</a></li>
</ul></li>
<li class="chapter" data-level="12.9" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#procedimento-para-testes-de-hipóteses-utilizando-o-nível-de-significância"><i class="fa fa-check"></i><b>12.9</b> Procedimento para Testes de Hipóteses (utilizando o nível de significância)</a></li>
<li class="chapter" data-level="12.10" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#procedimento-para-testes-de-hipóteses-utilizando-valor-p"><i class="fa fa-check"></i><b>12.10</b> Procedimento para Testes de Hipóteses (utilizando valor-p)</a></li>
<li class="chapter" data-level="12.11" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#ic-vs-th"><i class="fa fa-check"></i><b>12.11</b> IC vs TH</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">GED-13: Probabilidade e Estatística</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli" class="section level1">
<h1><span class="header-section-number">Capítulo 6</span> Modelos Probabilísticos: Distribuições Associadas a Processos de Bernoulli</h1>
<p>Consideraremos alguns modelos probabilísticos que merecem uma atenção especial. Algumas distribuições aparecem frequentemente em aplicações, por dois motivos:</p>
<ol style="list-style-type: decimal">
<li><p>ou porque o mecanismo probabilístico que define o problema em análise é tal que uma dessas distribuições é, de fato, a distribuição que descreve a situação de interesse; ou,</p></li>
<li><p>o problema em análise é tal que pode ser adequadamente modelado por uma dessas distribuições (neste caso, o modelo matemático nos dá uma boa aproximação da situação em questão).</p></li>
</ol>
<p>Iniciaremos estudando algumas distribuições associadas aos chamados processos de Bernoulli, que talvez sejam um dos processos aleatórios mais simples.</p>
<div id="o-experimento-de-bernoulli" class="section level2">
<h2><span class="header-section-number">6.1</span> O Experimento de Bernoulli</h2>
<p>Os processos de Bernoulli são construídos com base em experimentos de Bernoulli. Já encontramos esses experimentos e processos anteriormente, mas ainda não tínhamos dado um nome a eles.</p>
<p>Um experimento de Bernoulli consiste em um experimento aleatório que tem apenas dois resultados possíveis que, por conveniência rotulamos de “sucesso” ou “fracasso”. Como eles são mutuamente exclusivos e coletivamente exaustivos, formam uma partição do espaço amostral. Sucesso ocorre com probabilidade <span class="math inline">\(p\)</span> e, portanto, fracasso (o complementar de sucesso) ocorre com probabilidade <span class="math inline">\(1-p\)</span>.</p>
<p><strong>Experimento de Bernoulli:</strong></p>
<ul>
<li><p>Dois possíveis resultados (mutuamente exclusivos):<br />
<span class="math inline">\(S =\)</span> “sucesso” e <span class="math inline">\(F=\)</span> “fracasso”<br />
Espaço amostral: <span class="math inline">\(\Omega = \{ S, F\}\)</span></p></li>
<li><p>Define-se: <span class="math inline">\(P[S] = p\)</span>, <span class="math inline">\(P[F]= 1-p\)</span></p></li>
</ul>
<p>Obviamente, os rótulos “sucesso” e “fracasso” não necessariamente estão associados a acontecimentos bons ou ruins; temos um sucesso quando observamos a ocorrência do evento de interesse.</p>
<p>O lançamento de uma moeda é um exemplo: posso considerar sucesso, a ocorrência do resultado “cara”. A administração de uma vacina a um paciente é outro exemplo: sucesso pode denotar a imunização do paciente.</p>
<ul>
<li><p>Lançamento de uma moeda:<br />
<span class="math inline">\(S =\)</span> cara, <span class="math inline">\(F =\)</span> coroa</p></li>
<li><p>Administração de uma vacina:<br />
<span class="math inline">\(S =\)</span> paciente imunizado, <span class="math inline">\(F =\)</span> paciente não imunizado</p></li>
</ul>
</div>
<div id="distribuição-de-bernoulli" class="section level2">
<h2><span class="header-section-number">6.2</span> Distribuição de Bernoulli</h2>
<p>Em vez de utilizar a notação de eventos, que emprega os rótulos “sucesso” e “fracasso” para representar os resultados do experimento de Bernoulli, podemos utilizar uma variável aleatória para modelar essa situação. A v.a. resultante, então, terá distribuição de Bernoulli.</p>
<p>Uma v.a. <span class="math inline">\(X\)</span> tem distribuição de Bernoulli com parâmetro <span class="math inline">\(p\)</span> se assumir valores 0 ou 1, com probabilidade dada pela fdp <span class="math inline">\(f_X(x)\)</span> abaixo.</p>
<p>Seja a v.a. <span class="math inline">\(X \sim Ber(p)\)</span>:</p>
<p><span class="math inline">\(X =\)</span> resultado do experimento de Bernoulli</p>
<p><span class="math display">\[\begin{align*}
  &amp;{} f_{X}(x) = \left\{
  \begin{array}{rl}
    p^x q^{1-x}, &amp; x=0, 1\\
    0,           &amp; c.c.
  \end{array}\right.
  \quad 0 \leq p \leq 1; \quad q=1-p\\ 
  \\
  &amp;{} E[X] = p \qquad Var[X] = pq
\end{align*}\]</span></p>
<p>Note que quando <span class="math inline">\(x=0\)</span>, <span class="math inline">\(f_X(x) = q = 1-p\)</span>; e, quando <span class="math inline">\(x=1\)</span>, <span class="math inline">\(f_X(x)= p\)</span>, em que <span class="math inline">\(p\)</span> é a probabilidade de sucesso e assume qualquer valor real entre 0 e 1; e <span class="math inline">\(q\)</span> é probabilidade de fracasso.</p>
<p>É possível mostrar que o valor esperado desta v.a. é <span class="math inline">\(p\)</span> e que a variância vale <span class="math inline">\(pq\)</span>.</p>
<ul>
<li>Muitos modelos probabilísticos importantes são baseados na regra de Bernoulli.</li>
<li>Uma sequência de experimentos de Bernoulli independentes constituem um <strong>Processo de Bernoulli</strong>.</li>
</ul>
<p>Apesar de sua simplicidade, processos de Bernoulli podem ser utilizados para representar processos aleatórios interessantes, como veremos a seguir.</p>

<div class="example">
<span id="exm:unnamed-chunk-1" class="example"><strong>Exemplo 1.1  </strong></span>
</div>

<p>Vamos considerar a seguinte situação… completamente fictícia, claro!</p>
<p>Um aluno realizará um teste que consiste em 10 questões de múltipla escolha, cada uma com 4 opções, das quais apenas uma é correta. O aluno é aprovado no curso se responder pelo menos 6 questões corretamente.</p>
<p>Só que tem um problema: o aluno esqueceu que tinha de fazer esta prova e está completamente despreparado para o exame e decide apelar para a sorte, ou seja, vai escolher as respostas de maneira completamente aleatória, de forma que a resposta escolhida a uma determinada questão não tem relação com as demais.</p>
<p>Se o aluno adotar essa estratégia desesperada, qual a probabilidade de que ele passe no curso?</p>

<div class="solution">
 <span class="solution"><em>Solução. </em></span> 
</div>

<p>Em primeiro lugar, precisamos identificar a variável aleatória associada a este experimento. Note que a resposta a cada questão consiste em um experimento de Bernoulli, já que o aluno pode marcar a resposta certa (o que equivale a obter sucesso) ou a resposta errada (obtendo, assim, um fracasso). Desta forma, resposta a cada questão pode ser, então modelada por uma v.a. <span class="math inline">\(X_i\)</span>, que tem distribuição de Bernoulli. <span class="math inline">\(X_i\)</span> assume valor 1, se a resposta à questão <span class="math inline">\(i\)</span> é correta; e 0, se a resposta à questão <span class="math inline">\(i\)</span> é errada. A probabilidade de o aluno acertar a resposta de cada uma das questões é sempre a mesma e vale 1/4.</p>
<p>A resposta a cada uma das questões corresponde a um experimento de Bernoulli. Então, para <span class="math inline">\(i = 1, 2, \ldots, 10\)</span>, sejam as v.a.’s:</p>
<p><span class="math display">\[\begin{align*}
X_i = \left\{
  \begin{array}{rl}
    1, &amp; \text{se a i-ésima resposta está correta}\\
    0, &amp; \text{se a i-ésima resposta está errada}
  \end{array}\right.
\end{align*}\]</span></p>
<p>Ainda: <span class="math inline">\(P[X_i = 1] = p = 1/4\)</span>, para <span class="math inline">\(i = 1, 2, \ldots, 10\)</span>.</p>
<p>Mas não estamos interessados em saber se o aluno acertou ou errou cada uma das questões. Estamos interessados no resultado acumulado dos acertos; ou seja, no total de respostas corretas. Portanto, precisamos definir a v.a. que equivale ao total de respostas corretas:</p>
<p><span class="math inline">\(X =\)</span> total de respostas corretas<br />
<span class="math display">\[X = \sum_{i=1}^{10}X_i = k, \quad k = 0, 1, 2, \ldots, 10\]</span></p>
<p>Então, <span class="math inline">\(X\)</span> é igual à soma dos resultados de cada uma das v.a.’s <span class="math inline">\(X_i\)</span>. E esta soma pode assumir um valor <span class="math inline">\(k\)</span> igual a zero, ou 1 ou 2, e assim por diante até 10, correspondendo ao número de acertos no total das 10 questões.</p>
<p>Queremos calcular a probabilidade de que o número de acertos no teste seja maior ou igual a 6: <span class="math inline">\(P[X \geq 6]\)</span></p>
<p>Para calcular esta probabilidade, precisamos seguir o procedimento usual que consiste em calcular a probabilidade de obter cada um dos valores possíveis para a v.a. <span class="math inline">\(X\)</span> (isto é, vamos construir a fdp de <span class="math inline">\(X\)</span>) e, a partir, daí, calcularemos a probabilidade do evento de interesse.</p>
<p>A probabilidade de nenhum acerto corresponde à probabilidade de que a v.a. <span class="math inline">\(X\)</span> assuma valor igual a zero. Isso significa que o aluno errou conjuntamente todas as questões; então cada uma das v.a.’s <span class="math inline">\(X_i\)</span> vai assumir valor zero. Como as respostas para cada questão são dadas de maneira independente, a probabilidade conjunta é igual ao produto das probabilidades individuais. A probabilidade de responder incorretamente a uma questão qualquer é a probabilidade de fracasso, que vale <span class="math inline">\(1-p\)</span>. E assim, chega-se à conclusão de que a probabilidade de o aluno errar todas as questões vale <span class="math inline">\((1-p)^{10}\)</span> que é igual a <span class="math inline">\((3/4)^{10}\)</span>:</p>
<p><span class="math display">\[\begin{align*}
P[X=0]   &amp;= \text{probabilidade de nenhuma resposta correta}\\
         &amp;= P[X_1 = 0, X_2 = 0, \ldots, X_{10}=0],  &amp; \textsf{(sob indep.)} \\
         &amp;= P[X_1 = 0]\cdot P[X_2 = 0]\cdot \ldots \cdot P[X_{10} = 0]\\
         &amp;= (1-p)^{10} = \left(3/4\right)^{10}
\end{align*}\]</span></p>
<p>Vamos calcular agora a probabilidade de marcar apenas uma resposta correta. Precisamos enumerar todas as maneiras de acertar apenas uma resposta, ao responder a 10 questões. Isso significa que ou o aluno acertou apenas a resposta da primeira questão (e errou todas as outras), ou acertou apenas a resposta da segunda questão, e assim por diante, até a última situação possível que corresponde ao aluno ter errado todas as questões, exceto a última. Para cada uma dessas situações, temos um sucesso e 9 fracasso, portanto, cada situação acontece com probabilidade <span class="math inline">\(p \times (1-p)^9\)</span>.</p>
<p>Como existem 10 situações em que apenas um sucesso ocorre, a probabilidade de apenas um acerto em 10 tentativas vale <span class="math inline">\(p \times (1-p)^9 \times 10\)</span>.</p>
<p><span class="math display">\[\begin{align*}
P[X=1]   &amp;= \textsf{probabilidade de apenas uma resposta correta}\\
         &amp;= P[X_1 = 1]\cdot P[X_2 = 0]\cdot \ldots \cdot P[X_{10} = 0]\\
         &amp;+ P[X_1 = 0]\cdot P[X_2 = 1]\cdot \ldots \cdot P[X_{10} = 0]\\
         &amp; \vdots\\
         &amp;+ P[X_1 = 0]\cdot P[X_2 = 0]\cdot \ldots \cdot P[X_{10} = 1]\\
         &amp;= p \cdot (1-p)^9 \cdot 10 = (1/4)\left(3/4\right)^{9}\cdot 10
\end{align*}\]</span></p>
<p>Vamos aplicar o mesmo procedimento para 2 acertos, 3 acertos e assim, sucessivamente.</p>
<p>Sendo assim, a probabilidade de um total de ‘k’ respostas corretas, é dada pela expressão a seguir:</p>
<p><span class="math display">\[\begin{align*}
P[X=k] &amp;= \textsf{probabilidade de exatamente k respostas corretas}\\
       &amp;= {\binom{10}{k}}p^k (1-p)^{10-k}
\end{align*}\]</span></p>
<p>Há diversas maneiras de acertar apenas <span class="math inline">\(k\)</span> questões de um total de 10. Em todas as situações temos <span class="math inline">\(k\)</span> sucessos e <span class="math inline">\(10-k\)</span> fracassos; portanto, a probabilidade de observar cada uma dessas situações vale <span class="math inline">\(p^k \times (1-p)^{10-k}\)</span>; e o número de situações em que <span class="math inline">\(k\)</span> acertos ocorrem em 10 tentativas é dado pela combinação de 10 k-a-k.</p>
<p>Calculando para <span class="math inline">\(k \geq 6\)</span>, precisamos somar as probabilidades de obter ou 6 ou 7 ou 8 ou 9 ou 10 acertos. Essa probabilidade vale:</p>
<p><span class="math display">\[\begin{align*}
P[X\geq 6] &amp;= \textsf{probabilidade de pelo menos 6 respostas corretas}\\
           &amp;= \sum_{k=6}^{10}{\binom{10}{k}}(1/4)^k\left(3/4\right)^{10-k}\\
         &amp;= 0,0197 \quad \approx 2\% \;!!!
\end{align*}\]</span></p>
<p>Então, para a infelicidade deste aluno, chegamos à triste conclusão de que ele tem um pouco menos que 2% de chance de passar no curso, se responder de maneira aleatória a cada uma das questões! Não parece ser uma boa estratégia deixar o resultado da avaliação nas mãos do acaso!</p>
<div id="resumo-2" class="section level3 unnumbered">
<h3>Resumo</h3>
<p>Um processo de Bernoulli consiste em uma sequência finita ou infinita de experimentos de Bernoulli tal que cada experimento produz um sucesso com probabilidade <span class="math inline">\(p\)</span> e fracasso, com probabilidade <span class="math inline">\(1-p\)</span>’, independentemente do que ocorre nas outras repetições do experimento.</p>
<p>Então, basicamente temos usa sequência de resultados binários aleatórios independentes e estacionários.</p>
<ul>
<li><p>Um experimento de Bernoulli é repetido um certo número de vezes</p></li>
<li><p>Dois resultados possíveis em cada repetição:<br />
S = “sucesso” F = “fracasso”</p></li>
<li><p>Hipótese de Independência</p></li>
<li><p>Hipótese de Estacionariedade<br />
<span class="math inline">\(P[S]= p =\)</span> constante para todos os experimentos</p></li>
</ul>
<p>Podemos estar interessados em diferentes aspectos associados a um processo aleatório de Bernoulli. Cada aspecto pode ser analisado através da definição de uma v.a. aleatória que represente a situação de interesse. Por exemplo, podemos querer responder à pergunta de quantos sucessos serão observados em um determinado número de repetições do experimento de Bernoulli; ou, podemos querer determinar quantos experimentos são necessários a fim de obter um sucesso; ou <span class="math inline">\(k\)</span> sucessos; ou, ainda, podemos estar interessados em determinadas probabilidades condicionais que ocorrem em um processo de Bernoulli. A partir daí, podemos generalizar para situações em que o experimento aleatório tem mais do que dois resultados possíveis.</p>
</div>
</div>
<div id="distribuição-binomial" class="section level2">
<h2><span class="header-section-number">6.3</span> Distribuição Binomial</h2>
<p>A distribuição binomial é, sem dúvida, uma das distribuições discretas mais importantes.</p>
<p>A v.a. <span class="math inline">\(X\)</span> tem distribuição binomial com parâmetros <span class="math inline">\(n\)</span> e <span class="math inline">\(p\)</span> se
representa o número de sucessos em <span class="math inline">\(n\)</span> replicações de um experimento de Bernoulli, em que a probabilidade de observar sucesso em cada experimento vale <span class="math inline">\(p\)</span>.</p>
<p>A fdp da v.a. <span class="math inline">\(X\)</span> é dada pela expressão abaixo. A validade desta função para respresentar a probabilidade desejada pode ser verificada notando-se que cada sequência de resultados com <span class="math inline">\(x\)</span> sucessos no total de <span class="math inline">\(n\)</span> tentativas independentes ocorre com probabilidade <span class="math inline">\(p^x \times q^{n-x}\)</span>; esse valor de probabilidade é multiplicado pelo número de tais sequências possíveis, dado pela combinação de <span class="math inline">\(n\)</span> x-a-x.</p>
<p>Seja a v.a. <span class="math inline">\(X \sim \mathit{Bin} (n,p)\)</span>:</p>
<p><span class="math inline">\(X =\)</span> número de sucessos em um processo de Bernoulli</p>
<p><span class="math display">\[\begin{align*}
  &amp;{} f_{X}(x) = \left\{
  \begin{array}{rl}
    \binom{n}{x}p^x q^{n-x}, &amp; x = 0, 1, \ldots, n\\
    0,           &amp; c.c.
  \end{array}\right.
  \quad 0 \leq p \leq 1; \quad q=1-p \\
  \\ \\
  &amp;{} E[X] = np \qquad Var[X] = npq
\end{align*}\]</span></p>
<p>A v.a. <span class="math inline">\(X\)</span> pode assumir qualquer valor inteiro de 0 até o número de experimentos de Bernoulli, <span class="math inline">\(n\)</span>. Como a fdp de uma v.a. Binomial depende apenas dos valores assumidos pelos parâmetros <span class="math inline">\(n\)</span> e <span class="math inline">\(p\)</span>, é de se esperar que sua média e variância também dependam apenas dos valores que esses parâmetros assumem. De fato, o valor esperado de <span class="math inline">\(X\)</span> é dado <span class="math inline">\(np\)</span>, isto é, o número esperado de sucessos esperados em <span class="math inline">\(n\)</span> experimentos de Bernoulli independentes, quando cada sucesso ocorre com probabilidade <span class="math inline">\(p\)</span> é igual a <span class="math inline">\(np\)</span>. A variância de <span class="math inline">\(X\)</span> vale <span class="math inline">\(npq\)</span>.</p>
<p>Vejamos um exemplo.</p>

<div class="example">
<span id="exm:unnamed-chunk-3" class="example"><strong>Exemplo 3.1  </strong></span>
</div>

<p>Se a probabilidade de um paciente se recuperar de uma doença grave for de 40% e tivermos o conhecimento de 15 pacientes portadores dessa doença, podemos estar interessados em obter algumas respostas, tais como</p>
<ul>
<li>qual a probabilidade de que exatamente 5 dos 15 pacientes sejam curados; ou</li>
<li>qual a probabilidade de que pelo menos 10 deles sobrevivam; ou</li>
<li>qual a probabilidade de que de 2 a 10 pacientes se recuperem.</li>
</ul>
<p>Note que, se pudermos assumir que a resposta de cada paciente ao tratamento da doença seja independente dos demais e que a probabilidade de recuperação seja a mesma para todos os pacientes, estamos diante de um processo de Bernoulli com parâmetros <span class="math inline">\(n = 15\)</span> e <span class="math inline">\(p = 0,4\)</span>.</p>
<p>Podemos então utilizar a distribuição Binomial para calcular essas probabilidades de maneira exata. E vamos comparar este resultado exato com aquele que seria obtido de maneira aproximada utilizando a desigualdade de Chebyshev.</p>

<div class="solution">
 <span class="solution"><em>Solução. </em></span> 
</div>

<p>Temos: <span class="math inline">\(X \sim \textsf{Bin}(n,p)\)</span>, onde n = 15 (pacientes); p = 0,4 (probabilidade de cura).</p>
<ul>
<li>P[exatamente 5 pacientes serem curados]:</li>
</ul>
<p>Para responder à primeira questão, basta calcular o valor da fdp de <span class="math inline">\(X\)</span> no ponto <span class="math inline">\(X = 5\)</span>:</p>
<p><span class="math display">\[\begin{align*}
  P[X = 5] = \textsf{Bin}(5; 15; 0,4)  = \binom{15}{5}0,4^5 0,6^{10} = 0,1859
\end{align*}\]</span></p>
<p>Sendo assim, a probabilidade de que exatamente 5 dos 15 pacientes sejam curados vale aproximadamente 19%.</p>
<p>Esse valor de probabilidade pode ser facilmente calculado no R, utilizando o comando dado abaixo:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#cb41-1"></a><span class="kw">dbinom</span>(<span class="dv">5</span>, <span class="dv">15</span>, <span class="fl">0.4</span>)</span></code></pre></div>
<ul>
<li>P[pelo menos 10 pacientes sobreviverem]:</li>
</ul>
<p>Para a segunda questão, queremos a probabilidade de observar pelo menos 10 pacientes recuperados. Essa probabilidade pode ser obtida calculando a soma das probabilidades de observar de 10 a 15 sucessos ou, alternativamente, utilizando a noção de complementar, como 1 - probabilidade de observar menos que 10 recuperações, que corresponde à soma das probabilidades de observar apenas de 0 a 9 sucessos. A probabilidade desejada é de aproximadamente 3%:</p>
<p><span class="math display">\[\begin{align*}
  P[X \geq 10] &amp;= 1 - P[X &lt; 10] \\
               &amp;= \sum_{x=10}^{15}\textsf{Bin}(x; 15, 0,4) = 1 - \sum_{x=0}^{9}\textsf{Bin}(x; 15, 0,4) \\
               &amp;= 1 - 0,9662 = 0,0338
\end{align*}\]</span></p>
<p>No R, essa probabilidade pode ser obtida utilizando os seguintes comandos:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#cb42-1"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pbinom</span>(<span class="dv">9</span>, <span class="dv">15</span>, <span class="fl">0.4</span>)  </span>
<span id="cb42-2"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#cb42-2"></a><span class="kw">sum</span>(<span class="kw">dbinom</span>(<span class="dv">10</span><span class="op">:</span><span class="dv">15</span>, <span class="dv">15</span>, <span class="fl">0.4</span>))</span></code></pre></div>
<ul>
<li>P[2 a 10 pacientes se recuperarem]:</li>
</ul>
<p>Finalmente, a terceira pergunta envolve o cálculo da probabilidade de que a v.a. <span class="math inline">\(X\)</span> assuma um valor de 2 a 10. Novamente, podemos calcular essa probabilidade como sendo a soma das probabilidades de observar <span class="math inline">\(X\)</span> assumindo valores de 2 a 10, ou podemos utilizar a definição de FDA e calcular essa probabilidade como sendo a diferença entre o valor da FDA para <span class="math inline">\(X=10\)</span> e o valor da FDA para <span class="math inline">\(X=1\)</span>. A probabilidade desejada vale aproximadamente 99%:</p>
<p><span class="math display">\[\begin{align*}
  P[2 \leq X \leq 10] 
  &amp;= \sum_{x=2}^{10}\textsf{Bin}(x; 15, 0,4) 
   = \sum_{x=0}^{10}\textsf{Bin}(x; 15, 0,4) - \sum_{x=0}^{1}\textsf{Bin}(x; 15, 0,4)\\
  &amp;= 0,9907 - 0,0052 = 0,9855
\end{align*}\]</span></p>
<p>Os comandos utilizados para obter esse valor de probabilidade no R são disponibilizados abaixo.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#cb43-1"></a><span class="kw">sum</span>(<span class="kw">dbinom</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">10</span>, <span class="dv">15</span>, <span class="fl">0.4</span>))</span>
<span id="cb43-2"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#cb43-2"></a><span class="kw">pbinom</span>(<span class="dv">10</span>, <span class="dv">15</span>, <span class="fl">0.4</span>) <span class="op">-</span><span class="st"> </span><span class="kw">pbinom</span>(<span class="dv">1</span>, <span class="dv">15</span>, <span class="fl">0.4</span>)</span></code></pre></div>
<p>Agora, vamos comparar o valor de probabilidade para a última pergunta que foi obtido de maneira exata utilizando a distribuição binomial com o limite que seria definido pela desigualdade de Chebyshev, se não fosse possível utilizar a informação da distribuição da v.a. considerada.</p>
<p>A desigualdade de Chebyshev faz uso do valor esperado e da variância da v.a. Sendo assim, utilizando as propriedades da distribuição binomial o valor esperado de <span class="math inline">\(X\)</span> é dado por <span class="math inline">\(np = 6\)</span>; e a variância vale <span class="math inline">\(npq = 3,6\)</span>. Um intervalo de largura igual a 4 desvios em torno da média, nos dá de 2 a 10 pacientes (já que a v.a. em questão é discreta). Assim, para <span class="math inline">\(X\)</span> a uma distância máxima de dois desvios de sua média, a desigualdade de Chebyshev nos dá o limite inferior de 75% de chance de observar de 2 a 10 pacientes recuperados:</p>
<p><span class="math inline">\(\mu = np = 15 \cdot 0,4 = 6\)</span>;<br />
<span class="math inline">\(\sigma^2 = npq = 15 \cdot 0,4 \cdot 0,6 = 3,6 \Rightarrow \sigma = 1,897\)</span></p>
<p>Consideremos o intervalo: <span class="math inline">\(\mu \pm 2\sigma\)</span> = <span class="math inline">\((2.206, 9.794) \rightarrow (2, 10)\)</span> : dados discretos.</p>
<p><strong>Pela Desigualdade de Chebyshev:</strong></p>
<p>A desigualdade de Chebyshev garante que há pelo menos 75% (3/4) de chance de que 2 a 10 dos 15 pacientes sobrevivam.</p>
</div>
<div id="um-problema-de-tomada-de-decisão" class="section level2">
<h2><span class="header-section-number">6.4</span> Um Problema de Tomada de Decisão</h2>
<p>Em geral, usamos distribuições de probabilidade para decidir se uma determinada hipótese é ou não plausível. Nós retornaremos a este assunto mais formalmente em inferência estatística, mas por hora, vejamos um outro exemplo, em que os valores de probabilidade calculados a partir da distribuição binomial são utilizados para auxiliar o processo de tomada de decisão.</p>
<p>Vamos supor que exista uma vacina para um determinado vírus, cuja eficácia seja de apenas 25%. Porém dada a alta transmissibilidade da doença, essa eficácia é insuficiente para conter uma epidemia.</p>
<p>Uma nova vacina é oferecida ao Ministério da Saúde (MS) e é preciso decidir se vale a pena comprar a nova vacina.</p>
<p>Vamos assumir ainda que, segundo recomendações técnicas, se a vacina tiver eficácia de pelo menos 30%, pode comprar a nova vacina; e, se ela tiver eficácia maior ou igual a 50%, não pode perder a oportunidade de adquirir a nova vacina.</p>
<p>Portanto, antes de mais nada, precisamos determinar se a nova vacina é mais eficaz contra o mesmo vírus que a vacina disponível… Para isso, precisamos coletar evidências empíricas, ou seja, precisamos de dados.</p>
<p>Uma amostra aleatória de <span class="math inline">\(n = 20\)</span> voluntários é selecionada e são observados quantos deles não contraem a doença após o período de avaliação. Claro que esse número de pessoas testadas é completamente irreal e, de maneira alguma, um estudo científico para determinar a eficácia de uma vacina com base em uma amostra tão pequena teria qualquer validade. Usamos esse número tão somente com a finalidade de simplificar os cálculos e ilustrar os procedimentos utilizados no problema de análise de decisão.</p>
<p>Sendo assim, esses voluntários são monitorados de forma que se saiba, ao final do período de avaliação, quantos deles contraíram a doença. Com base na quantidade de indivíduos imunizados, podemos tomar uma decisão mais informada se vale ou não a pena adquirir a nova vacina.</p>
<p>Se assumirmos que a resposta de cada indivíduo é independente da do outro, e que a eficácia das vacinas não varie de indivíduo para indivíduo, estamos diante de um processo de Bernoulli de tamanho 20. Diante disso, espera-se que a vacina atual seja capaz de imunizar em média 25% do total, ou seja 5 indivíduos.</p>
<p>A questão agora é determinar que regra de decisão será utilizada para definir se a vacina nova é melhor ou não que a atual.</p>
<p>Supondo que uma amostra de tamanho 20 seja suficiente para tirarmos conclusões estatisticamente significativas, o que devemos decidir se:</p>
<ul>
<li>20 dos 20 voluntários forem imunizados?<br />
Nesta situação, parece haver evidências de que a vacina nova tem eficácia superior que a atual;</li>
<li>se nenhum dos voluntários tiver sido imunizado e, ao final do período de avaliação, todos tiverem contraído a doença?<br />
Neste caso, as evidências sugerem que a vacina nova seja pior que a atual.</li>
</ul>
<p>Ambas as situações representam casos extremos, em que não é tão difícil assim tomar uma decisão. Há situações, no entanto, em que o processo de tomada de decisão pode assumir um caráter bem mais dramático.</p>
<p>A fim de estruturar o problema com clareza para que possamos calcular os riscos associados às decisões que serão tomadas, precisamos confrontar nossos medos e avaliar <strong>o que se teme mais</strong>:</p>
<ol style="list-style-type: decimal">
<li>comprar a nova vacina acreditando que ela é mais eficaz que a atual e acabar descobrindo com o tempo que isso não é verdade, ou seja, que a eficácia da vacina é menor que 30%?</li>
</ol>
<p>ou</p>
<ol start="2" style="list-style-type: decimal">
<li>perder a oportunidade de comprar a vacina mais eficaz e sujeitar a população ao risco de uma grave epidemia?</li>
</ol>
<p>A partir de quantos indivíduos imunizados na amostra, podemos decidir que a nova vacina é mais eficaz que a atual e que, assim, podemos decidir comprá-la?</p>
<p>Vamos considerar algumas decisões possíveis:</p>
<p>D1: Compra se observar pelo menos 8 indivíduos imunizados<br />
D2: Compra se observar pelo menos 9 indivíduos imunizados<br />
D3: Compra se observar pelo menos 10 indivíduos imunizados</p>
<p>A decisão D1 consiste em comprar se pelo menos 8 voluntários da amostra tiverem sido imunizados; a decisão D2 é um pouco mais rigorosa e nos leva a comprar a nova vacina se pelo menos 9 voluntários tiverem sido imunizados e, por fim, a decisão D3 que recomenda a compra apenas se pelo menos a metade dos indivíduos da amostra tiver sido imunizada.</p>
<p>Suponha que o decisor tenha optado por D2. Podemos errar ao tomar essa decisão de 2 maneiras e os erros de decisão são chamados <strong>erro do tipo I</strong> e <strong>erro tipo II</strong>.</p>
<p>No erro tipo I, somos levados a crer, a partir das evidências empíricas, que a nova vacina é mais eficaz que a atual, quando ela de fato, não o é. Ou seja, segundo a regra de decisão D2, observamos um número maior que 8 indivíduos imunizados na amostra, mas esse resultado deveu-se meramente ao acaso, pois a vacina administrada não era mais eficaz que a atual.</p>
<p>Já no erro tipo II, temos uma perda de oportunidade, isto é, a vacina é, na realidade melhor que a atual, mas não tivemos evidência disso na amostra coletada, pois apenas um número menor ou igual a 8 dos voluntários foi imunizado.</p>
<div id="resumo-3" class="section level4 unnumbered">
<h4>Resumo</h4>
<p><img src="img/vaccine-decision-table.png" width="80%" /></p>
<p>Temos o estado real da natureza: ou a nova vacina não é suficientemente boa (o que quer dizer que sua eficácia é menor ou igual a 30%), ou ela é melhor que a atual (isto é, sua eficácia é maior que 50%). No entanto, esse estado real da natureza é desconhecido e precisaremos tomar uma decisão com base nas evidências que conseguirmos obter a partir da observação de uma amostra. A decisão será por não comprar a nova vacina, se não tivermos evidências de uma eficácia superior; e a decisão será por comprar a nova vacina, se formos levados a crer que a nova vacina é mais eficaz que a atual. Erramos quando as evidências empíricas não apontam para o estado real da natureza. Sendo assim, erramos quando decidimos comprar a vacina nova e ela não é mais eficaz que a atual (por que as evidências empírica nos levaram a acreditar que a vacina era boa) e erramos quando decidimos não comprar a nova vacina e ela é, de fato, melhor que a atual (por que não fomos capazes de perceber este fato empiricamente).</p>
<p>Os erros do tipo I e II normalmente não são simétricos. Sempre há um que é mais temido que o outro. Formulamos o problema de decisão associando o erro tipo I ao erro mais grave, ou seja, aquele que trará as piores consequências.</p>
<p>Vamos, então, calcular as probabilidades de cometer cada um desses erros.</p>
<p>Cometemos erro tipo I se decidimos compra a vacina nova quando não deveríamos. Então, utilizando a regra de decisão D2, o erro tipo I vai acontecer quando observarmos na amostra um número maior que 8 indivíduos imunizados, quando a eficácia da vacina nova é, na melhor das hipóteses igual a 30%. Portanto, a probabilidade de cometer erro tipo I é dada pela probabilidade condicional de observar <span class="math inline">\(X &gt; 8\)</span> dado que <span class="math inline">\(p = 0,3\)</span>.</p>
<p>Utilizando a distribuição binomial com parâmetros <span class="math inline">\(n = 20\)</span> e <span class="math inline">\(p = 0,3\)</span>, calculamos o risco de cometer erro tipo I, que é da ordem de 11%:</p>
<p><span class="math display">\[\begin{align*}
  P[\text{Erro Tipo I}]
    &amp;= P[\text{comprar quando não deveria}] \\
    &amp;= P [X &gt; 8 | p \leq 0,30]\\
    &amp;= P [X &gt; 8 | p  = 0,30] &amp;: \text{pior caso}\\
    &amp;= 1 - \sum_{x=0}^{8} \binom{20}{x} p^x (1-p)^{(20-x)}\\
    &amp;= 1 - 0,8867 = 0,1133
\end{align*}\]</span></p>
<p>Isso significa que, toda vez que decidirmos comprar a nova vacina, em aproximadamente 11% das vezes estaremos fazendo a coisa errada.</p>
<p>Por outro lado, cometemos erro tipo II se decidimos não comprar a vacina nova quando deveríamos. Isso ocorre quando os resultados empíricos não nos dão evidências da superioridade da eficácia da nova vacina, e observamos na amostra um número menor ou igual a 8 indivíduos imunizados, quando na verdade a eficácia da vacina nova era, no pior caso, igual a 50%. A probabilidade de cometer erro tipo II é dada pela probabilidade condicional de observar <span class="math inline">\(X \leq 8\)</span> dado que <span class="math inline">\(p = 0,5\)</span>. Utilizando a distribuição binomial com parâmetros <span class="math inline">\(n=20\)</span> e <span class="math inline">\(p=0,5\)</span>, chegamos à conclusão de que o risco de cometer erro tipo II é da ordem de 25%.</p>
<p><span class="math display">\[\begin{align*}
  P[\textsf{Erro Tipo II}] 
    &amp;= P [\text{não comprar quando deveria}] \\
    &amp;= P [X \leq 8 | p &gt; p_o]\\
    &amp;= P [X \leq 8 | p  = 0,5] &amp;: \text{pior caso}\\
    &amp;= \sum_{x=0}^{8} \binom{20}{x} p^x (1-p)^{(20-x)}\\
    &amp;= 0,2517
\end{align*}\]</span></p>
<p>Neste caso, em cerca de 25% das vezes que recusarmos a nova vacina, estaremos rejeitando um produto melhor que o atual.</p>
<p>Esses riscos calculados estão associados à regra de decisão adotada.
Estamos dispostos a correr esses riscos?</p>
<p>Vejamos como variam os riscos de cometer erros do tipo I e do tipo II, se optarmos por outras regras de decisão.</p>
<p>Procedendo de maneira análoga para as decisões D1 e D3, podemos completar a seguinte tabela que mostra os riscos associados a cada uma das decisões:</p>
<p><img src="img/vaccine-decisoes.png" width="60%" /></p>
<p>Note que ao tomar uma decisão mais rigorosa, ou seja, quando decidimos comprar a vacina nova apenas com evidências mais contundentes, como no caso da regra de decisão D3, nosso risco de comprar uma vacina de eficácia duvidosa cai de 11% para um pouco menos de 5%. No entanto, o rigor também tem seu preço. Ao utilizar essa regra de decisão, o risco de perder uma boa oportunidade aumenta de 25% para cerca de 41%.</p>
<p>Por outro lado, se nos permitimos convencer da eficácia da vacina nova com base em evidências menos robustas, o risco de cometer erro tipo I aumenta de 11% para quase 23%, enquanto o risco de cometer erro tipo II cai de 25% para aproximadamente 13%.</p>
<p>Algumas lições importantes que devemos levar deste exemplo são as seguintes: qualquer que seja a decisão tomada, sempre há riscos envolvidos, pois a informação de que dispomos é incompleta e imperfeita. E, assim, não é possível ter certeza de que estamos tomando a decisão correta. Para que a decisão seja a melhor possível, é necessário definir qual o erro mais temido, ou seja, que erro produz as consequências mais graves que deveriam ser evitadas; e, por fim, é necessário definir de antemão qual o risco máximo tolerado para cada tipo de erro de decisão que se pode cometer, pois esses limites ajudam a balizar as decisões a serem tomadas.</p>
</div>
</div>
<div id="distribuição-geométrica" class="section level2">
<h2><span class="header-section-number">6.5</span> Distribuição Geométrica</h2>
<p>Vimos anteriormente que podemos modelar o no de sucessos em um número fixo de experimentos de Bernoulli, utilizando a distribuição binomial. No entanto, podemos estar interessados em responder a outras perguntas associadas a um processo de Bernoulli. Por exemplo, podemos desejar modelar não o número de sucessos, mas <strong>o número de experimentos de Bernoulli necessários até que se observe o primeiro sucesso</strong>. Esta é uma questão que pertence a uma outra classe importante de problemas, associada ao tempo que se deve esperar até que observar a ocorrência de um certo evento de interesse. Esta classe de problemas surge em diferentes contextos e, portanto, eles podem ser modelados de diferentes maneiras. No contexto de um processo de Bernoulli, esse tipo de situação pode ser modelada utilizando a distribuição geométrica, como veremos a seguir.</p>
<p>Considere o seguinte experimento:</p>
<p>Um observador posiciona-se em um cruzamento movimentado e registra se um
pedestre tentando atravessar a rua é atropelado por um veículo.</p>
<p>O experimento tem dois resultados possíveis:<br />
S = a pessoa é atropelada<br />
F = a pessoa não é atropelada</p>
<p>O experimento consiste em registrar o número de pessoas que conseguem atravessar a rua até que a primeira pessoa seja atropelada.</p>
<p>Como podemos modelar este experimento?</p>
<p>Bem, será necessário fazer algumas simplificações para modelar esta situação: vamos assumir que cada pessoa tem a mesma chance <span class="math inline">\(p\)</span> de ser atropelada e que os atropelamentos acontecem de maneira independente uns dos outros, ou seja, não vamos ver várias pessoas sendo atropeladas juntas, nem que um atropelamento terá influência sobre um outro.</p>
<p>E assim, o espaço amostral, definido pelos possíveis resultados do experimento, é formado pelos eventos S (se a primeira pessoa a atravessar é atropelada), FS (se a segunda pessoa é a primeira a ser atropelada) e, assim por diante.</p>
<p><span class="math inline">\(\Omega = \{ S, FS, FFS, \ldots\}\)</span>; em que <span class="math inline">\(S\)</span> = a pessoa é atropelada</p>
<p>Note que a esse espaço amostral está associada uma v.a. <span class="math inline">\(X\)</span> discreta (já que o conjunto é infinito porém enumerável), que representa o número de pessoas observadas até o primeiro atropelamento. Portanto, <span class="math inline">\(X\)</span> pode assumir qualquer valor no conjunto dos números inteiros maiores que zero.</p>
<p><span class="math inline">\(X =\)</span> número de pessoas observadas até o primeiro atropelamento:<br />
<span class="math inline">\(X = i, \quad i = 1, 2, 3, \ldots\)</span></p>
<p>A fim de caracterizar probabilisticamente esta situação, precisamos calcular os valores de probabilidade associados a cada valor que a v.a. <span class="math inline">\(X\)</span> pode assumir, isto é, precisamos determinar a fdp de <span class="math inline">\(X\)</span>.</p>
<p>A probabilidade de <span class="math inline">\(X\)</span> assumir valor 1, que representa a situação em que a primeira pessoa a atravessar a rua é a primeira a ser atropelada, vale <span class="math inline">\(p\)</span>, que é a probabilidade de qualquer pessoa ser atropelada por um veículo.</p>
<p>Para <span class="math inline">\(X =2\)</span>, a probabilidade vale <span class="math inline">\((1-p) \times p\)</span>, pois temos um fracasso que ocorre com probabilidade <span class="math inline">\((1-p)\)</span>, seguido de um sucesso, que ocorre com probabilidade <span class="math inline">\(p\)</span>.</p>
<p>Para <span class="math inline">\(X = 3\)</span>, temos dois fracassos, seguidos de um sucesso e, portanto, a probabilidade vale <span class="math inline">\((1-p)^2 \times p\)</span>.</p>
<p>E prosseguimos… Então, a probabilidade de a n-ésima pessoa a atravessar a rua ser a primeira a ser atropelada vale <span class="math inline">\((1-p)^{n-1} \times p\)</span>. Note que <span class="math inline">\(n-1\)</span> pessoas conseguiram atravessar a rua sem nenhum incidente e o experimento sempre termina com um sucesso.</p>
<p>Então:</p>
<p><span class="math display">\[\begin{align*}
&amp;P[X = 1] = p             &amp;: \text{a 1a. pessoa é a primeira a ser atropelada} &amp;\\
&amp;P[X = 2] = (1-p) p       &amp;: \text{a 2a. pessoa é a primeira a ser atropelada}\\
&amp;P[X = 3] = (1-p)^2 p     &amp;: \text{a 3a. pessoa é a primeira a ser atropelada}\\
&amp;\vdots\\
&amp;P[X = n] = (1-p)^{n-1} p &amp;:  \text{a n-ésima pessoa é a primeira a ser atropelada}\\
&amp;\vdots  &amp;n \in \mathcal{Z} &gt; 0
\end{align*}\]</span></p>
<p>Portanto, a v.a. <span class="math inline">\(X\)</span> tem distribuição geométrica com parâmetro <span class="math inline">\(p\)</span> se
representa o número de experimentos de Bernoulli necessários até que se observe o primeiro sucesso, em que a probabilidade de observar um sucesso a cada experimento vale <span class="math inline">\(p\)</span>.</p>
<p>Seja a v.a. <span class="math inline">\(X \sim Geom (p)\)</span>:</p>
<p><span class="math inline">\(X =\)</span> no. de repetições de um experimento de Bernoulli até observar o primeiro sucesso</p>
<p>A fdp da v.a. <span class="math inline">\(X\)</span> é dada pela expressão abaixo.</p>
<p><span class="math display">\[\begin{align*}
  &amp;{} f_{X}(x) = \left\{
  \begin{array}{rl}
    q^{x-1}p , &amp; x = 1, 2, \ldots \\
    0,           &amp; c.c.
  \end{array}\right.
  \quad 0 \leq p \leq 1; \quad q = 1-p \\
  \\
  &amp;{} E[X] = \frac{1}{p} \qquad Var[X] = \frac{1-p}{p^2}
\end{align*}\]</span></p>
<p>Da maneira que definimos o experimento, a v.a. <span class="math inline">\(X\)</span> pode assumir qualquer valor inteiro maior que zero. No entanto, é possível definir a v.a. Geométrica como o número de tentativas <strong>antes</strong> do primeiro sucesso, de forma que o suporte da função passa a incluir o zero.</p>
<p>Para a versão da v.a. aleatória apresentada, o valor esperado de <span class="math inline">\(X\)</span> é dado <span class="math inline">\(1/p\)</span>, e a variância de <span class="math inline">\(X\)</span> vale <span class="math inline">\((1-p)/p^2\)</span>.</p>
<div id="propriedade-de-ausência-de-memória" class="section level3 unnumbered">
<h3>Propriedade de Ausência de Memória</h3>
<p>A distribuição geométrica tem uma propriedade muito interessante que se chama “Ausência de Memória”, isto é, a distribuição “esquece” o que aconteceu no passado. Esta propriedade é enunciada da seguinte forma:</p>
<p>Temos, para n, k = 1, 2, …</p>
<p><span class="math display">\[P[X &gt; n+k |X&gt; k] = P[X &gt; n]\]</span></p>
<p>É possível chegar a essa igualdade a partir da definição de probabilidade condicional:</p>
<p><span class="math display">\[\begin{align*}
  P[X &gt; n+k |X &gt; k] &amp;= \frac{P[X &gt; n+k] \cap P[X &gt; k]}{P[X &gt; k]}\\
                    &amp;= \frac{P[X &gt; n+k]}{P[X &gt; k]}\\
                    &amp;= \frac{(1-p)^{n+k}}{(1-p)^k} = (1-p)^n = P[X &gt; n].
\end{align*}\]</span></p>
<p>Assim, para dois números inteiros positivos <span class="math inline">\(n\)</span> e <span class="math inline">\(k\)</span>, a probabilidade de observar <span class="math inline">\(n\)</span> fracassos adicionais, dado que <span class="math inline">\(k\)</span> fracassos já ocorreram, é igual à probabilidade de observar <span class="math inline">\(n\)</span> fracassos no início da sequência de experimentos de Bernoulli.</p>
<p>Em outras palavras, a probabilidade de observar uma sequência de fracassos só depende do tamanho dessa sequência, não da sua posição. O processo de Bernoulli sempre se reinicia. Essa propriedade decorre da hipótese de independência dos experimentos que compõe o Processo de Bernoulli. E a família de distribuições geométricas é a única família de distribuições discretas com esta propriedade!</p>
<p>E uma nota é importante: podemos chamar as distribuições de probabilidade de famílias de distribuições, pois, na verdade, cada distribuição de probabilidades define uma família, já que cada combinação de valores dos parâmetros define uma única distribuição.</p>
<p>A distribuição geométrica comumente é utilizada para modelar o tempo de vida de sistemas, quando essa medida de tempo é tomada de forma discreta (por exemplo, em dias, meses, anos etc.). Mas, para isso, é necessário que seja válida a hipótese de que o sistema em questão não envelheça, ou seja, a distribuição geométrica não é adequada para modelar tempo de vida em situações em que a probabilidade de que o sistema falhe aumenta com o tempo. Outras distribuições podem ser utilizadas com esse propósito, como veremos no futuro.</p>
</div>
</div>
<div id="outras-distribuições" class="section level2">
<h2><span class="header-section-number">6.6</span> Outras Distribuições</h2>
<p>Há outras distribuições que podem ser desenvolvidas a partir de, ou em analogia aos Processos de Bernoulli, que representam diferentes aspectos desses processos que podem nos interessar.</p>
<p>Nós não entraremos em muitos detalhes, mas é importante pelo menos apresentá-las, a fim de que possamos reconhecer que é possível modelar probabilisticamente diferentes situações de interesse.</p>
<div id="distribuição-binomial-negativa-ou-distribuição-de-pascal" class="section level3 unnumbered">
<h3>Distribuição Binomial Negativa (ou Distribuição de Pascal)</h3>
<p>A distribuição binomial negativa (também chamada distribuição de Pascal) consiste em uma generalização da distribuição geométrica. Em vez de estarmos interessados em modelar o número de repetições do experimento de Bernoulli necessárias para observar o primeiro sucesso, agora estamos interessados em observar os <span class="math inline">\(k\)</span> primeiros sucessos.</p>
<p>Portanto a v.a. <span class="math inline">\(X\)</span> segue distribuição binomial negativa com parâmetros <span class="math inline">\(k\)</span> e <span class="math inline">\(p\)</span> se representa o número de repetições necessárias de um experimento de Bernoulli até obter o <span class="math inline">\(k-\)</span>ésimo sucesso.</p>
<p>A fdp da v.a. binomial negativa é dada por:</p>
<p><span class="math display">\[f_X(x; k, p) = \binom{x-1}{k-1} p^kq^{x-k} \quad 0 \leq p = 1-q \leq 1; \quad x = k, k+1, k+2, \ldots\]</span></p>
<p>Podemos também compará-la também com a distribuição binomial. Enquanto a distribuição binomial conta o número de sucessos em um número <strong>fixo de experimentos</strong> de Bernoulli, a distribuição binomial negativa modela o número de experimentos necessários para observar um determinado <strong>número fixo</strong> <span class="math inline">\(k\)</span> <strong>de sucessos</strong>.</p>
</div>
<div id="distribuição-multinomial" class="section level3 unnumbered">
<h3>Distribuição Multinomial</h3>
<p>Podemos imaginar uma outra situação, em que generalizaremos o experimento de Bernoulli. Agora, consideraremos um experimento que pode ter não apenas dois, mas um número <span class="math inline">\(m\)</span> finito de resultados possíveis. Um experimento como esse é chamado de <strong>experimento multinomial</strong>.</p>
<p>A v.a. <span class="math inline">\(X_i\)</span> com distribuição multinomial serve de modelo para a seguinte situação: há um total de <span class="math inline">\(n\)</span> experimentos independentes. Cada um desses experimentos pode resultar em uma de <span class="math inline">\(m\)</span> possibilidades. A probabilidade do resultado <span class="math inline">\(i\)</span> vale <span class="math inline">\(p_i\)</span> em cada repetição do experimento (ou seja, também temos independência e estacionariedade).</p>
<p>A v.a. <span class="math inline">\(X_i\)</span> conta o número de ocorrências de cada resultado possível nas <span class="math inline">\(n\)</span> repetições do experimento multinomial.</p>
<p><span class="math display">\[\mathbf{X} = (X_1, X_2, \ldots, X_m); \qquad
   \mathbf{p} = (p_1, p_2, \ldots, p_m)\]</span></p>
<p><span class="math display">\[f_{\mathbf{X}}(\mathbf{x}; \mathbf{p}, n) = \frac{n!}{x_1!x_2! \ldots x_m!} p_1^{x_1} p_2^{x_2} \ldots p_m^{x_m} \;:\qquad  \sum_{i=1}^{m} x_i = n, \;\sum_{i=1}^{m} p_i = 1.\]</span></p>
<p>Suponha que desejamos avaliar a robustez de um componente aeronáutico complexo quando sofre uma colisão com um objeto (por exemplo, um pássaro). O componente pode ser danificado de várias maneiras, cada uma com uma probabilidade diferente. Podemos utilizar a distribuição multinomial se estivermos interessados em modelar as ocorrências de determinadas combinações dos possíveis danos causados ao componente.</p>
</div>
<div id="distribuição-multinomial-negativa" class="section level3 unnumbered">
<h3>Distribuição Multinomial Negativa</h3>
<p>Outra distribuição interessante associada a uma variação do experimento de Bernoulli é a distribuição Multinomial Negativa. Ela consiste em uma generalização da distribuição binomial negativa, que modelava o número de repetições do experimento de Bernoulli necessário para observar <span class="math inline">\(k\)</span> sucessos.</p>
<p>No caso da distribuição Multinomial Negativa, temos um experimento multinomial e desejamos modelar o número de ocorrências de cada resultado possível observado em um número de repetições do experimento multinomial necessário para observar uma certa quantidade fixa <span class="math inline">\(k_0\)</span> de ocorrências de um desses resultados possíveis, <span class="math inline">\(X_0\)</span>:</p>
<p><span class="math display">\[\mathbf{X} = (X_0, X_1, X_2, \ldots, X_m); \qquad %\]
   \mathbf{p} = (p_0, p_1, p_2, \ldots, p_m); \qquad p_0 = 1 - \sum_{i=1}^m p_i\]</span></p>
<p><span class="math display">\[E[\mathbf{X}] = \frac{k_0}{p_0} \mathbf{p}; \qquad
    Var[\mathbf{X}] = \frac{k_0}{p_0^2} \mathbf{p}\mathbf{p}^\prime + \frac{k_0}{p_0} \textsf{diag}(\mathbf{p})\]</span></p>
</div>
<div id="distribuição-hipergeométrica" class="section level3 unnumbered">
<h3>Distribuição Hipergeométrica</h3>
<p>A distribuição hipergeométrica nos dá uma certa probabilidade condicional que ocorre em um processo de Bernoulli. Dado que sabemos haver <span class="math inline">\(k\)</span> sucessos em <span class="math inline">\(N\)</span> repetições do experimento de Bernoulli, desejamos modelar a probabilidade de observar <span class="math inline">\(x\)</span> sucessos nas primeiras <span class="math inline">\(n\)</span> repetições do experimento.</p>
<p>A v.a. <span class="math inline">\(X\)</span> com distribuição hipergeomética modela o número de sucessos obtidos nas <span class="math inline">\(n\)</span> primeiras repetições do experimento de Bernoulli, dado que sabemos haver <span class="math inline">\(K\)</span> sucessos em <span class="math inline">\(N\)</span> repetições do experimento:</p>
<p><span class="math display">\[f_X(x; N, K, n) = \frac{{\binom{n}{x}}{\binom{N-n}{K-x}}}{\binom{N}{K}}; \quad 0 \leq x \leq K\]</span></p>
<p>No denominador, temos o espaço amostral que consiste em todas as maneiras que podemos selecionar <span class="math inline">\(K\)</span> sucessos nas <span class="math inline">\(N\)</span> repetições do experimento. O número de maneiras de obter <span class="math inline">\(x\)</span> sucessos nas <span class="math inline">\(n\)</span> primeiras repetições do experimento é dado pela combinação de <span class="math inline">\(n\)</span>, <span class="math inline">\(x\)</span>-a-<span class="math inline">\(x\)</span>; e a próxima combinação corresponde ao número de maneiras de obter os <span class="math inline">\(K-x\)</span> sucessos restantes nas <span class="math inline">\(N-n\)</span> repetições restantes.</p>
<p>Note que essa é a mesma probabilidade que se obtém ao modelar o número de sucessos em uma sequência de sorteios realizados <strong>sem reposição</strong> (diferentemente da distribuição binomial, em que os sorteios eram realizados com reposição). Neste sentido, essa distribuição encontra muitas aplicações em amostragem de populações finitas e é melhor compreendida através do exemplo clássico do modelo de urna.</p>
<p><strong>Modelo de Urna</strong></p>
<p>Suponha que em uma grande urna existam <span class="math inline">\(N\)</span> bolas idênticas, das quais <span class="math inline">\(K\)</span> são vermelhas. Uma pessoa retira da urna, ao acaso e simultaneamente, <span class="math inline">\(n\)</span> bolas (isso equivale a dizer que os sorteios das bolas são realizado sem reposição) e queremos saber qual a probabilidade de que na amostra retirada <span class="math inline">\(x\)</span> bolas sejam vermelhas.</p>
<p><span class="math display">\[\frac{\binom{N}{K}{\binom{N-K}{n-x}}}{\binom{N}{n}}\]</span>
<span class="math inline">\(N\)</span> bolas, das quais <span class="math inline">\(K\)</span> sucessos; sorteia <span class="math inline">\(n\)</span>, das quais <span class="math inline">\(x\)</span> sucessos</p>
<p>Como os sorteios são realizados sem reposição, os experimentos de Bernoulli são dependentes, pois a probabilidade de sucesso não se mantém mais constante ao longo do tempo.</p>
</div>
<div id="distribuição-hipergeométrica-negativa" class="section level3 unnumbered">
<h3>Distribuição Hipergeométrica Negativa</h3>
<p>E, finalmente, temos a distribuição Hipergeométrica Negativa, raramente descrita em textos de graduação, que modela quantos itens devem ser selecionados a partir de uma população finita a fim de observar o <span class="math inline">\(k\)</span>-ésimo sucesso quando a amostragem é realizada sem reposição.</p>
<p>As distribuições Hipergeomética Negativa e Hipergeométrica têm uma relação análoga entre aquela existente entre as distribuição binomial negativa e binomial, isto é, enquanto a distribuição hipergeométrica modela o no. de sucessos em uma quantidade fixa de sorteios sem reposição, a distribuição hipergeométrica negativa modela o número necessário de sorteios sem reposição para obter uma quantidade fixa de sucessos.</p>
<p>[Ver artigo]</p>
</div>
</div>
<div id="resumo-4" class="section level2 unnumbered">
<h2>Resumo</h2>
<p>Um processo de Bernoulli é um processo aleatório caracterizado pela ocorrência de “sucessos” e “fracassos” em uma série de repetições de experimentos discretos tais que:</p>
<ol style="list-style-type: lower-roman">
<li>Existem apenas dois resultados possíveis, rotulados como “sucesso” e “fracasso”;<br />
</li>
<li>As repetições do experimento são mutuamente independentes; e<br />
</li>
<li>As probabilidades de “sucesso” e “fracasso” são as mesmas para todos os experimentos.</li>
</ol>
<p>Desenvolvemos diversas distribuições de probabilidade associadas a diferentes aspectos de um processo de Bernoulli:</p>
<div id="distribuição-binomial-1" class="section level4 unnumbered">
<h4>(1) Distribuição Binomial</h4>
<p>Se estivermos interessados no número total de sucessos em uma determinada quantidade <span class="math inline">\(n\)</span> fixa de repetições do experimento de Bernoulli, temos uma v.a. que tem distribuição binomial com parâmetros <span class="math inline">\(n\)</span> e <span class="math inline">\(p\)</span>, em que <span class="math inline">\(p\)</span> é a probabilidade de obter sucesso em cada experimento.<br />
<span class="math inline">\(X\)</span> = número total de sucessos em <span class="math inline">\(n\)</span> repetições do experimento de Bernoulli
<span class="math inline">\(X \sim Bin (n, p)\)</span></p>
</div>
<div id="distribuição-geométrica-1" class="section level4 unnumbered">
<h4>(2) Distribuição Geométrica</h4>
<p>Se quisermos modelar o número de experimentos de Bernoulli necessários para observar o primeiro sucesso, temos uma v.a. que tem distribuição geométrica com parâmetro <span class="math inline">\(p\)</span>.<br />
<span class="math inline">\(X\)</span> = número de experimentos necessários até observar o primeiro sucesso
<span class="math inline">\(X \sim Geo (p)\)</span></p>
</div>
<div id="distribuição-binomial-negativa" class="section level4 unnumbered">
<h4>(3) Distribuição Binomial Negativa</h4>
<p>Podemos querer modelar o numero de repetições do experimento de Bernoulli necessários até observar não 1 sucesso, mas <span class="math inline">\(k\)</span> sucessos. Neste caso, podemos empregar uma v.a. que tem distribuição binomial negativa com parâmetros <span class="math inline">\(k\)</span> e <span class="math inline">\(p\)</span>.<br />
<span class="math inline">\(X\)</span> = número de experimentos necessários até observar <span class="math inline">\(k\)</span> sucessos<br />
<span class="math inline">\(X \sim BinNeg (k, p)\)</span></p>
<p>E também vimos algumas variações:</p>
<p>Se tivermos um <strong>experimento multinomial</strong>, que consiste em um experimento aleatório com um número <span class="math inline">\(m\)</span> fixo de resultados possíveis, cada um ocorrendo com uma determinada probabilidade, podemos identificar as seguintes distribuições associadas a este tipo de experimento:</p>
</div>
<div id="distribuição-multinomial-1" class="section level4 unnumbered">
<h4>(1) Distribuição Multinomial</h4>
<p>O número total de ocorrências de cada um desses resultados possíveis pode ser modelado através de uma v.a. que tem distribuição multinomial, com parâmetros <span class="math inline">\(p\)</span> e <span class="math inline">\(n\)</span>, em que <span class="math inline">\(p\)</span> é o vetor das probabilidades dos resultados possíveis e <span class="math inline">\(n\)</span> é o numero de repetições do experimento multinomial;<br />
<span class="math inline">\(\mathbf{X} = (X_1, X_2, \ldots, X_m)\)</span> = número total de ocorrências de cada um de <span class="math inline">\(m\)</span> possíveis resultados de um experimento de De Moivre (multinomial)<br />
<span class="math inline">\(\mathbf{X} \sim Multin (\mathbf{p}, n)\)</span></p>
</div>
<div id="distribuição-multinomial-negativa-1" class="section level4 unnumbered">
<h4>(2) Distribuição Multinomial Negativa</h4>
<p>Quando desejamos modelar o número de ocorrências de cada um dos resultados possíveis observado em um número de repetições do experimento multinomial necessário para observar um certo número fixo de ocorrências de um desses resultados possíveis, temos uma v.a. com distribuição multinomial negativa.<br />
<span class="math inline">\(\mathbf{X} = (X_1, X_2, \ldots, X_m)\)</span> = número total de ocorrências de cada um de <span class="math inline">\(m\)</span> possíveis resultados de um experimento multinomial até obter <span class="math inline">\(k_0\)</span> ocorrências do resultado <span class="math inline">\(X_0\)</span><br />
<span class="math inline">\(\mathbf{X} \sim MultinNeg (\mathbf{p}, k_0)\)</span></p>
<p>Outras variações podem ser obtidas considerando experimentos de Bernoulli <strong>dependentes</strong>.</p>
</div>
<div id="distribuição-hipergeométrica-1" class="section level4 unnumbered">
<h4>(1) Distribuição Hipergeométrica</h4>
<p>Se estivermos interessados no numero total de sucessos em um número fixo de repetições de um experimento de Bernoulli, quando a amostragem é realizada sem reposição (o que quer dizer que a probabilidade de sucesso é alterada a cada sorteio), podemos empregar uma v.a. que segue distribuição hipergeométrica, com parâmetros <span class="math inline">\(N\)</span>, <span class="math inline">\(K\)</span> e <span class="math inline">\(n\)</span>, em que <span class="math inline">\(N\)</span> é o tamanho da população, <span class="math inline">\(K\)</span> é o número de sucessos na população e <span class="math inline">\(n\)</span> é o número de experimentos realizados.
<span class="math inline">\(X\)</span> = número total de sucessos em <span class="math inline">\(n\)</span> repetições de um experimento de Bernoulli quando a amostragem é realizada sem reposição<br />
<span class="math inline">\(X \sim HiperGeo (N, K, n)\)</span></p>
</div>
<div id="distribuição-hipergeométrica-negativa-1" class="section level4 unnumbered">
<h4>(2) Distribuição Hipergeométrica Negativa</h4>
<p>Quando estamos interessados no número de sorteios sem reposição necessários até observar <span class="math inline">\(k\)</span> sucessos, temos um v.a. Hipergeométrica negativa, com parâmetros <span class="math inline">\(N\)</span>, <span class="math inline">\(K\)</span> e <span class="math inline">\(k\)</span>.
<span class="math inline">\(X\)</span> = número de repetições de um experimento de Bernoulli com amostragem sem reposição até obter <span class="math inline">\(k\)</span> sucessos<br />
<span class="math inline">\(X \sim HiperGeoNeg (N, K, k)\)</span></p>
<p>Em seguida, estudaremos um outro tipo de processo aleatório, o chamado <strong>Processo de Poisson</strong>, para o qual também analisaremos vários aspectos e desenvolveremos as distribuições de probabilidade associadas.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="variáveis-aleatórias-e-distribuições.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["apostila-GED13.pdf", "apostila-GED13.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
