<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 8 Modelos Probabilísticos: Distribuição Normal | GED-13: Probabilidade e Estatística</title>
  <meta name="description" content="Apostila do curso de GED-13: Probabilidade e Estatística." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 8 Modelos Probabilísticos: Distribuição Normal | GED-13: Probabilidade e Estatística" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Apostila do curso de GED-13: Probabilidade e Estatística." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 8 Modelos Probabilísticos: Distribuição Normal | GED-13: Probabilidade e Estatística" />
  
  <meta name="twitter:description" content="Apostila do curso de GED-13: Probabilidade e Estatística." />
  

<meta name="author" content="Prof. Denise Beatriz Ferrari" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"/>
<link rel="next" href="distribuições-amostrais.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Probabilidade e Estatística</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Objetivos do Curso</a></li>
<li class="chapter" data-level="1" data-path="introdução.html"><a href="introdução.html"><i class="fa fa-check"></i><b>1</b> Introdução</a><ul>
<li class="chapter" data-level="1.1" data-path="introdução.html"><a href="introdução.html#estatística-e-o-raciocínio-científico"><i class="fa fa-check"></i><b>1.1</b> Estatística e o Raciocínio Científico</a></li>
<li class="chapter" data-level="1.2" data-path="introdução.html"><a href="introdução.html#o-que-é-estatística"><i class="fa fa-check"></i><b>1.2</b> O que é Estatística?</a></li>
<li class="chapter" data-level="1.3" data-path="introdução.html"><a href="introdução.html#o-papel-da-probabilidade-em-estatística"><i class="fa fa-check"></i><b>1.3</b> O Papel da Probabilidade em Estatística</a></li>
<li class="chapter" data-level="1.4" data-path="introdução.html"><a href="introdução.html#elementos-fundamentais-em-estatística"><i class="fa fa-check"></i><b>1.4</b> Elementos Fundamentais em Estatística</a><ul>
<li class="chapter" data-level="" data-path="introdução.html"><a href="introdução.html#população-e-amostra"><i class="fa fa-check"></i>População e Amostra</a></li>
<li class="chapter" data-level="" data-path="introdução.html"><a href="introdução.html#variáveis"><i class="fa fa-check"></i>Variáveis</a></li>
<li class="chapter" data-level="" data-path="introdução.html"><a href="introdução.html#dados-e-fontes-de-dados"><i class="fa fa-check"></i>Dados e Fontes de Dados</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introdução.html"><a href="introdução.html#tipos-de-problemas"><i class="fa fa-check"></i><b>1.5</b> Tipos de Problemas</a></li>
<li class="chapter" data-level="1.6" data-path="introdução.html"><a href="introdução.html#o-processo-de-análise-de-dados"><i class="fa fa-check"></i><b>1.6</b> O Processo de Análise de Dados</a></li>
<li class="chapter" data-level="1.7" data-path="introdução.html"><a href="introdução.html#métodos-para-exploração-resumo-e-descrição-de-dados"><i class="fa fa-check"></i><b>1.7</b> Métodos para Exploração, Resumo e Descrição de Dados</a><ul>
<li class="chapter" data-level="" data-path="introdução.html"><a href="introdução.html#análise-exploratória-de-dados-exploratory-data-analysis-eda"><i class="fa fa-check"></i>Análise Exploratória de Dados (“Exploratory Data Analysis”, EDA)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html"><i class="fa fa-check"></i><b>2</b> Introdução à Teoria de Probabilidades</a><ul>
<li class="chapter" data-level="2.1" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#breve-histórico"><i class="fa fa-check"></i><b>2.1</b> Breve Histórico</a><ul>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#chance-e-incerteza"><i class="fa fa-check"></i>Chance e Incerteza</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#jogos-de-azar"><i class="fa fa-check"></i>Jogos de Azar</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#origem-da-teoria-matemática-de-probabilidades"><i class="fa fa-check"></i>Origem da Teoria Matemática de Probabilidades</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#formalização-matemática"><i class="fa fa-check"></i>Formalização Matemática</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#definições-iniciais"><i class="fa fa-check"></i><b>2.2</b> Definições Iniciais</a><ul>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#experimento-aleatório"><i class="fa fa-check"></i>Experimento Aleatório</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#espaço-amostral-e-evento"><i class="fa fa-check"></i>Espaço Amostral e Evento</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#lei-de-probabilidade"><i class="fa fa-check"></i>Lei de Probabilidade</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#interpretações-de-probabilidade"><i class="fa fa-check"></i><b>2.3</b> Interpretações de Probabilidade</a><ul>
<li><a href="introdução-à-teoria-de-probabilidades.html#interpretação-clássica-a-priori-laplace-1812">Interpretação Clássica (<em>a priori</em>): Laplace, 1812</a></li>
<li><a href="introdução-à-teoria-de-probabilidades.html#interpretação-empírica-ou-de-frequência-relativa-a-posteriori-richard-v.-mises-1919">Interpretação Empírica ou de Frequência Relativa (<em>a posteriori</em>): Richard V. Mises, 1919</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#interpretação-subjetiva"><i class="fa fa-check"></i>Interpretação Subjetiva</a></li>
<li class="chapter" data-level="" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#resumo"><i class="fa fa-check"></i>Resumo</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#definição-axiomática"><i class="fa fa-check"></i><b>2.4</b> Definição Axiomática</a></li>
<li class="chapter" data-level="2.5" data-path="introdução-à-teoria-de-probabilidades.html"><a href="introdução-à-teoria-de-probabilidades.html#revisitando-o-paradoxo-de-de-méré-o-problema-dos-dados"><i class="fa fa-check"></i><b>2.5</b> Revisitando o Paradoxo de De Méré: O Problema dos Dados</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html"><i class="fa fa-check"></i><b>3</b> Probabilidade Condicional e Independência</a><ul>
<li class="chapter" data-level="3.1" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#probabilidade-condicional"><i class="fa fa-check"></i><b>3.1</b> Probabilidade Condicional</a><ul>
<li class="chapter" data-level="" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#propriedades"><i class="fa fa-check"></i>Propriedades</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#independência-de-eventos"><i class="fa fa-check"></i><b>3.2</b> Independência de Eventos</a><ul>
<li class="chapter" data-level="" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#propriedades-1"><i class="fa fa-check"></i>Propriedades</a></li>
<li class="chapter" data-level="" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#independência-condicional"><i class="fa fa-check"></i>Independência Condicional</a></li>
<li class="chapter" data-level="" data-path="probabilidade-condicional-e-independência.html"><a href="probabilidade-condicional-e-independência.html#eventos-independentes-x-eventos-mutuamente-exclusivos"><i class="fa fa-check"></i>Eventos Independentes x Eventos Mutuamente Exclusivos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="teoremas-fundamentais-da-probabilidade.html"><a href="teoremas-fundamentais-da-probabilidade.html"><i class="fa fa-check"></i><b>4</b> Teoremas Fundamentais da Probabilidade</a><ul>
<li class="chapter" data-level="4.1" data-path="teoremas-fundamentais-da-probabilidade.html"><a href="teoremas-fundamentais-da-probabilidade.html#teorema-da-probabilidade-total-dividir-para-conquistar"><i class="fa fa-check"></i><b>4.1</b> Teorema da Probabilidade Total: …dividir para conquistar!</a></li>
<li class="chapter" data-level="4.2" data-path="teoremas-fundamentais-da-probabilidade.html"><a href="teoremas-fundamentais-da-probabilidade.html#teorema-de-bayes-aprendendo-pela-experiência"><i class="fa fa-check"></i><b>4.2</b> Teorema de Bayes: …aprendendo pela experiência</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html"><i class="fa fa-check"></i><b>5</b> Variáveis Aleatórias e Distribuições</a><ul>
<li class="chapter" data-level="5.1" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#variáveis-aleatórias"><i class="fa fa-check"></i><b>5.1</b> Variáveis Aleatórias</a><ul>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#definição-caso-unidimensional"><i class="fa fa-check"></i>Definição (caso unidimensional)</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#tipos-de-variáveis-aleatórias"><i class="fa fa-check"></i>Tipos de Variáveis Aleatórias</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#distribuições-de-probabilidade"><i class="fa fa-check"></i><b>5.2</b> Distribuições de Probabilidade</a><ul>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#função-distribuição-de-probabilidade-fdp-caso-discreto"><i class="fa fa-check"></i>Função Distribuição de Probabilidade (fdp): caso discreto</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#função-distribuição-de-probabilidade-fdp-caso-contínuo"><i class="fa fa-check"></i>Função Distribuição de Probabilidade (fdp): caso contínuo</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#função-distribuição-acumulada-fda"><i class="fa fa-check"></i>Função Distribuição Acumulada (FDA)</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#valor-esperado-e-variância"><i class="fa fa-check"></i><b>5.3</b> Valor Esperado e Variância</a><ul>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#valor-esperado"><i class="fa fa-check"></i>Valor Esperado</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#o-problema-dos-pontos-e-a-aposta-de-pascal"><i class="fa fa-check"></i>O Problema dos Pontos e a Aposta de Pascal</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#variância"><i class="fa fa-check"></i>Variância</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#desvio-padrão"><i class="fa fa-check"></i>Desvio-padrão</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#momentos"><i class="fa fa-check"></i><b>5.4</b> Momentos</a><ul>
<li><a href="variáveis-aleatórias-e-distribuições.html#assimetria-skewness-e-excesso-kurtosis">Assimetria (<em>skewness</em>) e Excesso (<em>kurtosis</em>)</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#desigualdades-de-markov-e-chebyshev"><i class="fa fa-check"></i><b>5.5</b> Desigualdades de Markov e Chebyshev</a><ul>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#desigualdade-de-markov"><i class="fa fa-check"></i>Desigualdade de Markov</a></li>
<li class="chapter" data-level="" data-path="variáveis-aleatórias-e-distribuições.html"><a href="variáveis-aleatórias-e-distribuições.html#desigualdade-de-chebyshev"><i class="fa fa-check"></i>Desigualdade de Chebyshev</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><i class="fa fa-check"></i><b>6</b> Modelos Probabilísticos: Distribuições Associadas a Processos de Bernoulli</a><ul>
<li class="chapter" data-level="6.1" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#o-experimento-de-bernoulli"><i class="fa fa-check"></i><b>6.1</b> O Experimento de Bernoulli</a></li>
<li class="chapter" data-level="6.2" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-de-bernoulli"><i class="fa fa-check"></i><b>6.2</b> Distribuição de Bernoulli</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#resumo-2"><i class="fa fa-check"></i>Resumo</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-binomial"><i class="fa fa-check"></i><b>6.3</b> Distribuição Binomial</a></li>
<li class="chapter" data-level="6.4" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#um-problema-de-tomada-de-decisão"><i class="fa fa-check"></i><b>6.4</b> Um Problema de Tomada de Decisão</a></li>
<li class="chapter" data-level="6.5" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-geométrica"><i class="fa fa-check"></i><b>6.5</b> Distribuição Geométrica</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#propriedade-de-ausência-de-memória"><i class="fa fa-check"></i>Propriedade de Ausência de Memória</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#outras-distribuições"><i class="fa fa-check"></i><b>6.6</b> Outras Distribuições</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-binomial-negativa-ou-distribuição-de-pascal"><i class="fa fa-check"></i>Distribuição Binomial Negativa (ou Distribuição de Pascal)</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-multinomial"><i class="fa fa-check"></i>Distribuição Multinomial</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-multinomial-negativa"><i class="fa fa-check"></i>Distribuição Multinomial Negativa</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-hipergeométrica"><i class="fa fa-check"></i>Distribuição Hipergeométrica</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#distribuição-hipergeométrica-negativa"><i class="fa fa-check"></i>Distribuição Hipergeométrica Negativa</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-bernoulli.html#resumo-4"><i class="fa fa-check"></i>Resumo</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><i class="fa fa-check"></i><b>7</b> Modelos Probabilísticos: Distribuições Associadas a Processos de Poisson</a><ul>
<li class="chapter" data-level="7.1" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#uma-aproximação-para-a-distribuição-binomial"><i class="fa fa-check"></i><b>7.1</b> Uma aproximação para a Distribuição Binomial</a></li>
<li class="chapter" data-level="7.2" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#distribuição-de-poisson"><i class="fa fa-check"></i><b>7.2</b> Distribuição de Poisson</a></li>
<li class="chapter" data-level="7.3" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#o-processo-de-poisson"><i class="fa fa-check"></i><b>7.3</b> O Processo de Poisson</a></li>
<li class="chapter" data-level="7.4" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#distribuição-exponencial"><i class="fa fa-check"></i><b>7.4</b> Distribuição Exponencial</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#propriedade-de-ausência-de-memória-1"><i class="fa fa-check"></i>Propriedade de Ausência de Memória</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#distribuição-de-weibull"><i class="fa fa-check"></i>Distribuição de Weibull:</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html"><a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html#distribuição-gama"><i class="fa fa-check"></i><b>7.5</b> Distribuição Gama</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html"><i class="fa fa-check"></i><b>8</b> Modelos Probabilísticos: Distribuição Normal</a><ul>
<li class="chapter" data-level="8.1" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#distribuição-normal"><i class="fa fa-check"></i><b>8.1</b> Distribuição Normal</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#mais-uma-aproximação-para-a-distribuição-binomial"><i class="fa fa-check"></i>…(Mais) Uma Aproximação para a Distribuição Binomial</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#cálculo-de-probabilidades"><i class="fa fa-check"></i>Cálculo de Probabilidades</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#padronização-1"><i class="fa fa-check"></i>Padronização</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#regra-empírica"><i class="fa fa-check"></i>Regra Empírica</a></li>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#coeficiente-de-variação"><i class="fa fa-check"></i>Coeficiente de Variação</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#aproximação-para-distribuições-discretas"><i class="fa fa-check"></i><b>8.2</b> Aproximação para Distribuições Discretas</a><ul>
<li class="chapter" data-level="" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#aproximação-para-a-distribuição-binomial"><i class="fa fa-check"></i>Aproximação para a Distribuição Binomial</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="modelos-probabilísticos-distribuição-normal.html"><a href="modelos-probabilísticos-distribuição-normal.html#métodos-descritivos-para-avaliar-normalidade"><i class="fa fa-check"></i><b>8.3</b> Métodos Descritivos para Avaliar Normalidade</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html"><i class="fa fa-check"></i><b>9</b> Distribuições Amostrais</a><ul>
<li class="chapter" data-level="9.1" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#introdução-à-inferência-estatística"><i class="fa fa-check"></i><b>9.1</b> Introdução à Inferência Estatística</a><ul>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#inferência-estatística"><i class="fa fa-check"></i>Inferência Estatística</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#amostras-e-distribuições-amostrais"><i class="fa fa-check"></i><b>9.2</b> Amostras e Distribuições Amostrais</a><ul>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#amostra-aleatória"><i class="fa fa-check"></i>Amostra Aleatória</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#parâmetos-vs.-estatísticas"><i class="fa fa-check"></i>Parâmetos vs. Estatísticas</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-amostral"><i class="fa fa-check"></i>Distribuição Amostral</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-da-média-amostral"><i class="fa fa-check"></i><b>9.3</b> Distribuição da Média Amostral</a><ul>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#propriedades-da-média-amostral"><i class="fa fa-check"></i>Propriedades da Média Amostral</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#lei-dos-grandes-números"><i class="fa fa-check"></i>Lei dos Grandes Números</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#teorema-do-limite-central"><i class="fa fa-check"></i><b>9.4</b> Teorema do Limite Central</a></li>
<li class="chapter" data-level="9.5" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuições-amostrais-associadas-a-populações-normais"><i class="fa fa-check"></i><b>9.5</b> Distribuições Amostrais Associadas a Populações Normais</a><ul>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-qui-quadrado"><i class="fa fa-check"></i>Distribuição Qui-Quadrado</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-t-student"><i class="fa fa-check"></i>Distribuição t-Student</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#aproximando-distribuições-amostrais-via-simulação-de-monte-carlo"><i class="fa fa-check"></i><b>9.6</b> Aproximando Distribuições Amostrais via Simulação de Monte Carlo</a><ul>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-aproximada-da-mediana-amostral"><i class="fa fa-check"></i>Distribuição Aproximada da Mediana Amostral</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-aproximada-do-desvio-padrão-amostral"><i class="fa fa-check"></i>Distribuição Aproximada do Desvio-Padrão Amostral</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-aproximada-da-variância-amostral"><i class="fa fa-check"></i>Distribuição Aproximada da Variância Amostral</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-aproximada-do-mad-desvio-mediano-absoluto"><i class="fa fa-check"></i>Distribuição Aproximada do MAD (Desvio Mediano Absoluto)</a></li>
<li class="chapter" data-level="" data-path="distribuições-amostrais.html"><a href="distribuições-amostrais.html#distribuição-aproximada-da-amplitude-inter-quartis-iqr"><i class="fa fa-check"></i>Distribuição Aproximada da Amplitude Inter-Quartis (IQR)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="estimação-pontual.html"><a href="estimação-pontual.html"><i class="fa fa-check"></i><b>10</b> Estimação Pontual</a><ul>
<li class="chapter" data-level="10.1" data-path="estimação-pontual.html"><a href="estimação-pontual.html#estimador-e-estimativa"><i class="fa fa-check"></i><b>10.1</b> Estimador e Estimativa</a></li>
<li class="chapter" data-level="10.2" data-path="estimação-pontual.html"><a href="estimação-pontual.html#propriedades-de-estimadores"><i class="fa fa-check"></i><b>10.2</b> Propriedades de Estimadores</a><ul>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#não-tendeciosidade-exatidão"><i class="fa fa-check"></i>Não-Tendeciosidade (exatidão)</a></li>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#eficiência-precisão"><i class="fa fa-check"></i>Eficiência (precisão)</a></li>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#consistência"><i class="fa fa-check"></i>Consistência</a></li>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#erro-médio-quadrático"><i class="fa fa-check"></i>Erro Médio Quadrático</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="estimação-pontual.html"><a href="estimação-pontual.html#métodos-clássicos-de-estimação-de-parâmetros"><i class="fa fa-check"></i><b>10.3</b> Métodos Clássicos de Estimação de Parâmetros</a><ul>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#método-dos-momentos"><i class="fa fa-check"></i>Método dos Momentos</a></li>
<li class="chapter" data-level="" data-path="estimação-pontual.html"><a href="estimação-pontual.html#método-da-máxima-verossimilhança"><i class="fa fa-check"></i>Método da Máxima Verossimilhança</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="intervalos-de-confiança.html"><a href="intervalos-de-confiança.html"><i class="fa fa-check"></i><b>11</b> Intervalos de Confiança</a><ul>
<li class="chapter" data-level="11.1" data-path="intervalos-de-confiança.html"><a href="intervalos-de-confiança.html#estimação-por-intervalos"><i class="fa fa-check"></i><b>11.1</b> Estimação por Intervalos</a></li>
<li class="chapter" data-level="11.2" data-path="intervalos-de-confiança.html"><a href="intervalos-de-confiança.html#procedimento-para-construção-de-ics"><i class="fa fa-check"></i><b>11.2</b> Procedimento para Construção de IC’s</a><ul>
<li><a href="intervalos-de-confiança.html#caso-1-ic-para-mu-com-sigma2-conhecida">CASO 1: IC para <span class="math inline">\(\mu\)</span> com <span class="math inline">\(\sigma^2\)</span> conhecida</a></li>
<li><a href="intervalos-de-confiança.html#caso-2.1-ic-para-mu-com-sigma2-desconhecida">CASO 2.1: IC para <span class="math inline">\(\mu\)</span> com <span class="math inline">\(\sigma^2\)</span> desconhecida</a></li>
<li><a href="intervalos-de-confiança.html#caso-2.2-ic-para-mu-com-sigma2-desconhecida-amostras-grandes">CASO 2.2: IC para <span class="math inline">\(\mu\)</span> com <span class="math inline">\(\sigma^2\)</span> desconhecida (amostras grandes)</a></li>
<li><a href="intervalos-de-confiança.html#caso-3-ic-para-p-proporção-populacional">CASO 3: IC para <span class="math inline">\(p\)</span> (proporção populacional)</a></li>
<li><a href="intervalos-de-confiança.html#caso-3-ic-para-sigma2">CASO 3: IC para <span class="math inline">\(\sigma^2\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html"><i class="fa fa-check"></i><b>12</b> Testes de Hipóteses</a><ul>
<li class="chapter" data-level="12.1" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#formulação-de-hipóteses-estatísticas"><i class="fa fa-check"></i><b>12.1</b> Formulação de Hipóteses Estatísticas</a></li>
<li class="chapter" data-level="12.2" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#estatística-do-teste"><i class="fa fa-check"></i><b>12.2</b> Estatística do Teste</a></li>
<li class="chapter" data-level="12.3" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#erros-de-decisão"><i class="fa fa-check"></i><b>12.3</b> Erros de Decisão</a></li>
<li class="chapter" data-level="12.4" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#região-crítica"><i class="fa fa-check"></i><b>12.4</b> Região Crítica</a></li>
<li class="chapter" data-level="12.5" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#valor-p"><i class="fa fa-check"></i><b>12.5</b> Valor-p</a></li>
<li class="chapter" data-level="" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#qual-a-probabilidade-de-cometer-erro-do-tipo-ii"><i class="fa fa-check"></i>Qual a probabilidade de cometer erro do tipo II?</a></li>
<li class="chapter" data-level="12.6" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#poder-do-teste"><i class="fa fa-check"></i><b>12.6</b> Poder do Teste</a></li>
<li class="chapter" data-level="12.7" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#resumo-gráfico"><i class="fa fa-check"></i><b>12.7</b> Resumo Gráfico</a></li>
<li class="chapter" data-level="12.8" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#testes-mono--e-bi-caudais"><i class="fa fa-check"></i><b>12.8</b> Testes Mono- e Bi-Caudais</a><ul>
<li class="chapter" data-level="" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#região-de-rejeição-para-um-teste-bi-caudal"><i class="fa fa-check"></i>Região de Rejeição para um Teste Bi-caudal</a></li>
</ul></li>
<li class="chapter" data-level="12.9" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#procedimento-para-testes-de-hipóteses-utilizando-o-nível-de-significância"><i class="fa fa-check"></i><b>12.9</b> Procedimento para Testes de Hipóteses (utilizando o nível de significância)</a></li>
<li class="chapter" data-level="12.10" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#procedimento-para-testes-de-hipóteses-utilizando-valor-p"><i class="fa fa-check"></i><b>12.10</b> Procedimento para Testes de Hipóteses (utilizando valor-p)</a></li>
<li class="chapter" data-level="12.11" data-path="testes-de-hipóteses.html"><a href="testes-de-hipóteses.html#ic-vs-th"><i class="fa fa-check"></i><b>12.11</b> IC vs TH</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">GED-13: Probabilidade e Estatística</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modelos-probabilísticos-distribuição-normal" class="section level1">
<h1><span class="header-section-number">Capítulo 8</span> Modelos Probabilísticos: Distribuição Normal</h1>
<div id="distribuição-normal" class="section level2">
<h2><span class="header-section-number">8.1</span> Distribuição Normal</h2>
<p>Diferentemente das distribuições notáveis que estudamos até agora, a distribuição normal não foi construída como um modelo para uma situação aleatória bem definida; pelo contrário, trata-se de um modelo teórico, ou seja, consiste em uma abstração matemática. Ainda assim, a distribuição normal é uma das distribuições mais importantes para a Estatística, pois é útil para representar diversos fenômenos aleatórios que se manifestam no mundo real, além de modelar adequadamente a distribuição de probabilidades de estatísticas comumente utilizadas para realizar inferência.</p>
<div id="mais-uma-aproximação-para-a-distribuição-binomial" class="section level3 unnumbered">
<h3>…(Mais) Uma Aproximação para a Distribuição Binomial</h3>
<p>Vimos anteriormente que perguntas do tipo “qual a probabilidade de obter <span class="math inline">\(k\)</span> resultados favoráveis em <span class="math inline">\(n\)</span> repetições de um experimento de Bernoulli”, poderiam ser respondidas utilizando a distribuição binomial, segundo a expressão matemática a seguir</p>
<p><span class="math display">\[P[X = k] = \frac{n!}{(n-k)!k!} p^k (1-p)^{n-k}\]</span></p>
<p>O problema é que quando o número <span class="math inline">\(n\)</span> de repetições do experimento de Bernoulli é grande, o cálculo dessa probabilidade torna-se proibitivamente intenso sem o auxílio de uma calculadora ou de outras ferramentas computacionais.</p>
<p>Abraham De Moivre (1667-1754) foi o primeiro a chegar à formulação matemática da distribuição normal, ainda no século XVIII. Com a revogação do Édito de Nantes em 1865 pelo rei Luis XIV, estima-se que cerca de 200 a 900 mil protestantes franceses tenham deixado o país nas duas décadas seguintes. Esta lei tinha sido promulgada quase um século antes e conferia liberdade religiosa aos huguenotes. Com o fim da garantia de liberdade religiosa na França, De Moivre se viu forçado a buscar exílio na Inglaterra onde, mesmo sendo um país protestante, não se viu livre de sofrer preconceito por causa de sua origem francesa. Por conta disso, embora fosse um matemático talentoso, além de ter conexões importantes (ele foi amigo pessoal de Edmond Halley, Isaac Newton e James Stirling), De Moivre nunca conseguiu um emprego permanente e ganhava a vida precariamente trabalhando como tutor de matemática e prestando consultoria aos apostadores que frequentavam os cafés de Londres. Estes jogadores geralmente estavam interessados em responder a perguntas do tipo “qual a probabilidade de obter 60 ou mais caras em 100 lançamentos de uma moeda honesta?”. Vimos que probabilidades deste tipo podem ser calculadas de maneira exata utilizando a distribuição binomial dada na expressão matemática apresentada acima. A ocupação de De Moivre exigia que ele frequentemente realizasse esses penosos cálculos de probabilidades envolvendo a distribuição binomial.</p>
<p>De Moivre notou que conforme o número <span class="math inline">\(n\)</span> de repetições do experimento Bernoulli aumentava, a distribuição do número total de sucessos se aproximava de uma curva suave.</p>
<p><img src="08-ch8_files/figure-html/unnamed-chunk-1-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Se ele apenas fosse capaz de encontrar uma formulação matemática para esta curva, poderia calcular de maneira muito mais rápida as probabilidades de interesse. E foi exatamente isso o que ele fez em 1733, e a expressão matemática que desenvolveu para representar essa curva é o que hoje chamamos de <strong>distribuição Normal</strong>.</p>
<p>Uma v.a. <span class="math inline">\(X\)</span> com distribuição Normal com parâmetros <span class="math inline">\(\mu\)</span> e <span class="math inline">\(\sigma\)</span> tem fdp dada pela expressão abaixo:</p>
<p>Seja a v.a. <span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span>:</p>
<p><span class="math display">\[\begin{align*}
  &amp; f_{X}(x) =  \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}, \begin{array}{rl} &amp; -\infty &lt; x  &lt; \infty\\
               &amp; \mu \in \mathcal{R}, \; \sigma &gt; 0.
  \end{array}
  \\ \\ \\
  &amp; E[X] = \mu \qquad Var[X] = \sigma^2
\end{align*}\]</span></p>
<p>Esta densidade define, na verdade, uma família de distribuições já que cada distribuição corresponde a uma das infinitas combinações possíveis de valores para os parâmetros <span class="math inline">\(\mu\)</span> e <span class="math inline">\(\sigma\)</span>. O valor esperado da distribuição normal é <span class="math inline">\(\mu\)</span> e a variância é e <span class="math inline">\(\sigma^2\)</span>, ou seja, temos uma distribuição completamente determinada pelo primeiro momento e o segundo momento central, que correspondem às duas medidas descritivas mais utilizadas: localização e dispersão.</p>
<p><img src="08-ch8_files/figure-html/unnamed-chunk-2-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>A família de distribuições normais é formada por curvas simétricas em forma de sino, cuja moda (a abcissa que corresponde ao ponto de máximo) coincide com a média e também com a mediana, que correspondem ao ponto de simetria da distribuição, <span class="math inline">\(\mu\)</span>.</p>
<p>A curva normal possui dois pontos de inflexão dados por <span class="math inline">\(\mu - \sigma\)</span> e <span class="math inline">\(\mu + \sigma\)</span>, ou seja, são os pontos que se encontram a uma distância de um desvio da média (na figura, esses pontos são representados pelas retas pontilhadas coloridas), que definem aproximadamente 2/3 da área sob cada uma das curvas.</p>
<p>A curva normal tende assintoticamente a zero conforme se afasta do valor médio, o que significa que valores próximos à média são observados com grande frequência e raramente ocorrem valores afastados do centro.</p>
<p>Como é uma fdp, a área total sob da curva normal vale 1. E o achatamento da curva depende do valor do parâmetro <span class="math inline">\(\sigma\)</span>; quanto maior o valor de <span class="math inline">\(\sigma\)</span>, maior o espalhamento e, assim, mais achatada é a curva.</p>
<p>Esta é, sem dúvida, a família de distribuições de probabilidades mais importante para a Estatística por vários motivos: primeiro, porque muitos fenômenos encontrados no mundo real tem comportamento aleatório pelo menos aproximadamente normal; segundo, e mais importante, devido às suas características matemáticas, grande parte da teoria de inferência estatística paramétrica se baseia na distribuição normal; muitas variáveis aleatórias de interesse, incluindo diversas estatísticas comumente utilizadas para realizar inferência possuem distribuições que podem ser aproximadas por uma curva normal.</p>
<p>De fato, uma das primeiras aplicações da distribuição normal foi na análise de erros de medidas em observações astronômicas, devidos a imperfeições dos instrumentos e também dos observadores. Ainda no século XVII, Galileu Galilei (1564-1642) notou que esses erros eram geralmente simétricos e que erros de pequena magnitude ocorriam com maior frequência que erros muito grandes. Esta conjectura levou ao desenvolvimento de inúmeras distribuições candidatas para representar o comportamento aleatório dos erros, mas foi somente no início do século XIX que Carl Friedrich Gauss (1777-1855) chegou independentemente à formulação matemática da distribuição normal, ao perceber que tais erros seguiam essa distribuição. No entanto, por não ter desenvolvido uma prova que considerasse válida, em 1809 Gauss publicou o resultado como uma nota de fim de capítulo de um livro sobre a teoria do movimento de corpos celestes (<em>Teoria Motus Corporum Celestium</em>). E assim a descoberta ficou por um tempo esquecida.</p>
<p>O resgate da distribuição normal deveu-se a Laplace, que demonstrou uma versão mais geral do resultado de De Moivre. Enquanto De Moivre tinha mostrado que o número de sucessos em um processo de Bernoulli de tamanho <span class="math inline">\(n\)</span> tinha distribuição aproximadamente normal, apoiando-se no resultado de Gauss, Laplace chegou em 1810 à mesma conclusão, com respeito ao total ou à media das observações, independentemente da distribuição dessas observações.</p>
<p>Em outras palavras, ele mostrou que mesmo que uma variável aleatória não seguisse a distribuição normal, as médias de amostras retiradas dessa população teriam distribuição aproximadamente normal e essa aproximação seria tão melhor quanto maior o tamanho da amostra. Este resultado, de extrema importância para a Estatística, é o chamado .stand-out<a href="distribuições-amostrais.html#teorema-do-limite-central">Teorema do Limite central</a>, que estudaremos mais adiante. O Teorema do Limite central, por exemplo, fornece o alicerce teórico para a evidência empírica de que, na prática, muitos fenômenos aleatórios naturais seguem, pelo menos de maneira aproximada, a distribuição normal.</p>
<p>Devido às grandes contribuições de Gauss e Laplace para sua formulação matemática, a distribuição normal é também conhecida como distribuição Gaussiana ou distribuição de Gauss-Laplace. O termo “normal” seria cunhado por Karl Pearson apenas no início do século XX.</p>
</div>
<div id="cálculo-de-probabilidades" class="section level3 unnumbered">
<h3>Cálculo de Probabilidades</h3>
<p>Como a distribuição normal é contínua, podemos calcular probabilidades associadas a intervalos de valores que a v.a. pode assumir. Sendo assim,</p>
<p><span class="math display">\[P[x_1 &lt; X &lt; x_2] = \frac{1}{\sqrt{2\pi}\sigma} \int_{x_1}^{x_2} exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right]dx\]</span></p>
<p>que corresponde à probabilidade de que <span class="math inline">\(X\)</span> assuma valores no intervalo que vai de <span class="math inline">\(x_1\)</span> a <span class="math inline">\(x_2\)</span> corresponde à área sombreada na figura abaixo, de forma que é necessário calcular a integral da fdp de <span class="math inline">\(X\)</span> de <span class="math inline">\(x_1\)</span> até <span class="math inline">\(x_2\)</span>. Lembre-se ainda que podemos calcular essa área como a diferença entre os valores da função distribuição acumulada nesses dois pontos.</p>
<p><img src="08-ch8_files/figure-html/unnamed-chunk-3-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>No entanto, as integrais da densidade normal não podem ser resolvidas analiticamente, de forma que os valores de probabilidade associados a essa distribuição podem ser obtidos de maneira aproximada, através de valores tabelados, ou, ainda podem ser facilmente calculados com o auxílio de pacotes estatísticos computacionais, como o R.</p>
</div>
<div id="padronização-1" class="section level3 unnumbered">
<h3>Padronização</h3>
<p>Na impossibilidade de utilização de algum software estatístico, a padronização é um recurso importante para o cálculo de probabilidades envolvendo a distribuição Normal. A padronização consiste em uma transformação de escala e origem da variável aleatória, de forma que a v.a. transformada tem média zero e variância unitária. Assim, diz-se que a v.a. foi padronizada. A v.a. resultante é adimensional. Note que essa transformação pode ser aplicada a qualquer variável aleatória.</p>
<p>A v.a. <em>normal padronizada</em> tem distribuição normal com média zero e variância igual a 1 e é representada pela letra <span class="math inline">\(Z\)</span>. Para esta v.a., temos valores tabelados para sua distribuição, de forma a tornar possível calcular valores de probabilidade associados qualquer distribuição da família de distribuições normais.</p>
<p><span class="math display">\[\begin{align*}
  X \sim N(\mu, \sigma^2) \quad \Longrightarrow \quad 
  &amp; Z = \frac{X - \mu}{\sigma} \sim N(\mu_Z = 0, \sigma_Z^2 = 1)\\
  &amp; \varphi(z) = f_Z (z) = \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}z^2}\\
  &amp; \Phi(z) = F_Z(z) = P[Z \leq z], \; \forall z \in \Re
\end{align*}\]</span></p>
<p>Utilizamos <span class="math inline">\(varphi(z)\)</span> e <span class="math inline">\(\Phi(z)\)</span> para representar, respectivamente, a fdp e a FDA da v.a. normal padronizada.</p>
<p>Como a distribuição normal é simétrica, as áreas nas extremidades dos quantis <span class="math inline">\(-z_\alpha\)</span> e <span class="math inline">\(z_\alpha\)</span> são iguais e valem <span class="math inline">\(\alpha\)</span>. Consequentemente, a área interior delimitada pelos quantis <span class="math inline">\(-z_\alpha/2\)</span> e <span class="math inline">\(z_\alpha/2\)</span> vale <span class="math inline">\(1 - \alpha\)</span>.</p>
<p><img src="08-ch8_files/figure-html/unnamed-chunk-4-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Da simetria:</p>
<ul>
<li><span class="math inline">\(P[X \leq -z_\alpha] = P[Z \geq z_\alpha] = \alpha\)</span><br />
</li>
<li><span class="math inline">\(P[-z_{\alpha/2} &lt; Z &lt; z_{\alpha/2}] = 1 - \alpha\)</span></li>
</ul>

<div class="example">
<span id="exm:unnamed-chunk-5" class="example"><strong>Exemplo 3.3  </strong></span>
</div>

<p>A tabela de distribuição normal nos dá as probabilidades acumuladas, ou seja, no miolo da tabela temos os valores de <span class="math inline">\(P[Z \leq z] = \Phi(z)\)</span>. Podemos utilizá-la para calcular valores de probabilidades:</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(P[Z \leq 1.25] = \Phi(1.25)\)</span></li>
</ol>
<p><img src="img/distr-normal-a.png" width="100%" /></p>
<p>Para determinar o valor desta probabilidade, procuro na vertical a unidade e a primeira casa decimal do quantil desejado (1,2) e na horizontal, o valor da segunda casa decimal (0,05). O valor na interseção de linha e coluna corresponde ao valor de probabilidade acumulada para esse quantil.</p>
<p>Essa probabilidade pode ser facilmente obtida utilizando o comando abaixo no software R.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="modelos-probabilísticos-distribuição-normal.html#cb47-1"></a><span class="kw">pnorm</span>(<span class="fl">1.25</span>)</span></code></pre></div>
<ol start="2" style="list-style-type: lower-alpha">
<li><span class="math inline">\(P[Z &gt; 1.25] = 1- P[Z \leq 1.25] = 1 - \Phi(1.25)\)</span></li>
</ol>
<p><img src="img/distr-normal-b.png" width="100%" /></p>
<p>Precisamos calcular a área correspondente à cauda superior. Então, como a tabela dá a área acumulada, preciso calcular o complementar daquilo que nos é dado na tabela:</p>
<p><span class="math inline">\(P[Z &gt; 1.25] = 1 - P[Z ≤ 1.25] = 1 - \Phi(1.25) = 1 - 0.8944 = 0.1056\)</span></p>
<p>Podemos calcular essa probabilidade com o auxílio do software R, de acordo com o comando fornecido abaixo:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="modelos-probabilísticos-distribuição-normal.html#cb48-1"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="fl">1.25</span>)</span></code></pre></div>
<ol start="3" style="list-style-type: lower-alpha">
<li><span class="math inline">\(P[Z \leq - 1.25] = \Phi(-1.25) = 1 - \Phi(1.25)\)</span></li>
</ol>
<p><img src="img/distr-normal-c.png" width="100%" /></p>
<p>Precisamos calcular a área correspondente à cauda inferior correspondente ao quantil -1,25. Mas, como as margens da tabela só me dão quantis positivos, é necessário utilizar-se da simetria da distribuição normal: sabemos que a área à esquerda do quantil -1,25 é igual à área à direita do quantil 1,25, portanto:</p>
<p><span class="math inline">\(P[Z ≤ -1.25] = P[Z &gt; 1.25] = 1 - P[Z ≤ 1.25] = 1 - \Phi(1.25) = 0.1056\)</span>
(igual ao mesmo valor de probabilidade do item anterior, claro!)</p>
<p>Novamente, é recomendável utilizar o software R para calcular essa probabilidade, de acordo com o comando fornecido abaixo.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="modelos-probabilísticos-distribuição-normal.html#cb49-1"></a><span class="kw">pnorm</span>(<span class="op">-</span><span class="fl">1.25</span>)</span></code></pre></div>
<ol start="4" style="list-style-type: lower-alpha">
<li><span class="math inline">\(P[-0.38 \leq Z \leq 1.25] = \Phi(1.25) - \Phi(-0.38) = \Phi(1.25) + \Phi(0.38) - 1\)</span></li>
</ol>
<p><img src="img/distr-normal-d.png" width="100%" /></p>
<p>Finalmente, queremos a probabilidade de que <span class="math inline">\(Z\)</span> esteja no intervalo que vai de -0,38 a 1,25. Então, podemos subtrair as duas áreas acumuladas:</p>
<p><span class="math inline">\(P[Z ≤ 1.25] - P[Z ≤ -0.38]\)</span></p>
<p>Como não temos na tabela os quantis negativos, é necessário expressar <span class="math inline">\(P[Z ≤ -0.38]\)</span> em termos do quantil positivo 0,38, com base na simetria da distribuição.</p>
<p>Então,<br />
<span class="math inline">\(P[Z ≤ -0.38] = P[Z &gt; 0.38] = 1 - P[Z ≤ 0.38]\)</span></p>
<p>Portanto,</p>
<p><span class="math inline">\(P[-0.38 ≤ Z ≤ 1.25] = \Phi(1.25) + \Phi(0.38) - 1\)</span></p>
<p>O software R novamente simplifica muito o cálculo desta probabilidade, bastando utilizar o comando dado abaixo:</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="modelos-probabilísticos-distribuição-normal.html#cb50-1"></a><span class="kw">pnorm</span>(<span class="fl">1.25</span>) <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="op">-</span><span class="fl">0.38</span>)</span></code></pre></div>
</div>
<div id="regra-empírica" class="section level3 unnumbered">
<h3>Regra Empírica</h3>
<p>Comumente estamos interessados em determinar a probabilidade de que uma
v.a. assuma valores a uma certa distância de <span class="math inline">\(k\)</span> desvios-padrão de sua média. Tais limites são conhecidos como <em>limites de tolerância</em>.</p>
<p>Vimos anteriormente que a Desigualdade de Chebyshev nos permite determinar limites inferiores para esses valores de probabilidade, qualquer que seja a distribuição da v.a., quando conhecemos apenas o valor esperado e a variância da v.a.</p>
<p>Qualquer distribuição normal, independentemente dos valores assumidos por seus parâmetros <span class="math inline">\(\mu\)</span> e <span class="math inline">\(\sigma\)</span>, possui a mesma probabilidade a uma distância fixa, dada em termos de número de desvios de sua média.</p>
<p><span class="math display">\[\begin{align*}
  X \sim N(\mu, \sigma^2) \quad \Longrightarrow \quad 
  &amp;Z \sim N(0,1):\\ 
  &amp;P[|X -\mu| \leq k\sigma] = P[|Z| \leq k], \quad \forall k&gt;0
\end{align*}\]</span></p>
<p><img src="img/distr-normal-regra-empirica.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Para a distribuição normal, 68% (ou seja aproximadamente 2/3) das observações encontram-se a uma distância de 1 desvio-padrão de sua média; 95% das observações se encontram dentro dos limites de aproximadamente -2 a +2 desvios da média e, finalmente 99,7% (ou quase a totalidade) das observações se encontra a uma distância de 3 desvios da média. Sendo assim, espera-se que apenas cerca de 0,3% de todos os valores se encontrem a uma distância da média superior a três desvios. Então, embora o suporte da distribuição normal seja toda a reta real, na prática, a largura da distribuição normal é seis sigma.</p>
<p>A associação dos valores de probabilidade 68, 95 e 99,7 da distribuição normal aos respectivos fatores-k é chamada de <em>Regra Empírica</em>, exatamente por causa da grande utilização da distribuição normal para representar a distribuição das observações obtidas empiricamente nas mais diversas aplicações práticas.</p>
<p>Como curiosidade, veja como esses limites se comparam com aqueles obtidos através da Desigualdade de Chebyshev, em que os mesmos valores de probabilidade são garantidos para intervalos muito mais largos.</p>
<p><img src="img/distr-normal-regra-empirica-tabela.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="coeficiente-de-variação" class="section level3 unnumbered">
<h3>Coeficiente de Variação</h3>
<p>A distribuição normal é frequentemente utilizada para modelar vas que assumem apenas valores positivos (como área, altura, peso, distância, entre outras). O problema é que o suporte da distribuição normal é a reta real, o que significa que a v.a. normalmente distribuída pode assumir qualquer valor real, positivo ou negativo.</p>
<p>Como podemos contornar essa dificuldade?</p>
<p>Precisamos garantir que a probabilidade de observar um valor negativo seja desprezível. A regra de bolso nos diz que isso ocorre quando o coeficiente de variação, dado pela razão entre o desvio-padrão e a média, <span class="math inline">\(\sigma\)</span> sobre <span class="math inline">\(\mu\)</span> é menor que 0,3.</p>
<p><span class="math display">\[CV = \frac{\sigma}{\mu} &lt;  0,3\]</span></p>

<div class="example">
<span id="exm:unnamed-chunk-10" class="example"><strong>Exemplo 8.1  </strong></span>
</div>

<p>Peças em projeto aeronáutico comumente são unidas através de rebitagem. O cliente define a especificação do diâmetro dos rebites em 3,0 <span class="math inline">\(\pm\)</span> 0,01 mm. Qualquer rebite cujo diâmetro se encontre dentro da especificação será aceitável.</p>
<p>Considerando o diâmetro dos rebites uma v.a. normalmente distribuída com média <span class="math inline">\(\mu =\)</span> 3,0 e desvio-padrão <span class="math inline">\(\sigma =\)</span> 0,005, que proporção de rebites será rejeitada?</p>

<div class="solution">
 <span class="solution"><em>Solução. </em></span> 
</div>

<p>São aceitáveis os rebites cujos diâmetros se encontram no intervalo (2,99; 3,01).<br />
Portanto, queremos a probabilidade de rejeitar um determinado rebite, dada por:<br />
1 - P[2,99 &lt; X &lt; 3,01]</p>
<p><strong>Solução Manual</strong><br />
1. Padronizar a v.a. para uso da tabela normal ( <span class="math inline">\(\mu=\)</span> 3 e <span class="math inline">\(\sigma =\)</span> 0,005):<br />
<span class="math inline">\(z_1\)</span> = (2,99 - µ)/σ = -2.0 <span class="math inline">\(\quad z_2\)</span> = (3,01 - µ)/σ = 2.0<br />
2. Buscar na tabela valores de probabilidade:<br />
P[Z &lt; <span class="math inline">\(z_1\)</span> ] = 0,02275 e P[Z &lt; <span class="math inline">\(z_2\)</span> ] = 0,97725<br />
3. Probabilidade desejada:<br />
1 - P[2,99 &lt; X &lt; 3,01] = 1 - P[-2 &lt; Z &lt; 2] = 1 - (0,97725 - 0,02275) = 0,0455 <span class="math inline">\(\quad \therefore \quad \approx\)</span> 4,55%</p>
<p>Portanto, espera-se que em média 4,55% dos rebites sejam rejeitados.</p>
<p>No R, é possível calcular esta probabilidade utilizando o comando abaixo:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="modelos-probabilísticos-distribuição-normal.html#cb51-1"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="kw">pnorm</span>(<span class="fl">3.01</span>, <span class="dt">mean =</span> <span class="dv">3</span>, <span class="dt">sd =</span> <span class="fl">0.005</span>) <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="fl">2.99</span>, <span class="dt">mean =</span> <span class="dv">3</span>, <span class="dt">sd =</span> <span class="fl">0.005</span>))</span></code></pre></div>
</div>
</div>
<div id="aproximação-para-distribuições-discretas" class="section level2">
<h2><span class="header-section-number">8.2</span> Aproximação para Distribuições Discretas</h2>
<p>A distribuição Normal comumente é utilizada para aproximar distribuições discretas simétricas. No entanto, como a distribuição normal é <em>contínua</em>, é necessário incluir uma correção para levar em conta a continuidade da distribuição. Essa correção é necessária toda as vezes que aproximamos uma população discreta por uma distribuição contínua.</p>
<p>Essa correção foi proposta por Augustus de Morgan em 1838, na tentativa de aperfeiçoar a aproximação de De Moivre para a distribuição Binomial, com base na ideia de que cada probabilidade binomial deveria ser interpretada como uma área de base unitária.</p>
<p><img src="08-ch8_files/figure-html/unnamed-chunk-13-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Seja <span class="math inline">\(X \sim p_X(x)\)</span> a v.a. discreta de interesse. A distribuição de <span class="math inline">\(X\)</span> é representada pelo histograma.</p>
<p>Queremos calcular a probabilidade: <span class="math inline">\(P[i \leq X \leq j], \quad i &lt; j;\; i,j \in \mathcal{Z}\)</span></p>
<ol style="list-style-type: lower-roman">
<li><p>Do histograma, pode-se determinar esta probabilidade de maneira .stand-out[extata], calculando-se:<br />
<span class="math display">\[P[i \leq X \leq j] = \sum_{x=i}^j p_X(x)\]</span></p></li>
<li><p>Suponha <span class="math inline">\(f_X(x)\)</span> uma boa aproximação para <span class="math inline">\(p_X(x)\)</span>. A fim de calcular a probabilidade associada à v.a. discreta a partir da aproximação pela função contínua <span class="math inline">\(f_X(x)\)</span>, a área sob a curva contínua precisa ser obtida através da integral entre os limites <span class="math inline">\(i\)</span> e <span class="math inline">\(j\)</span> desejados, com o acréscimo de 1/2 (a metade da base) em cada direção:<br />
<span class="math display">\[P[i \leq X \leq j] = \int_{x=i-1/2}^{j+1/2} f_X(x) dx\]</span></p></li>
</ol>
<div id="aproximação-para-a-distribuição-binomial" class="section level3 unnumbered">
<h3>Aproximação para a Distribuição Binomial</h3>
<p>Como De Moivre demonstrou, uma v.a. binomial com parâmetros <span class="math inline">\(n\)</span> e <span class="math inline">\(p\)</span> pode ter sua distribuição satisfatoriamente aproximada pela distribuição Normal para valores elevados de <span class="math inline">\(n\)</span>; isto é, para <span class="math inline">\(n ≥ 30\)</span> e quando ambos os produtos <span class="math inline">\(np\)</span> e <span class="math inline">\(nq\)</span> valem pelo menos 5:</p>
<p><span class="math inline">\(X \sim Bin (n, p)\)</span></p>
<p>Se <span class="math inline">\(n \geq 30; \; np \geq 5; \; nq \geq 5\)</span>:</p>
<p><span class="math display">\[X \sim Bin(n, p) \longrightarrow N(\mu = np, \sigma^2 = npq) \\ \frac{X - np}{\sqrt{npq}} \stackrel{\cdot}{\sim} N(0,1)\]</span></p>
<p>Nestas circunstâncias, a distribuição binomial apresenta forma de sino, com média <span class="math inline">\(pq\)</span> e variância <span class="math inline">\(npq\)</span>, de forma que, ao aplicar a transformação de padronização à v.a. <span class="math inline">\(X\)</span>, a distribuição da v.a. resultante é aproximadamente normal padronizada.</p>

<div class="example">
<span id="exm:unnamed-chunk-14" class="example"><strong>Exemplo 8.2  </strong></span>
</div>

<p>Companhias aéreas costumam praticar “overbooking”, vendendo um número de passagens superior ao número de assentos disponíveis na aeronave, a fim de maximizar seu retorno, já que existe a expectativa de que nem todos os passageiros se apresentem na hora do embarque. Tais passageiros são classificados como “no-show”.</p>
<p>Suponha que tenham sido emitidas 200 passagens para um voo com capacidade para 197 passageiros e que a taxa de “no-show” para este voo seja de 2%.</p>
<p>Qual a probabilidade de que haja <em>overbooking</em> para este voo, de forma que nem todos os passageiros que se apresentarem para embarque poderão viajar?</p>

<div class="solution">
 <span class="solution"><em>Solução. </em></span> 
</div>

<p>Se considerarmos que os passageiros viajam sozinhos, sem acompanhantes, e que chegaram de maneira independente ao aeroporto, podemos modelar o número de “shows”, isto é, o número de passageiros que se apresentam para o embarque como uma v.a. com distribuição Binomial, com parâmetros <span class="math inline">\(n= 200\)</span> e <span class="math inline">\(p = 0.98\)</span>:</p>
<p><span class="math inline">\(X =\)</span> número de “shows” (passageiros que se apresentam para embarque)<br />
<span class="math inline">\(p =\)</span> probabilidade de “show” <span class="math inline">\(= 1 - 0,02 = 0,98\)</span></p>
<p>Portanto: <span class="math inline">\(X \sim Bin ( n = 200, p = 0,98 )\)</span></p>
<p>Queremos calcular a probabilidade de que o número de “shows” seja maior que a capacidade do voo, que vale 197: <span class="math inline">\(P[X &gt; 197]\)</span></p>
<p>Dadas as características do problema, podemos resolvê-lo de diferentes maneiras. Primeiro, vamos considerar a solução analítica exata, utilizando a distribuição Binomial.</p>
<p><strong>Cálculo exato utilizando a Distribuição Binomial:</strong></p>
<p>Neste caso, precisamos somar os valores de probabilidade binomial para valores de <span class="math inline">\(X\)</span> que vão de 198 a 200. Fazendo isto, chegamos à conclusão de que há aproximadamente 23,5% de chance de overbooking.</p>
<p><span class="math inline">\(P[X &gt; 197] = \sum_{x=198}^{200} Bin (x, n, p) = \sum_{x=198}^{200} \frac{n!}{(n-x)!x!} p^x (1-p)^{n-x} = \ldots\)</span><br />
<span class="math inline">\(\approx 23.5\%\)</span></p>
<p>Os cálculos são facilmente realizados com o auxílio do software R, utilizando qualquer dos comandos alternativos dados abaixo.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="modelos-probabilísticos-distribuição-normal.html#cb52-1"></a><span class="kw">sum</span>(<span class="kw">dbinom</span>(<span class="dv">198</span><span class="op">:</span><span class="dv">200</span>, <span class="dt">size =</span> <span class="dv">200</span>, <span class="dt">prob =</span> <span class="fl">0.98</span>))  </span>
<span id="cb52-2"><a href="modelos-probabilísticos-distribuição-normal.html#cb52-2"></a><span class="kw">pbinom</span>(<span class="dv">200</span>, <span class="dv">200</span>, <span class="fl">0.98</span>) <span class="op">-</span><span class="st"> </span><span class="kw">pbinom</span>(<span class="dv">197</span>, <span class="dv">200</span>, <span class="fl">0.98</span>)</span></code></pre></div>
<p><strong>Utilizando a Aproximação Normal:</strong></p>
<p>Já que o número de passagens vendidas é elevado, podemos tentar utilizar a aproximação para uma distribuição Normal com média <span class="math inline">\(\mu = np = 196\)</span> e variância igual <span class="math inline">\(npq\)</span>:</p>
<p><span class="math inline">\(\mu = np = 200 \times 0.98 = 196\)</span><br />
<span class="math inline">\(\sigma = \sqrt{npq} = \sqrt{200 \times 0.98 \times 0.02} = 1.98\)</span></p>
<p>Para que a aproximação seja adequada, precisamos verificar as condições de que <span class="math inline">\(np\)</span> e <span class="math inline">\(nq\)</span> sejam ambos maiores que 5. Estas condições garantem que a distribuição binomial seja simétrica, com forma aproximada de sino:</p>
<p><span class="math inline">\(np = 200 \times 0.98 = 196; \quad nq = 200 \times 0.02 = 4\)</span>.</p>
<p><img src="08-ch8_files/figure-html/unnamed-chunk-17-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Para este exemplo, a distribuição binomial não é simétrica. Veja no gráfico, como a cauda da distribuição binomial (em cinza) é mais curta à direita. Ainda assim, prosseguiremos.</p>
<p>Ao aproximar a distribuição binomial (que é discreta) pela distribuição normal (que é contínua), precisamos realizar a correção para a continuidade.</p>
<p>Desejamos calcular a probabilidade <span class="math inline">\(P[X &gt; 197]\)</span> (sinalizada em azul no gráfico). Portanto, o quantil considerado para a aproximação normal deverá ser de <span class="math inline">\(197 + 1/2\)</span>. Padronizando este valor, temos o escore-z (que corresponde ao quantil da distribuição normal padronizada) dado por <span class="math inline">\(z_2\)</span>:</p>
<p><span class="math inline">\(x_2 = 197 + 0.5 = 197.5 \\ \Rightarrow \; Z \sim N(0, 1): \qquad z_2 = \frac{(197.5 - 196)}{1.98} = 0.7576\)</span></p>
<p>Portanto,<br />
<span class="math display">\[P[X &gt; 197] \approx P[Z &gt; z_1] = 1 - \Phi(z_1)  \approx 22.4\%,\]</span></p>
<p>ou seja, a probabilidade desejada vale aproximadamente 22,4% e pode ser obtida numericamente no software R utilizando o comando fornecido abaixo.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="modelos-probabilísticos-distribuição-normal.html#cb53-1"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="fl">197.5</span>, <span class="dt">mean =</span> <span class="dv">196</span>, <span class="dt">sd =</span> <span class="fl">1.98</span>)  <span class="co"># com correção para continuidade</span></span></code></pre></div>
<p>Esta aproximação apresenta erro da ordem de 1 ponto percentual com relação ao valor exato calculado a partir da distribuição Binomial, devido à inadequação do ajuste.</p>
<p><strong>Utilizando a Aproximação de Poisson:</strong></p>
<p>Podemos também aproximar a distribuição Binomial pela distribuição de Poisson quando <span class="math inline">\(n\)</span> é grande e <span class="math inline">\(p\)</span> é pequeno. Neste caso, vamos aproximar a distribuição do número de passageiros que não se apresentam para o embarque, que será representado pela v.a. <span class="math inline">\(Y\)</span>. Para cada passageiro, esta probabilidade é <span class="math inline">\(q\)</span> e vale 0,02. Portanto, o parâmetro da distribuição de Poisson correspondente é <span class="math inline">\(\lambda = nq = 4\)</span>:</p>
<ul>
<li><span class="math inline">\(Y \sim Pois(\lambda)\)</span>: número de “no-shows”</li>
<li>Condição: <span class="math inline">\(\lambda = nq = 200 \times 0.02 = 4\)</span></li>
</ul>
<p>Sendo assim, para que haja <em>overbooking</em>, o número de “no-shows” deve ser menor ou igual a 2 e, portanto, a probabilidade desejada segundo a aproximação de Poisson vale cerca de 23,8%, conforme mostram os cálculos abaixo.</p>
<p><span class="math inline">\(P[X &gt; 197] \approx P[Y \leq 2] = \sum_{x=0}^{2} Pois (x, \lambda = nq) =\ldots \approx 23.8\%\)</span></p>
<p>Este valor de probabilidade é obtido utilizando o software R através do seguinte comando:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="modelos-probabilísticos-distribuição-normal.html#cb54-1"></a><span class="kw">sum</span>(<span class="kw">dpois</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">2</span>, <span class="dt">lambda =</span> <span class="dv">4</span>))</span></code></pre></div>
<p>Veja graficamente a semelhança das duas distribuições. Neste exemplo, a distribuição de Poisson se mostrou uma aproximação mais adequada que a distribuição Normal. A área sombreada em azul, representa a probabilidade de interesse calculada.</p>
<p><img src="08-ch8_files/figure-html/unnamed-chunk-20-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><strong>Utilizando Simulação:</strong></p>
<p>Podemos ainda estimar essa probabilidade via simulação. Para isso, basta gerar uma grande quantidade de realizações da v.a. Binomial, com parâmetros <span class="math inline">\(n = 200\)</span> e <span class="math inline">\(p = 0,98\)</span>.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-1"></a>Nsim &lt;-<span class="st"> </span><span class="dv">1000</span> <span class="co"># no. de voos simulados</span></span>
<span id="cb55-2"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-2"></a>Nrep &lt;-<span class="st"> </span><span class="dv">100</span>  <span class="co"># no. de replicações</span></span>
<span id="cb55-3"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-3"></a>simula_voo &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rbinom</span>(Nsim<span class="op">*</span>Nrep, <span class="dt">size =</span> <span class="dv">200</span>, <span class="dt">prob =</span> <span class="fl">0.98</span>),</span>
<span id="cb55-4"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-4"></a>                     <span class="dt">ncol =</span> Nrep)</span>
<span id="cb55-5"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-5"></a>              <span class="co"># cada coluna armazena uma replicação de</span></span>
<span id="cb55-6"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-6"></a>              <span class="co"># &#39;Nsim&#39; voos simulados</span></span>
<span id="cb55-7"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-7"></a></span>
<span id="cb55-8"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-8"></a><span class="co"># condição de overbooking:</span></span>
<span id="cb55-9"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-9"></a>overbook &lt;-<span class="st"> </span>simula_voo <span class="op">&gt;</span><span class="st"> </span><span class="dv">197</span></span>
<span id="cb55-10"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-10"></a></span>
<span id="cb55-11"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-11"></a><span class="co"># calcula freq. de overbooking observada</span></span>
<span id="cb55-12"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-12"></a><span class="co"># para cada replicação de &#39;Nsim&#39; voos simulados</span></span>
<span id="cb55-13"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-13"></a>frel_overbook &lt;-<span class="st"> </span><span class="kw">colMeans</span>(overbook) </span>
<span id="cb55-14"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-14"></a></span>
<span id="cb55-15"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-15"></a><span class="co"># Histograma com as estimativas para P[X &gt; 197]</span></span>
<span id="cb55-16"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-16"></a><span class="kw">hist</span>(frel_overbook, <span class="dt">freq=</span><span class="ot">FALSE</span>,</span>
<span id="cb55-17"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-17"></a>     <span class="dt">density =</span> <span class="dv">25</span>,</span>
<span id="cb55-18"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-18"></a>     <span class="dt">yaxt =</span> <span class="st">&quot;n&quot;</span>,</span>
<span id="cb55-19"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-19"></a>     <span class="dt">main =</span> <span class="st">&quot;Freq. relativa de &#39;overbooking&#39;&quot;</span>, </span>
<span id="cb55-20"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-20"></a>     <span class="dt">xlab =</span> <span class="st">&quot;&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb55-21"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-21"></a>     <span class="dt">col=</span><span class="st">&quot;gray&quot;</span>)</span>
<span id="cb55-22"><a href="modelos-probabilísticos-distribuição-normal.html#cb55-22"></a><span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">mean</span>(frel_overbook), <span class="dt">col =</span> <span class="dv">2</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>, <span class="dt">lwd =</span> <span class="dv">3</span>)</span></code></pre></div>
<p>Os valores simulados são organizados na matriz <code>simula_voo</code>, tal que cada coluna corresponde a uma replicação da simulação de <code>Nsim</code> voos simulados. Há portanto, um total de <code>Nsim</code> linhas e <code>Nrep</code> colunas.</p>
<p>Cada elemento de <code>simula_voo</code> corresponde ao número de passageiros que se apresentaram para o embarque em um voo simulado. Verificamos se cada um desses voos resultou em <em>overbooking</em> e registramos a frequência relativa de <em>overbooking</em> em cada coluna, isto é, em cada replicação da simulação. Cada frequência relativa calculada corresponde a uma estimativa para a probabilidade de <span class="math inline">\(X &gt; 197\)</span>. Com isso, obtemos um número igual a <code>Nrep</code> estimativas para esta probabilidade. O histograma representa a distribuição das frequências relativas de <em>overbooking</em> observadas nas <code>Nrep</code> replicações. Veja que o centro da distribuição amostral é bem próximo do valor de probabilidade que desejamos calcular.</p>
<p><img src="08-ch8_files/figure-html/unnamed-chunk-22-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="métodos-descritivos-para-avaliar-normalidade" class="section level2">
<h2><span class="header-section-number">8.3</span> Métodos Descritivos para Avaliar Normalidade</h2>
<p>Embora não seja a melhor maneira de fazer isso, podemos avaliar a normalidade dos dados observando o <strong>histograma</strong> ou <strong>gráfico de frequência relativa</strong>. Se os dados forem aproximadamente normalmente distribuídos, espera-se que o histograma seja unimodal em torno da média, simétrico, com caudas curtas.</p>
<p>É importante verificar a <strong>amplitude interquartis</strong> e também o desvio-padrão amostral para os dados. Para dados com distribuição aproximadamente Normal, a razão entre a amplitude interquartis e o desvio padrão amostral deve estar em torno de 1,3.</p>
<p>E finalmente, o método descritivo mais utilizado para avaliar normalidade é o <strong>gráfico de quantis</strong>, que compara os quantos amostrais com os teóricos da distribuição normal correspondente. Se os dados tem distribuição aproximadamente normal, os pontos no gráfico de quantis estão dispostos em uma linha reta.</p>
<p>Vejamos a aplicação desses métodos em um conjunto de dados.</p>

<div class="example">
<span id="exm:unnamed-chunk-23" class="example"><strong>Exemplo 8.3  </strong></span>
</div>

<p>Os dados se referem a 100 medidas de consumo de combustível de um tipo de automóvel de passeio. O primeiro passo consiste em carregar os dados e analisar o resumo numérico.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="modelos-probabilísticos-distribuição-normal.html#cb56-1"></a><span class="co"># carrega dados</span></span>
<span id="cb56-2"><a href="modelos-probabilísticos-distribuição-normal.html#cb56-2"></a>consumo &lt;-<span class="st"> </span><span class="kw">scan</span>(<span class="st">&quot;data/CONSUMO.txt&quot;</span>)</span>
<span id="cb56-3"><a href="modelos-probabilísticos-distribuição-normal.html#cb56-3"></a></span>
<span id="cb56-4"><a href="modelos-probabilísticos-distribuição-normal.html#cb56-4"></a><span class="co"># produz resumo numérico dos dados</span></span>
<span id="cb56-5"><a href="modelos-probabilísticos-distribuição-normal.html#cb56-5"></a><span class="kw">summary</span>(consumo)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   12.76   15.17   15.73   15.73   16.29   19.09</code></pre>
<p>Como uma primeira verificação de normalidade, vamos examinar o histograma que representa a distribuição dos valores de consumo de combustível registrados. A curva normal correspondente é sobreposta ao histograma. Claramente, a distribuição dos dados de consumo de combustível é unimodal em torno da média (que vale 15.73, conforme mostra o resumo numérico dos dados); além disso, a distribuição é aparentemente simétrica (a média é igual à mediana) com formato aproximado de sino.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="modelos-probabilísticos-distribuição-normal.html#cb58-1"></a><span class="co"># constroi histograma de freq. relativa</span></span>
<span id="cb58-2"><a href="modelos-probabilísticos-distribuição-normal.html#cb58-2"></a><span class="kw">hist</span>(consumo, <span class="dt">freq =</span> <span class="ot">FALSE</span>,  <span class="dt">main =</span> <span class="st">&quot;&quot;</span>, </span>
<span id="cb58-3"><a href="modelos-probabilísticos-distribuição-normal.html#cb58-3"></a>     <span class="dt">ylab =</span> <span class="st">&quot;Freq. Relativa&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;km/l&quot;</span>)</span>
<span id="cb58-4"><a href="modelos-probabilísticos-distribuição-normal.html#cb58-4"></a></span>
<span id="cb58-5"><a href="modelos-probabilísticos-distribuição-normal.html#cb58-5"></a>  m &lt;-<span class="st"> </span><span class="kw">mean</span>(consumo)</span>
<span id="cb58-6"><a href="modelos-probabilísticos-distribuição-normal.html#cb58-6"></a>  s &lt;-<span class="st"> </span><span class="kw">sd</span>(consumo)</span>
<span id="cb58-7"><a href="modelos-probabilísticos-distribuição-normal.html#cb58-7"></a>  <span class="kw">curve</span>(<span class="kw">dnorm</span>(x, m, s), <span class="dt">add =</span> <span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="08-ch8_files/figure-html/unnamed-chunk-26-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="modelos-probabilísticos-distribuição-normal.html#cb59-1"></a><span class="co"># calcula amplitude interquartis</span></span>
<span id="cb59-2"><a href="modelos-probabilísticos-distribuição-normal.html#cb59-2"></a>IQR &lt;-<span class="st"> </span><span class="kw">diff</span>(<span class="kw">quantile</span>(consumo, <span class="dt">probs =</span> <span class="kw">c</span>(<span class="fl">0.25</span>, <span class="fl">0.75</span>))) </span>
<span id="cb59-3"><a href="modelos-probabilísticos-distribuição-normal.html#cb59-3"></a><span class="co"># razão entre amplitude interquartis e desvio-padrão amostral</span></span>
<span id="cb59-4"><a href="modelos-probabilísticos-distribuição-normal.html#cb59-4"></a>IQR<span class="op">/</span><span class="kw">sd</span>(consumo)</span></code></pre></div>
<pre><code>##      75% 
## 1.092566</code></pre>
<p>A razão entre a amplitude interquartis e o desvio-padrão amostral é um pouco menor que 1.3; isso significa que a distribuição amostral é um pouco menos espalhada que a distribuição normal.</p>
<p>Por fim, analisemos o gráfico de quantis, também chamado de gráfico de probabilidades.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="modelos-probabilísticos-distribuição-normal.html#cb61-1"></a><span class="co"># produz gráfico de quantis</span></span>
<span id="cb61-2"><a href="modelos-probabilísticos-distribuição-normal.html#cb61-2"></a><span class="kw">qqnorm</span>(consumo, </span>
<span id="cb61-3"><a href="modelos-probabilísticos-distribuição-normal.html#cb61-3"></a>       <span class="dt">main =</span> <span class="st">&quot;&quot;</span>, </span>
<span id="cb61-4"><a href="modelos-probabilísticos-distribuição-normal.html#cb61-4"></a>       <span class="dt">pch =</span> <span class="dv">19</span>)</span>
<span id="cb61-5"><a href="modelos-probabilísticos-distribuição-normal.html#cb61-5"></a><span class="co"># adiciona reta de referência</span></span>
<span id="cb61-6"><a href="modelos-probabilísticos-distribuição-normal.html#cb61-6"></a><span class="kw">qqline</span>(consumo, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="08-ch8_files/figure-html/unnamed-chunk-29-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Em um gráfico de quantis, o eixo vertical corresponde às observações do conjunto ordenadas do menor ao maior valor; no eixo horizontal temos os escores-z esperados das observações, sob a hipótese de normalidade. Quando os dados têm distribuição aproximadamente normal, os valores observados serão próximos dos valores esperados. Desta forma, quando o gráfico que quantis evidencia pontos dispostos em uma linha reta; desvios significativos de uma tendência linear indicam não-normalidade.</p>
<p>Esses métodos de verificação apresentados são bastante simples e, no entanto, poderosos, mas têm natureza simplesmente descritiva. Isso significa que não conferem validade estatística aos achados. Sendo assim, embora pouco provável, é possível que os dados sejam oriundos de uma distribuição não normal, mesmo que os resultados dessas técnicas descritivas apontem para uma aparente normalidade. Portanto, não podemos afirmar que os dados são, de fato, normalmente distribuídos com base no emprego de métodos descritivos; podemos apenas afirmar que parece razoável crer que os dados são normalmente distribuídos.</p>
<p>Existem métodos formais, baseados em testes de hipóteses, para avaliar a significância estatística dessa inferência. No entanto, testes de normalidade tendem a ser muito sensíveis a pequenos desvios de normalidade, o que quer dizer que eles tendem a rejeitar a hipótese de normalidade para qualquer distribuição que não seja perfeitamente simétrica e unimodal, especialmente quando muitas observações estão disponíveis.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="modelos-probabilísticos-distribuições-associadas-a-processos-de-poisson.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="distribuições-amostrais.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["apostila-GED13.pdf", "apostila-GED13.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
